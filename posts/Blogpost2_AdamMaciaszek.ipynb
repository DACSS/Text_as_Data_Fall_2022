{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Blog Post 2 Adam Maciaszek\"\n",
        "author: \"Adam Maciaszek\"\n",
        "desription: \"Web Scraping Ancient babylonian texts\"\n",
        "date: \"10/10/2022\"\n",
        "format:\n",
        "  html:\n",
        "    toc: true\n",
        "    code-fold: true\n",
        "    code-copy: true\n",
        "    code-tools: true\n",
        "---"
      ],
      "id": "a79ab218"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import numpy as np\n",
        "import collections\n",
        "import matplotlib.pyplot as plt"
      ],
      "id": "56d5be83",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Blog Post 2\n",
        "Further investigation into Zipf's law and ancient texts\n",
        "\n",
        "## Web Scraping Ancient babylonian texts\n",
        "To analyze ancient texts in relation to the Zipf law and the general complexity compared to modern-day language A large source of documents needed to be gathered. For this, I used a collection created by the Department of History, School of History, Religions & Philosophies of SOAS University of London. This collection's purpose was to hear how the ancient language of Akkadian sounded like and have recordings of each text as well as a phonetic spelling of each word. Each text is separate line by line with its direct translation of the line rather than a reworded contextual translation. The collection of these texts was made more difficult since the website I found currently is being reorganized and I needed to use the WayBackMAchine archived webpages which does not include the sound recording but all of the texts were saved\n"
      ],
      "id": "6bc67754"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def cleaner(the_input):\n",
        "    the_input = re.sub(\"\\(\\(.*\\)\\)\",'', the_input)\n",
        "    the_input=the_input.lower()\n",
        "    the_input = the_input.replace('(ii',\"\").replace(\"iii.\",\"\").replace(\"ii.\",\"\").replace(\"i ii \",\"\").replace(\"i i \",\"\").replace(\"i iii \",\"\")\n",
        "    the_input = the_input.replace('#',\"\").replace('˺',\"\").replace('˹',\"\").replace(':',\"\").replace('<',\"\").replace('>',\"\").replace('*',\"\").replace('\\xa0',\"\").replace('|',\"\").replace('/',\"\").replace('–',\"\").replace('“',\"\").replace('”',\"\").replace(\"[\",\"\").replace(\"]\",\"\").replace(\"(\",\"\").replace(\")\",\"\").replace(\"’\",\"\").replace(\".\",\"\").replace(\"…\",\"\").replace(\":\",\"\").replace(\"!\",\"\").replace(\"?\",\"\")\n",
        "    the_input = the_input.replace(\"   \",\" \").replace(\"  \",\" \").replace(\",\",\"\").replace(\";\",\"\").replace('\"',\"\")\n",
        "    return the_input\n",
        "\n",
        "def grab_html2(url,text_output):\n",
        "    df = pd.read_html(url)\n",
        "    df=df[1]\n",
        "    for x in range(0,len(df)):\n",
        "        akk=df.iloc[x][0]\n",
        "        akk = re.sub(r'[0-9]+', '', akk)\n",
        "        akk = cleaner(akk)\n",
        "        akk = akk.replace('- ',\" \")\n",
        "        akk = akk.replace(' -',\" \")\n",
        "        eng=df.iloc[x][1]\n",
        "        eng = re.sub(r'[0-9]+', '', eng)\n",
        "        eng = cleaner(eng)\n",
        "        eng = eng.replace('- ',\" \")\n",
        "        eng = eng.replace(' -',\" \")\n",
        "        akk=akk[1:] if akk.startswith(\" \") else akk\n",
        "        eng=eng[1:] if eng.startswith(\" \") else eng\n",
        "        if akk=='' or \"lines\" in akk and \"lost\" in akk or \"fragmentary\" in akk:\n",
        "            continue\n",
        "        else:\n",
        "            text_output.append([akk,eng])\n",
        "    return text_output\n",
        "\n",
        "def grab_html(url,text_output):\n",
        "    error_flag=0\n",
        "    df = pd.read_html(url)\n",
        "    df=df[1]\n",
        "    temp_text = []\n",
        "    for x in range(0,len(df)):\n",
        "        tester=df.iloc[x][0]\n",
        "        tester = cleaner(tester)\n",
        "        if \"lines\" in tester and \"lost\" in tester or \"fragmentary\" in tester:\n",
        "            tester=\"\"\n",
        "        akk = re.split('([0123456789]+)', tester)\n",
        "        index=-1\n",
        "        while '' in akk:\n",
        "            akk.remove('')\n",
        "        while '-' in akk:\n",
        "            index = akk.index('-')\n",
        "            del akk[index]\n",
        "            del akk[index]\n",
        "            \n",
        "        tester=df.iloc[x][1]\n",
        "        tester = cleaner(tester)\n",
        "        if \"lines\" in tester and \"lost\" in tester or \"fragmentary\" in tester:\n",
        "            tester=\"\"\n",
        "        eng = re.split('([0123456789]+)', tester)\n",
        "        index=-1\n",
        "        while '' in eng:\n",
        "            eng.remove('')\n",
        "        while '-' in eng:\n",
        "            index = eng.index('-')\n",
        "            del eng[index]\n",
        "            del eng[index]\n",
        "        if len(akk)!=len(eng):\n",
        "            error_flag=1\n",
        "            break\n",
        "        for y in range(0,len(akk)):\n",
        "            if akk[y].isnumeric() or akk[y]=='':\n",
        "                continue\n",
        "            else:\n",
        "                akk[y]=akk[y][1:] if akk[y].startswith(\" \") else akk[y]\n",
        "                eng[y]=eng[y][1:] if eng[y].startswith(\" \") else eng[y]\n",
        "                akk[y]=akk[y][2:] if akk[y].startswith(\"’ \") else akk[y]\n",
        "                eng[y]=eng[y][2:] if eng[y].startswith(\"’ \") else eng[y]\n",
        "                temp_text.append([akk[y],eng[y]])\n",
        "    if error_flag==1:\n",
        "        return grab_html2(url,text_output)\n",
        "    else:\n",
        "        text_output.extend(temp_text)\n",
        "        return text_output"
      ],
      "id": "72f7f873",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Below is a loop scraping and collecting all the data from a list of URLs, originally the function would be able to grab each element from the home webpage but being archived by the way back machine each URL for a text needs to be specified.\n"
      ],
      "id": "4eb2f579"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "text = []\n",
        "urls=[\"https://web.archive.org/web/20220920202225/https://www.soas.ac.uk/baplar/recordings/ammi-ditnas-hymn-to-itar-read-by-k-hecker.html\",\"https://web.archive.org/web/20220920202226/https://www.soas.ac.uk/baplar/recordings/the-codex-hammurabi-prologue-i1-49-read-by-albert-naccache.html\",\"https://web.archive.org/web/20220920202223/https://www.soas.ac.uk/baplar/recordings/the-codex-hammurapi-epilogue-xlix-18-28-and-53-80-read-by-aage-westenholz.html\",\"https://web.archive.org/web/20220920202227/https://www.soas.ac.uk/baplar/recordings/the-epic-of-gilgame-old-babylonian-version-tablet-ii-lines-85-111-read-by-michael-streck.html\",\"https://web.archive.org/web/20220920202232/https://www.soas.ac.uk/baplar/recordings/the-epic-of-gilgame-old-babylonian-version-tablet-ii-lines-1-61-read-by-jacob-klein.html\",\"https://web.archive.org/web/20220920202229/https://www.soas.ac.uk/baplar/recordings/gilgamesh-x-huehnergard.html\",\"https://web.archive.org/web/20220920202226/https://www.soas.ac.uk/baplar/recordings/the-epic-of-gilgamesh-old-babylonian-version-bmvat-lines-ii0-iii14-read-by-martin-west.html\",\"https://web.archive.org/web/20220920202232/https://www.soas.ac.uk/baplar/recordings/the-epic-of-anz-old-babylonian-version-from-susa-tablet-ii-lines-1-83-read-by-claus-wilcke.html\",\"https://web.archive.org/web/20220920202229/https://www.soas.ac.uk/baplar/recordings/atramass-ob-version-from-sippir-tablet-i-lines-i1-iii16-read-by-claus-wilcke.html\",\"https://web.archive.org/web/20220920202231/https://www.soas.ac.uk/baplar/recordings/diviners-prayer-to-the-gods-of-the-night-read-by-michael-streck.html\",\"https://web.archive.org/web/20220920202228/https://www.soas.ac.uk/baplar/recordings/incantation-for-dog-bite-read-by-michael-streck.html\",\"https://web.archive.org/web/20220920202223/https://www.soas.ac.uk/baplar/recordings/letter-of-marduk-nir-to-ruttum-abb-iii-15-read-by-wilfred-van-soldt.html\",\"https://web.archive.org/web/20220920202225/https://www.soas.ac.uk/baplar/recordings/letter-of-kurkurtum-to-erb-sn-abb-xii-89-read-by-wilfred-van-soldt.html\",\"https://web.archive.org/web/20220920202230/https://www.soas.ac.uk/baplar/recordings/ob-letter-iddin-sin.html\",\"https://web.archive.org/web/20220920202225/https://www.soas.ac.uk/baplar/recordings/the-epic-of-gilgame-standard-version-tablet-xi-lines-1-163-read-by-karl-hecker.html\",\"https://web.archive.org/web/20220920202224/https://www.soas.ac.uk/baplar/recordings/the-poem-of-the-righteous-sufferer-ludlul-bl-nmeqi-tablet-ii-lines-1-26-and-56-82-read-by-brigitte-groneberg.html\",\"https://web.archive.org/web/20220920202229/https://www.soas.ac.uk/baplar/recordings/the-poem-of-the-righteous-sufferer-ludlul-bl-nmeqi-tablet-ii-lines-1-55-read-by-margaret-jaques-cavigneaux.html\",\"https://web.archive.org/web/20220920202231/https://www.soas.ac.uk/baplar/recordings/itars-descent-to-the-netherworld-lines-1-125-read-by-martin-west.html\",\"https://web.archive.org/web/20220920202231/https://www.soas.ac.uk/baplar/recordings/the-ama-hymn-lines-15-52-read-by-martin-west.html\"]\n",
        "for source in urls:\n",
        "    text = grab_html(source,text)\n",
        "        \n",
        "for x in range(0,10) : print(text[x])"
      ],
      "id": "e793da41",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here each is separating the Akkadian only text from the array. Each line or chunk is broken down into an array of words and then appended to a list of all the Akkadian words. Using the counter class it fills a dictionary with each word being a key and the value is that word's frequency. The graph displays on the x axis in order of theier frequency of usage of the first 12 words and the y-axis is how many times that word was used.\n"
      ],
      "id": "58b782c8"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "all_words = []\n",
        "akkadian=[i[0] for i in text]\n",
        "for z in range(0,len(akkadian)):\n",
        "    stuff = re.split(' ', akkadian[z])\n",
        "    all_words = all_words + stuff\n",
        "all_words=np.sort(all_words)\n",
        "all_words=all_words[all_words!='']\n",
        "elements_count = collections.Counter(all_words)\n",
        "print(\"In Akkadian there are \",len(all_words),\" and\",len(elements_count),\"of which are unique\")\n",
        "\n",
        "elements = sorted(elements_count.items(), key=lambda item: (-item[1], item[0]))\n",
        "elements_count=collections.OrderedDict(elements)\n",
        "index=0\n",
        "for key, value in elements_count.items():\n",
        "    index+=1\n",
        "    print(f\"{key}: {value}\")\n",
        "    if index > 11: break\n",
        "        \n",
        "specific_word = list(elements_count.keys())\n",
        "word_freq = list(elements_count.values())\n",
        "\n",
        "plt.bar(specific_word[:12], word_freq[:12])\n",
        "plt.show()"
      ],
      "id": "3febe476",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Below the same process was repeated for all of the English translations of the same lines. This is done as a control since the content should be nearly the same the word distribution should be similar if it follows Zipf law the same way English does.\n"
      ],
      "id": "f2c50ac5"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "all_words = []\n",
        "english=[i[1] for i in text]\n",
        "for z in range(0,len(english)):\n",
        "    stuff = re.split(' ', english[z])\n",
        "    all_words = all_words + stuff\n",
        "\n",
        "all_words=np.sort(all_words)\n",
        "all_words=all_words[all_words!='']\n",
        "elements_count = collections.Counter(all_words)\n",
        "print(\"In English there are \",len(all_words),\" and\",len(elements_count),\"of which are unique\")\n",
        "\n",
        "elements = sorted(elements_count.items(), key=lambda item: (-item[1], item[0]))\n",
        "elements_count=collections.OrderedDict(elements)\n",
        "index=0\n",
        "for key, value in elements_count.items():\n",
        "    index+=1\n",
        "    print(f\"{key}: {value}\")\n",
        "    if index > 11: break\n",
        "        \n",
        "specific_word = list(elements_count.keys())\n",
        "word_freq = list(elements_count.values())\n",
        "\n",
        "plt.bar(specific_word[:12], word_freq[:12])\n",
        "plt.show()"
      ],
      "id": "22995194",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The next area of calculation is finding the syllable count for the words and there will need to be separate functions for each language. Normally this would be very difficult if had the raw cuniform of Akkadian but since it is phonetic spelling there are no silent letters or special rules unique to that language\n"
      ],
      "id": "2f998a55"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def syllable_eng(word):\n",
        "    word = word.lower()\n",
        "    count = 0\n",
        "    vowels = \"aeiouy\"\n",
        "    if word[0] in vowels:\n",
        "        count += 1\n",
        "    for index in range(1, len(word)):\n",
        "        if word[index] in vowels and word[index - 1] not in vowels:\n",
        "            count += 1\n",
        "    if word.endswith(\"e\"):\n",
        "        count -= 1\n",
        "    if count == 0:\n",
        "        count += 1\n",
        "    return count\n",
        "def syllable_akk(word):\n",
        "    word = word.lower()\n",
        "    count = 0\n",
        "    vowels = \"īāîáâêeēíûaoūui\"\n",
        "    if word[0] in vowels:\n",
        "        count += 1\n",
        "    for index in range(1, len(word)):\n",
        "        if word[index] in vowels and word[index - 1] not in vowels:\n",
        "            count += 1\n",
        "    if count == 0:\n",
        "        count += 1\n",
        "    return count"
      ],
      "id": "b75aeb4f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here the average number of syllabls per word is calulated over all for each language showing that akkadian despite having many fewer words to describe the same concept they are longer and have more syllabuls. In the graph each dot represents a line or chunk of text the red in Akkadian and the blue in English\n"
      ],
      "id": "2bdecc02"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "akkadian=[i[0] for i in text]\n",
        "english=[i[1] for i in text]\n",
        "words_akk,syl_akk,words_eng,syl_eng=[],[],[],[]\n",
        "for line in  range(0,len(akkadian)):\n",
        "    words_akk.append(len(akkadian[line].split()))\n",
        "    syl_akk.append(syllable_akk(akkadian[line]))\n",
        "    words_eng.append(len(english[line].split()))\n",
        "    syl_eng.append(syllable_eng(english[line]))\n",
        "print(\"Average number of syllables per word Akkadian: \",(sum(syl_akk)/sum(words_akk)))\n",
        "print(\"Average number of syllables per word English: \", (sum(syl_eng)/sum(words_eng)))\n",
        "plt.plot(words_akk,syl_akk, 'o', color='red');\n",
        "plt.plot(words_eng,syl_eng, 'o', color='blue');\n",
        "plt.xlabel('Words per Line/Chunk')\n",
        "plt.ylabel('Syllables per Line/Chunk')\n",
        "plt.show()"
      ],
      "id": "219c3254",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}