<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.280">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Yan Shi">

<title>Text-as-Data Fall 2022 - Yan_Shi_blogpost3</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../images/DACSS_Round_Network.png" rel="icon" type="image/png">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>
<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>


<meta name="twitter:title" content="Text-as-Data Fall 2022 - Yan_Shi_blogpost3">
<meta name="twitter:description" content="There are some positive emoiton words associate with remote work tweet, such as love, best, great, flexible">
<meta name="twitter:creator" content="@UMassDACSS">
<meta name="twitter:site" content="@UMassDACSS">
<meta name="twitter:card" content="summary">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a href="../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../images/UMass White Wordmark Horiz.png" alt="" class="navbar-logo">
    </a>
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">Text-as-Data Fall 2022</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="https://dacss.github.io/Text_as_Data_Fall_2022/">
 <span class="menu-text">Fall 2022</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../about.html">
 <span class="menu-text">Contributors</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://umass.edu/sbs/dacss">
 <span class="menu-text">DACSS</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/DACSS/Text_as_Data_Fall_2022"><i class="bi bi-github" role="img" aria-label="GitHub">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
              <div class="quarto-toggle-container">
                  <a href="" class="quarto-color-scheme-toggle nav-link" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
              </div>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Yan_Shi_blogpost3</h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Yan Shi </p>
          </div>
  </div>
    
  
    
  </div>
  

</header>

<div class="cell" data-execution_count="74">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> nltk</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> re</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> string <span class="im">import</span> digits</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-execution_count="3">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># read twitter data with keyword remote work</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(<span class="st">'#all_remote_work_tweets(2019-2022).csv'</span>).drop(columns <span class="op">=</span> [<span class="st">'Unnamed: 0'</span>, <span class="st">'states'</span>, <span class="st">'index'</span>], axis <span class="op">=</span> <span class="dv">1</span>)</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>df.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="3">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>author_id</th>
      <th>username</th>
      <th>author_followers</th>
      <th>author_tweets</th>
      <th>author_description</th>
      <th>author_location</th>
      <th>text</th>
      <th>created_at</th>
      <th>geo_id</th>
      <th>retweets</th>
      <th>replies</th>
      <th>likes</th>
      <th>quote_count</th>
      <th>geo_name</th>
      <th>states_abbrev</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2729932651</td>
      <td>TwelveRivers12</td>
      <td>367</td>
      <td>1862</td>
      <td>We strive to raise the bar of what it means to...</td>
      <td>Austin, TX</td>
      <td>#WFH but make it fashion (Twelve Rivers fashio...</td>
      <td>2020-12-19 20:00:14+00:00</td>
      <td>c3f37afa9efcf94b</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>Austin, TX</td>
      <td>TX</td>
    </tr>
    <tr>
      <th>1</th>
      <td>483173029</td>
      <td>CarrieHOlerich</td>
      <td>2138</td>
      <td>88698</td>
      <td>Driven, passionate #Communications graduate.🎓📚...</td>
      <td>Nebraska, USA</td>
      <td>Late night evening #wfh vibes finish my evenin...</td>
      <td>2020-12-19 07:12:54+00:00</td>
      <td>0fc2e8f588955000</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>Johnny Goodman Golf Course</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>2</th>
      <td>389908361</td>
      <td>JuanC611</td>
      <td>214</td>
      <td>12248</td>
      <td>I'm a #BCB, craft beer drinkin #Kaskade listen...</td>
      <td>Oxnard, CA</td>
      <td>Step 2, in progress...\n#wfh #wfhlife @ Riverp...</td>
      <td>2020-12-19 02:56:54+00:00</td>
      <td>a3c0ae863771d69e</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>Oxnard, CA</td>
      <td>CA</td>
    </tr>
    <tr>
      <th>3</th>
      <td>737763400118198277</td>
      <td>MissionTXperts</td>
      <td>828</td>
      <td>1618</td>
      <td>Follow us on IG! @missiontxperts #FamousForExp...</td>
      <td>Mission, TX</td>
      <td>Congratulations on your graduation!!! Welcome ...</td>
      <td>2020-12-18 22:35:35+00:00</td>
      <td>77633125ba089dcb</td>
      <td>1</td>
      <td>1</td>
      <td>15</td>
      <td>1</td>
      <td>Mission, TX</td>
      <td>TX</td>
    </tr>
    <tr>
      <th>4</th>
      <td>522212036</td>
      <td>FitnessFoundry</td>
      <td>2693</td>
      <td>14002</td>
      <td>Award Winning Personal Trainer| EMT-B 🚑 NSCA-R...</td>
      <td>Boston and Malden, MA</td>
      <td>Part 2 #HomeWorkout \n\n#OldSchool Jumping Jac...</td>
      <td>2020-12-18 19:07:33+00:00</td>
      <td>75f5a403163f6f95</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>Malden, MA</td>
      <td>MA</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<div class="cell" data-execution_count="3">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># look at data type</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>df.info()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>&lt;class 'pandas.core.frame.DataFrame'&gt;
RangeIndex: 31965 entries, 0 to 31964
Data columns (total 15 columns):
 #   Column              Non-Null Count  Dtype 
---  ------              --------------  ----- 
 0   author_id           31965 non-null  int64 
 1   username            31958 non-null  object
 2   author_followers    31965 non-null  int64 
 3   author_tweets       31965 non-null  int64 
 4   author_description  30868 non-null  object
 5   author_location     30154 non-null  object
 6   text                31965 non-null  object
 7   created_at          31965 non-null  object
 8   geo_id              31965 non-null  object
 9   retweets            31965 non-null  int64 
 10  replies             31965 non-null  int64 
 11  likes               31965 non-null  int64 
 12  quote_count         31965 non-null  int64 
 13  geo_name            31965 non-null  object
 14  states_abbrev       30392 non-null  object
dtypes: int64(7), object(8)
memory usage: 3.7+ MB</code></pre>
</div>
</div>
<div class="cell" data-execution_count="4">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> string</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>string.punctuation</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> clean_text(text):</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>    <span class="co">'''</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="co">    text cleaning, remove numbers, url, punctuation, newline, special characters</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a><span class="co">    '''</span></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>    text <span class="op">=</span> text.lower()</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>    text <span class="op">=</span> <span class="st">''</span>.join([i <span class="cf">for</span> i <span class="kw">in</span> text <span class="cf">if</span> <span class="kw">not</span> i.isdigit()])</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>    text <span class="op">=</span> re.sub(<span class="st">'\[.*?\]'</span>, <span class="st">''</span>, text)</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>    text <span class="op">=</span> re.sub(<span class="st">'https?://\S+|www\.\S+'</span>, <span class="st">''</span>, text)</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>    text <span class="op">=</span> re.sub(<span class="st">'&lt;.*?&gt;+'</span>, <span class="st">''</span>, text)</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>    text <span class="op">=</span> re.sub(<span class="st">'[</span><span class="sc">%s</span><span class="st">]'</span> <span class="op">%</span> re.escape(string.punctuation), <span class="st">' '</span>, text)</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>    text <span class="op">=</span> re.sub(<span class="st">'</span><span class="ch">\n</span><span class="st">'</span>, <span class="st">''</span>, text)</span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>    tweet <span class="op">=</span> re.sub(<span class="st">'\w*\d\w*'</span>, <span class="st">''</span>, text)</span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>    clean_text <span class="op">=</span> re.sub(<span class="st">"@[A-Za-z0-9_]+"</span>,<span class="st">""</span>, tweet)</span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>    clean_text <span class="op">=</span> re.sub(<span class="st">"#[A-Za-z0-9_]+"</span>,<span class="st">""</span>, clean_text)</span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>    clean_text <span class="op">=</span> re.sub(<span class="vs">r'http\S+'</span>, <span class="st">''</span>, clean_text)</span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> clean_text</span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> text_preprocessing(text):</span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a>    <span class="co">'''</span></span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a><span class="co">    preprocessing text</span></span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a><span class="co">    '''</span></span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a>    tokenizer <span class="op">=</span> nltk.tokenize.RegexpTokenizer(<span class="vs">r'\w+'</span>)</span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true" tabindex="-1"></a>    nopunct <span class="op">=</span> clean_text(text)</span>
<span id="cb5-26"><a href="#cb5-26" aria-hidden="true" tabindex="-1"></a>    tokenized_text <span class="op">=</span> tokenizer.tokenize(nopunct)</span>
<span id="cb5-27"><a href="#cb5-27" aria-hidden="true" tabindex="-1"></a>    combined_text <span class="op">=</span> <span class="st">' '</span>.join(tokenized_text)</span>
<span id="cb5-28"><a href="#cb5-28" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> combined_text</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-execution_count="5">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'clean_text'</span>] <span class="op">=</span> df[<span class="st">'text'</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: text_preprocessing(x))</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>df</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="5">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>author_id</th>
      <th>username</th>
      <th>author_followers</th>
      <th>author_tweets</th>
      <th>author_description</th>
      <th>author_location</th>
      <th>text</th>
      <th>created_at</th>
      <th>geo_id</th>
      <th>retweets</th>
      <th>replies</th>
      <th>likes</th>
      <th>quote_count</th>
      <th>geo_name</th>
      <th>states_abbrev</th>
      <th>clean_text</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2729932651</td>
      <td>TwelveRivers12</td>
      <td>367</td>
      <td>1862</td>
      <td>We strive to raise the bar of what it means to...</td>
      <td>Austin, TX</td>
      <td>#WFH but make it fashion (Twelve Rivers fashio...</td>
      <td>2020-12-19 20:00:14+00:00</td>
      <td>c3f37afa9efcf94b</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>Austin, TX</td>
      <td>TX</td>
      <td>wfh but make it fashion twelve rivers fashion ...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>483173029</td>
      <td>CarrieHOlerich</td>
      <td>2138</td>
      <td>88698</td>
      <td>Driven, passionate #Communications graduate.🎓📚...</td>
      <td>Nebraska, USA</td>
      <td>Late night evening #wfh vibes finish my evenin...</td>
      <td>2020-12-19 07:12:54+00:00</td>
      <td>0fc2e8f588955000</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>Johnny Goodman Golf Course</td>
      <td>NaN</td>
      <td>late night evening wfh vibes finish my evening...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>389908361</td>
      <td>JuanC611</td>
      <td>214</td>
      <td>12248</td>
      <td>I'm a #BCB, craft beer drinkin #Kaskade listen...</td>
      <td>Oxnard, CA</td>
      <td>Step 2, in progress...\n#wfh #wfhlife @ Riverp...</td>
      <td>2020-12-19 02:56:54+00:00</td>
      <td>a3c0ae863771d69e</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>Oxnard, CA</td>
      <td>CA</td>
      <td>step in progress wfh wfhlife riverpark</td>
    </tr>
    <tr>
      <th>3</th>
      <td>737763400118198277</td>
      <td>MissionTXperts</td>
      <td>828</td>
      <td>1618</td>
      <td>Follow us on IG! @missiontxperts #FamousForExp...</td>
      <td>Mission, TX</td>
      <td>Congratulations on your graduation!!! Welcome ...</td>
      <td>2020-12-18 22:35:35+00:00</td>
      <td>77633125ba089dcb</td>
      <td>1</td>
      <td>1</td>
      <td>15</td>
      <td>1</td>
      <td>Mission, TX</td>
      <td>TX</td>
      <td>congratulations on your graduation welcome to ...</td>
    </tr>
    <tr>
      <th>4</th>
      <td>522212036</td>
      <td>FitnessFoundry</td>
      <td>2693</td>
      <td>14002</td>
      <td>Award Winning Personal Trainer| EMT-B 🚑 NSCA-R...</td>
      <td>Boston and Malden, MA</td>
      <td>Part 2 #HomeWorkout \n\n#OldSchool Jumping Jac...</td>
      <td>2020-12-18 19:07:33+00:00</td>
      <td>75f5a403163f6f95</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>Malden, MA</td>
      <td>MA</td>
      <td>part homeworkout oldschool jumping jack variat...</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>31960</th>
      <td>2398266878</td>
      <td>realNickWake</td>
      <td>395</td>
      <td>7586</td>
      <td>#Michiganian / #Michigander, Ardent #Capitalis...</td>
      <td>Michigan, USA</td>
      <td>@rstudley Open up businesses to determine what...</td>
      <td>2021-03-01 16:05:06+00:00</td>
      <td>6231ced9cc2b96aa</td>
      <td>2</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>Grandville, MI</td>
      <td>MI</td>
      <td>rstudley open up businesses to determine what ...</td>
    </tr>
    <tr>
      <th>31961</th>
      <td>1180842344</td>
      <td>ksgates__</td>
      <td>702</td>
      <td>7563</td>
      <td>Marketing &amp; Membership at LCC | @CMAA | Perman...</td>
      <td>NaN</td>
      <td>Gearing up for a busy spring welcoming new mem...</td>
      <td>2021-03-01 15:55:28+00:00</td>
      <td>27c45d804c777999</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>Kansas, USA</td>
      <td>KS</td>
      <td>gearing up for a busy spring welcoming new mem...</td>
    </tr>
    <tr>
      <th>31962</th>
      <td>17499112</td>
      <td>ahurwitz03</td>
      <td>207</td>
      <td>1796</td>
      <td>PSA: my new favorite color is green 💚 meow - U...</td>
      <td>Vermont</td>
      <td>Wearing carhartts today to pretend like I’m do...</td>
      <td>2021-03-01 13:28:16+00:00</td>
      <td>9aa25269f04766ab</td>
      <td>0</td>
      <td>0</td>
      <td>2</td>
      <td>0</td>
      <td>Vermont, USA</td>
      <td>VT</td>
      <td>wearing carhartts today to pretend like i m do...</td>
    </tr>
    <tr>
      <th>31963</th>
      <td>483173029</td>
      <td>CarrieHOlerich</td>
      <td>2141</td>
      <td>89128</td>
      <td>Driven, passionate #Communications graduate.🎓📚...</td>
      <td>Nebraska, USA</td>
      <td>If laying on the sofa laughing about Twtter du...</td>
      <td>2021-03-01 07:41:20+00:00</td>
      <td>a84b808ce3f11719</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>Omaha, NE</td>
      <td>NE</td>
      <td>if laying on the sofa laughing about twtter du...</td>
    </tr>
    <tr>
      <th>31964</th>
      <td>483173029</td>
      <td>CarrieHOlerich</td>
      <td>2141</td>
      <td>89128</td>
      <td>Driven, passionate #Communications graduate.🎓📚...</td>
      <td>Nebraska, USA</td>
      <td>Blasting some #Queen during #wfh\n👩‍💻 #myfirst...</td>
      <td>2021-03-01 00:18:24+00:00</td>
      <td>0fc2e8f588955000</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>Johnny Goodman Golf Course</td>
      <td>NaN</td>
      <td>blasting some queen during wfh myfirstconcert ...</td>
    </tr>
  </tbody>
</table>
<p>31965 rows × 16 columns</p>
</div>
</div>
</div>
<div class="cell" data-execution_count="6">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> nltk</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>nltk.download(<span class="st">'stopwords'</span>)</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk.corpus <span class="im">import</span> stopwords</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>STOPWORDS <span class="op">=</span> <span class="bu">set</span>(stopwords.words(<span class="st">'english'</span>))</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> remove_stopwords(text):</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""custom function to remove the stopwords"""</span></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="st">" "</span>.join([word <span class="cf">for</span> word <span class="kw">in</span> <span class="bu">str</span>(text).split() <span class="cf">if</span> word <span class="kw">not</span> <span class="kw">in</span> STOPWORDS])</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'no_stopwords_text'</span>] <span class="op">=</span> df[<span class="st">'clean_text'</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: remove_stopwords(x))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stderr">
<pre><code>[nltk_data] Downloading package stopwords to
[nltk_data]     /Users/yanshi/nltk_data...
[nltk_data]   Package stopwords is already up-to-date!</code></pre>
</div>
</div>
<div class="cell" data-execution_count="7">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>hashtag <span class="op">=</span> [<span class="st">'wfh'</span>, <span class="st">'remotework'</span>, <span class="st">'workfromhome'</span>, <span class="st">'workingfromhome'</span>, <span class="st">'remoteworking'</span>, <span class="st">'telecommuting'</span>]</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> remove_hashtag(text):</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="st">" "</span>.join([word <span class="cf">for</span> word <span class="kw">in</span> <span class="bu">str</span>(text).split() <span class="cf">if</span> word <span class="kw">not</span> <span class="kw">in</span> hashtag])</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'no_remotework_text'</span>] <span class="op">=</span> df[<span class="st">'no_stopwords_text'</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: remove_hashtag(x))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-execution_count="8">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> nltk</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>nltk.download(<span class="st">'wordnet'</span>)</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk.stem <span class="im">import</span> WordNetLemmatizer</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>lemmatizer <span class="op">=</span> WordNetLemmatizer()</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> lem_words(text):</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="st">" "</span>.join([lemmatizer.lemmatize(word) <span class="cf">for</span> word <span class="kw">in</span> text.split()])</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'lematize_text'</span>] <span class="op">=</span> df[<span class="st">'no_remotework_text'</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: lem_words(x))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stderr">
<pre><code>[nltk_data] Downloading package wordnet to /Users/yanshi/nltk_data...
[nltk_data]   Package wordnet is already up-to-date!</code></pre>
</div>
</div>
<div class="cell" data-execution_count="9">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>df.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="9">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>author_id</th>
      <th>username</th>
      <th>author_followers</th>
      <th>author_tweets</th>
      <th>author_description</th>
      <th>author_location</th>
      <th>text</th>
      <th>created_at</th>
      <th>geo_id</th>
      <th>retweets</th>
      <th>replies</th>
      <th>likes</th>
      <th>quote_count</th>
      <th>geo_name</th>
      <th>states_abbrev</th>
      <th>clean_text</th>
      <th>no_stopwords_text</th>
      <th>no_remotework_text</th>
      <th>lematize_text</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2729932651</td>
      <td>TwelveRivers12</td>
      <td>367</td>
      <td>1862</td>
      <td>We strive to raise the bar of what it means to...</td>
      <td>Austin, TX</td>
      <td>#WFH but make it fashion (Twelve Rivers fashio...</td>
      <td>2020-12-19 20:00:14+00:00</td>
      <td>c3f37afa9efcf94b</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>Austin, TX</td>
      <td>TX</td>
      <td>wfh but make it fashion twelve rivers fashion ...</td>
      <td>wfh make fashion twelve rivers fashion office ...</td>
      <td>make fashion twelve rivers fashion office big ...</td>
      <td>make fashion twelve river fashion office big g...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>483173029</td>
      <td>CarrieHOlerich</td>
      <td>2138</td>
      <td>88698</td>
      <td>Driven, passionate #Communications graduate.🎓📚...</td>
      <td>Nebraska, USA</td>
      <td>Late night evening #wfh vibes finish my evenin...</td>
      <td>2020-12-19 07:12:54+00:00</td>
      <td>0fc2e8f588955000</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>Johnny Goodman Golf Course</td>
      <td>NaN</td>
      <td>late night evening wfh vibes finish my evening...</td>
      <td>late night evening wfh vibes finish evening wf...</td>
      <td>late night evening vibes finish evening wfhlife</td>
      <td>late night evening vibe finish evening wfhlife</td>
    </tr>
    <tr>
      <th>2</th>
      <td>389908361</td>
      <td>JuanC611</td>
      <td>214</td>
      <td>12248</td>
      <td>I'm a #BCB, craft beer drinkin #Kaskade listen...</td>
      <td>Oxnard, CA</td>
      <td>Step 2, in progress...\n#wfh #wfhlife @ Riverp...</td>
      <td>2020-12-19 02:56:54+00:00</td>
      <td>a3c0ae863771d69e</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>Oxnard, CA</td>
      <td>CA</td>
      <td>step in progress wfh wfhlife riverpark</td>
      <td>step progress wfh wfhlife riverpark</td>
      <td>step progress wfhlife riverpark</td>
      <td>step progress wfhlife riverpark</td>
    </tr>
    <tr>
      <th>3</th>
      <td>737763400118198277</td>
      <td>MissionTXperts</td>
      <td>828</td>
      <td>1618</td>
      <td>Follow us on IG! @missiontxperts #FamousForExp...</td>
      <td>Mission, TX</td>
      <td>Congratulations on your graduation!!! Welcome ...</td>
      <td>2020-12-18 22:35:35+00:00</td>
      <td>77633125ba089dcb</td>
      <td>1</td>
      <td>1</td>
      <td>15</td>
      <td>1</td>
      <td>Mission, TX</td>
      <td>TX</td>
      <td>congratulations on your graduation welcome to ...</td>
      <td>congratulations graduation welcome missiontxpe...</td>
      <td>congratulations graduation welcome missiontxpe...</td>
      <td>congratulation graduation welcome missiontxper...</td>
    </tr>
    <tr>
      <th>4</th>
      <td>522212036</td>
      <td>FitnessFoundry</td>
      <td>2693</td>
      <td>14002</td>
      <td>Award Winning Personal Trainer| EMT-B 🚑 NSCA-R...</td>
      <td>Boston and Malden, MA</td>
      <td>Part 2 #HomeWorkout \n\n#OldSchool Jumping Jac...</td>
      <td>2020-12-18 19:07:33+00:00</td>
      <td>75f5a403163f6f95</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>Malden, MA</td>
      <td>MA</td>
      <td>part homeworkout oldschool jumping jack variat...</td>
      <td>part homeworkout oldschool jumping jack variat...</td>
      <td>part homeworkout oldschool jumping jack variat...</td>
      <td>part homeworkout oldschool jumping jack variat...</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<div class="cell" data-execution_count="10">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co">#generate word cloud</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>tweets <span class="op">=</span> <span class="st">''</span></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> tweet <span class="kw">in</span> df[<span class="st">'lematize_text'</span>].values:</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>    tweets <span class="op">+=</span> <span class="st">''</span>.join(tweet)<span class="op">+</span><span class="st">' '</span></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> wordcloud <span class="im">import</span> WordCloud</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>wordcloud <span class="op">=</span> WordCloud(width <span class="op">=</span> <span class="dv">800</span>, height <span class="op">=</span> <span class="dv">800</span>,</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>                background_color <span class="op">=</span><span class="st">'white'</span>,</span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>                min_font_size <span class="op">=</span> <span class="dv">10</span>).generate(tweets)</span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a><span class="co"># plot the WordCloud image                      </span></span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize <span class="op">=</span> (<span class="dv">8</span>, <span class="dv">8</span>), facecolor <span class="op">=</span> <span class="va">None</span>)</span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a>plt.imshow(wordcloud)</span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a>plt.axis(<span class="st">"off"</span>)</span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a>plt.tight_layout(pad <span class="op">=</span> <span class="dv">0</span>)</span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="Yan_Shi_blogpost3_files/figure-html/cell-11-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>There are some positive emoiton words associate with remote work tweet, such as love, best, great, flexible</p>
<div class="cell" data-execution_count="11">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> datetime <span class="im">import</span> datetime</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> datetime <span class="im">import</span> timedelta</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a><span class="co">#convert date str to datetime</span></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'date'</span>] <span class="op">=</span> df[<span class="st">'created_at'</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: datetime.strptime(x, <span class="st">'%Y-%m-</span><span class="sc">%d</span><span class="st"> %H:%M:%S%z'</span>).date())</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'month'</span>] <span class="op">=</span> df[<span class="st">'date'</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: x.year)</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'month'</span>] <span class="op">=</span> df[<span class="st">'date'</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: x.month)</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a><span class="co">#create new column indicate # of tweet</span></span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'tweet'</span>] <span class="op">=</span> <span class="dv">1</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-execution_count="48">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'Date'</span>] <span class="op">=</span> pd.to_datetime(df[<span class="st">'date'</span>], errors<span class="op">=</span><span class="st">'coerce'</span>)</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>per <span class="op">=</span> df.Date.dt.to_period(<span class="st">"M"</span>)</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>df_aggre <span class="op">=</span> df.groupby(per).<span class="bu">sum</span>()</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>df_aggre</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="48">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>author_id</th>
      <th>author_followers</th>
      <th>author_tweets</th>
      <th>retweets</th>
      <th>replies</th>
      <th>likes</th>
      <th>quote_count</th>
      <th>month</th>
      <th>tweet</th>
    </tr>
    <tr>
      <th>Date</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2019-03</th>
      <td>7.438393e+19</td>
      <td>343788.0</td>
      <td>2170734.0</td>
      <td>183.0</td>
      <td>47.0</td>
      <td>628.0</td>
      <td>17.0</td>
      <td>732</td>
      <td>244</td>
    </tr>
    <tr>
      <th>2019-04</th>
      <td>4.046708e+19</td>
      <td>928765.0</td>
      <td>3378692.0</td>
      <td>90.0</td>
      <td>41.0</td>
      <td>405.0</td>
      <td>17.0</td>
      <td>948</td>
      <td>237</td>
    </tr>
    <tr>
      <th>2019-05</th>
      <td>3.972946e+19</td>
      <td>352691.0</td>
      <td>2379015.0</td>
      <td>61.0</td>
      <td>38.0</td>
      <td>360.0</td>
      <td>6.0</td>
      <td>1145</td>
      <td>229</td>
    </tr>
    <tr>
      <th>2019-06</th>
      <td>4.395675e+19</td>
      <td>1183557.0</td>
      <td>7955395.0</td>
      <td>78.0</td>
      <td>37.0</td>
      <td>424.0</td>
      <td>3.0</td>
      <td>1584</td>
      <td>264</td>
    </tr>
    <tr>
      <th>2019-07</th>
      <td>3.932131e+19</td>
      <td>1360104.0</td>
      <td>18625242.0</td>
      <td>90.0</td>
      <td>75.0</td>
      <td>714.0</td>
      <td>8.0</td>
      <td>3269</td>
      <td>467</td>
    </tr>
    <tr>
      <th>2019-08</th>
      <td>4.410848e+19</td>
      <td>1357105.0</td>
      <td>6326535.0</td>
      <td>117.0</td>
      <td>71.0</td>
      <td>554.0</td>
      <td>10.0</td>
      <td>1784</td>
      <td>223</td>
    </tr>
    <tr>
      <th>2019-09</th>
      <td>3.765725e+19</td>
      <td>1002927.0</td>
      <td>3209900.0</td>
      <td>88.0</td>
      <td>62.0</td>
      <td>352.0</td>
      <td>9.0</td>
      <td>1926</td>
      <td>214</td>
    </tr>
    <tr>
      <th>2019-10</th>
      <td>3.544762e+19</td>
      <td>768274.0</td>
      <td>5372587.0</td>
      <td>84.0</td>
      <td>35.0</td>
      <td>312.0</td>
      <td>8.0</td>
      <td>2360</td>
      <td>236</td>
    </tr>
    <tr>
      <th>2019-11</th>
      <td>2.258816e+19</td>
      <td>1078118.0</td>
      <td>3426775.0</td>
      <td>44.0</td>
      <td>47.0</td>
      <td>501.0</td>
      <td>10.0</td>
      <td>1969</td>
      <td>179</td>
    </tr>
    <tr>
      <th>2019-12</th>
      <td>2.915014e+19</td>
      <td>1189362.0</td>
      <td>4754427.0</td>
      <td>57.0</td>
      <td>59.0</td>
      <td>405.0</td>
      <td>8.0</td>
      <td>2400</td>
      <td>200</td>
    </tr>
    <tr>
      <th>2020-01</th>
      <td>2.945092e+19</td>
      <td>3087824.0</td>
      <td>8221563.0</td>
      <td>85.0</td>
      <td>76.0</td>
      <td>747.0</td>
      <td>11.0</td>
      <td>217</td>
      <td>217</td>
    </tr>
    <tr>
      <th>2020-02</th>
      <td>4.105943e+19</td>
      <td>1584795.0</td>
      <td>5560972.0</td>
      <td>88.0</td>
      <td>35.0</td>
      <td>496.0</td>
      <td>12.0</td>
      <td>410</td>
      <td>205</td>
    </tr>
    <tr>
      <th>2020-03</th>
      <td>8.645601e+20</td>
      <td>48557156.0</td>
      <td>197921690.0</td>
      <td>3679.0</td>
      <td>3629.0</td>
      <td>36473.0</td>
      <td>694.0</td>
      <td>21543</td>
      <td>7181</td>
    </tr>
    <tr>
      <th>2020-04</th>
      <td>7.294542e+20</td>
      <td>46979898.0</td>
      <td>188548406.0</td>
      <td>3402.0</td>
      <td>2406.0</td>
      <td>26683.0</td>
      <td>609.0</td>
      <td>22436</td>
      <td>5609</td>
    </tr>
    <tr>
      <th>2020-05</th>
      <td>3.490690e+20</td>
      <td>30129569.0</td>
      <td>120193010.0</td>
      <td>1389.0</td>
      <td>993.0</td>
      <td>10803.0</td>
      <td>207.0</td>
      <td>12975</td>
      <td>2595</td>
    </tr>
    <tr>
      <th>2020-06</th>
      <td>1.649488e+20</td>
      <td>17943489.0</td>
      <td>70096650.0</td>
      <td>614.0</td>
      <td>341.0</td>
      <td>3838.0</td>
      <td>61.0</td>
      <td>7176</td>
      <td>1196</td>
    </tr>
    <tr>
      <th>2020-07</th>
      <td>1.955315e+20</td>
      <td>17309655.0</td>
      <td>63812046.0</td>
      <td>490.0</td>
      <td>440.0</td>
      <td>4229.0</td>
      <td>63.0</td>
      <td>9226</td>
      <td>1318</td>
    </tr>
    <tr>
      <th>2020-08</th>
      <td>1.570420e+20</td>
      <td>16645513.0</td>
      <td>60769499.0</td>
      <td>801.0</td>
      <td>557.0</td>
      <td>4891.0</td>
      <td>113.0</td>
      <td>9280</td>
      <td>1160</td>
    </tr>
    <tr>
      <th>2020-09</th>
      <td>1.735446e+20</td>
      <td>9439745.0</td>
      <td>41633450.0</td>
      <td>387.0</td>
      <td>383.0</td>
      <td>3638.0</td>
      <td>58.0</td>
      <td>9279</td>
      <td>1031</td>
    </tr>
    <tr>
      <th>2020-10</th>
      <td>1.817899e+20</td>
      <td>8768590.0</td>
      <td>40669344.0</td>
      <td>331.0</td>
      <td>317.0</td>
      <td>2722.0</td>
      <td>59.0</td>
      <td>9170</td>
      <td>917</td>
    </tr>
    <tr>
      <th>2020-11</th>
      <td>1.437103e+20</td>
      <td>7627941.0</td>
      <td>33446687.0</td>
      <td>376.0</td>
      <td>271.0</td>
      <td>3041.0</td>
      <td>79.0</td>
      <td>8426</td>
      <td>766</td>
    </tr>
    <tr>
      <th>2020-12</th>
      <td>1.083744e+20</td>
      <td>4819769.0</td>
      <td>22376433.0</td>
      <td>127.0</td>
      <td>199.0</td>
      <td>1636.0</td>
      <td>30.0</td>
      <td>6660</td>
      <td>555</td>
    </tr>
    <tr>
      <th>2021-03</th>
      <td>1.383146e+20</td>
      <td>3995683.0</td>
      <td>27766309.0</td>
      <td>323.0</td>
      <td>303.0</td>
      <td>2735.0</td>
      <td>45.0</td>
      <td>2274</td>
      <td>758</td>
    </tr>
    <tr>
      <th>2021-04</th>
      <td>9.634597e+19</td>
      <td>4755020.0</td>
      <td>27458348.0</td>
      <td>224.0</td>
      <td>224.0</td>
      <td>2369.0</td>
      <td>36.0</td>
      <td>2212</td>
      <td>553</td>
    </tr>
    <tr>
      <th>2021-05</th>
      <td>1.030695e+20</td>
      <td>9989706.0</td>
      <td>43211693.0</td>
      <td>240.0</td>
      <td>164.0</td>
      <td>1853.0</td>
      <td>40.0</td>
      <td>2615</td>
      <td>523</td>
    </tr>
    <tr>
      <th>2021-06</th>
      <td>8.698560e+19</td>
      <td>5177755.0</td>
      <td>24851971.0</td>
      <td>302.0</td>
      <td>105.0</td>
      <td>1221.0</td>
      <td>22.0</td>
      <td>2688</td>
      <td>448</td>
    </tr>
    <tr>
      <th>2021-07</th>
      <td>9.350160e+19</td>
      <td>4866449.0</td>
      <td>23239899.0</td>
      <td>258.0</td>
      <td>113.0</td>
      <td>1359.0</td>
      <td>45.0</td>
      <td>2807</td>
      <td>401</td>
    </tr>
    <tr>
      <th>2021-08</th>
      <td>1.433259e+20</td>
      <td>5569418.0</td>
      <td>28447352.0</td>
      <td>238.0</td>
      <td>150.0</td>
      <td>2016.0</td>
      <td>31.0</td>
      <td>3616</td>
      <td>452</td>
    </tr>
    <tr>
      <th>2021-09</th>
      <td>6.667617e+19</td>
      <td>5335971.0</td>
      <td>22639462.0</td>
      <td>233.0</td>
      <td>137.0</td>
      <td>1619.0</td>
      <td>24.0</td>
      <td>3276</td>
      <td>364</td>
    </tr>
    <tr>
      <th>2021-10</th>
      <td>7.075310e+19</td>
      <td>3572529.0</td>
      <td>14799941.0</td>
      <td>228.0</td>
      <td>94.0</td>
      <td>1899.0</td>
      <td>15.0</td>
      <td>2950</td>
      <td>295</td>
    </tr>
    <tr>
      <th>2021-11</th>
      <td>7.354641e+19</td>
      <td>2237299.0</td>
      <td>8141217.0</td>
      <td>100.0</td>
      <td>94.0</td>
      <td>997.0</td>
      <td>22.0</td>
      <td>2541</td>
      <td>231</td>
    </tr>
    <tr>
      <th>2021-12</th>
      <td>1.652327e+20</td>
      <td>3041139.0</td>
      <td>12163714.0</td>
      <td>147.0</td>
      <td>83.0</td>
      <td>1224.0</td>
      <td>14.0</td>
      <td>3804</td>
      <td>317</td>
    </tr>
    <tr>
      <th>2022-01</th>
      <td>9.561257e+19</td>
      <td>1813404.0</td>
      <td>7585565.0</td>
      <td>282.0</td>
      <td>155.0</td>
      <td>2202.0</td>
      <td>88.0</td>
      <td>284</td>
      <td>284</td>
    </tr>
    <tr>
      <th>2022-02</th>
      <td>9.447138e+19</td>
      <td>1969710.0</td>
      <td>9494066.0</td>
      <td>95.0</td>
      <td>91.0</td>
      <td>1017.0</td>
      <td>7.0</td>
      <td>488</td>
      <td>244</td>
    </tr>
    <tr>
      <th>2022-03</th>
      <td>1.105446e+20</td>
      <td>1445940.0</td>
      <td>6369174.0</td>
      <td>234.0</td>
      <td>108.0</td>
      <td>1714.0</td>
      <td>15.0</td>
      <td>807</td>
      <td>269</td>
    </tr>
    <tr>
      <th>2022-04</th>
      <td>8.211766e+19</td>
      <td>925590.0</td>
      <td>5163050.0</td>
      <td>171.0</td>
      <td>89.0</td>
      <td>1479.0</td>
      <td>20.0</td>
      <td>1016</td>
      <td>254</td>
    </tr>
    <tr>
      <th>2022-05</th>
      <td>9.748346e+19</td>
      <td>1218399.0</td>
      <td>4793837.0</td>
      <td>7125.0</td>
      <td>605.0</td>
      <td>36933.0</td>
      <td>1801.0</td>
      <td>1265</td>
      <td>253</td>
    </tr>
    <tr>
      <th>2022-06</th>
      <td>9.655524e+19</td>
      <td>2835914.0</td>
      <td>11209940.0</td>
      <td>193.0</td>
      <td>130.0</td>
      <td>1089.0</td>
      <td>25.0</td>
      <td>1548</td>
      <td>258</td>
    </tr>
    <tr>
      <th>2022-07</th>
      <td>9.918573e+19</td>
      <td>1771341.0</td>
      <td>8111514.0</td>
      <td>135.0</td>
      <td>113.0</td>
      <td>806.0</td>
      <td>14.0</td>
      <td>1715</td>
      <td>245</td>
    </tr>
    <tr>
      <th>2022-08</th>
      <td>1.049189e+20</td>
      <td>1783001.0</td>
      <td>7768621.0</td>
      <td>193.0</td>
      <td>107.0</td>
      <td>1428.0</td>
      <td>7.0</td>
      <td>2152</td>
      <td>269</td>
    </tr>
    <tr>
      <th>2022-09</th>
      <td>8.922183e+19</td>
      <td>869384.0</td>
      <td>3837078.0</td>
      <td>117.0</td>
      <td>142.0</td>
      <td>1294.0</td>
      <td>16.0</td>
      <td>2250</td>
      <td>250</td>
    </tr>
    <tr>
      <th>2022-10</th>
      <td>1.781892e+19</td>
      <td>417164.0</td>
      <td>1698870.0</td>
      <td>42.0</td>
      <td>21.0</td>
      <td>217.0</td>
      <td>3.0</td>
      <td>540</td>
      <td>54</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<div class="cell" data-scrolled="true" data-execution_count="56">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>df_aggre <span class="op">=</span> df_aggre.drop(columns <span class="op">=</span> [<span class="st">'author_id'</span>, <span class="st">'author_followers'</span>, <span class="st">'author_tweets'</span>, <span class="st">'month'</span>, <span class="st">'quote_count'</span>])</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a><span class="co">#df_aggre['date'] = df_aggre.index</span></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a><span class="co">#df_aggre = df_aggre.reset_index(drop = True)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-execution_count="50">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>df_aggre.index <span class="op">=</span> df_aggre.index.<span class="bu">map</span>(<span class="bu">str</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-execution_count="117">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="co">#general statistic for monthly data</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>df_aggre.describe()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="117">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>retweets</th>
      <th>replies</th>
      <th>likes</th>
      <th>quote_count</th>
      <th>#tweet</th>
      <th>tweet</th>
      <th>month</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>12.000000</td>
      <td>12.000000</td>
      <td>12.000000</td>
      <td>12.000000</td>
      <td>12.000000</td>
      <td>12.000000</td>
      <td>12.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>278.416667</td>
      <td>205.166667</td>
      <td>1941.166667</td>
      <td>45.916667</td>
      <td>339.166667</td>
      <td>339.166667</td>
      <td>6.500000</td>
    </tr>
    <tr>
      <th>std</th>
      <td>253.683216</td>
      <td>153.817385</td>
      <td>1768.247557</td>
      <td>33.494798</td>
      <td>282.504331</td>
      <td>282.504331</td>
      <td>3.605551</td>
    </tr>
    <tr>
      <th>min</th>
      <td>78.000000</td>
      <td>87.000000</td>
      <td>733.000000</td>
      <td>13.000000</td>
      <td>98.000000</td>
      <td>98.000000</td>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>115.000000</td>
      <td>122.750000</td>
      <td>776.000000</td>
      <td>23.250000</td>
      <td>180.500000</td>
      <td>180.500000</td>
      <td>3.750000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>184.500000</td>
      <td>169.500000</td>
      <td>1297.500000</td>
      <td>36.000000</td>
      <td>260.500000</td>
      <td>260.500000</td>
      <td>6.500000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>324.500000</td>
      <td>227.500000</td>
      <td>2176.000000</td>
      <td>66.500000</td>
      <td>402.250000</td>
      <td>402.250000</td>
      <td>9.250000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>977.000000</td>
      <td>664.000000</td>
      <td>6739.000000</td>
      <td>127.000000</td>
      <td>1160.000000</td>
      <td>1160.000000</td>
      <td>12.000000</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<div class="cell" data-execution_count="58">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="co">#simple plot data</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> column <span class="kw">in</span> df_aggre.columns:</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>    plt.figure(figsize<span class="op">=</span>(<span class="dv">40</span>, <span class="dv">5</span>))</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>    plt.subplot(<span class="dv">132</span>)</span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>    plt.plot(df_aggre[column],<span class="st">'r--'</span>)</span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>    plt.ylabel(column)</span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a>    plt.xlabel(<span class="st">'date'</span>)</span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a>    plt.tick_params(axis<span class="op">=</span><span class="st">'x'</span>, labelrotation <span class="op">=</span> <span class="dv">45</span>)</span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="st">'# of '</span><span class="op">+</span>column<span class="op">+</span><span class="st">' from 2019-2022'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="Yan_Shi_blogpost3_files/figure-html/cell-17-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="Yan_Shi_blogpost3_files/figure-html/cell-17-output-2.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="Yan_Shi_blogpost3_files/figure-html/cell-17-output-3.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="Yan_Shi_blogpost3_files/figure-html/cell-17-output-4.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-execution_count="52">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> datetime <span class="im">import</span> date</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>df_second_peak <span class="op">=</span> df[(date(<span class="dv">2022</span>, <span class="dv">3</span>, <span class="dv">1</span>)<span class="op">&lt;</span> df[<span class="st">'date'</span>]) <span class="op">&amp;</span> (df[<span class="st">'date'</span>] <span class="op">&lt;</span> date(<span class="dv">2022</span>, <span class="dv">6</span>, <span class="dv">1</span>))]</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>df_second_peak.info()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>&lt;class 'pandas.core.frame.DataFrame'&gt;
Int64Index: 768 entries, 25539 to 30069
Data columns (total 25 columns):
 #   Column              Non-Null Count  Dtype  
---  ------              --------------  -----  
 0   author_id           768 non-null    int64  
 1   username            768 non-null    object 
 2   author_followers    768 non-null    int64  
 3   author_tweets       768 non-null    int64  
 4   author_description  741 non-null    object 
 5   author_location     714 non-null    object 
 6   text                768 non-null    object 
 7   created_at          768 non-null    object 
 8   geo_id              768 non-null    object 
 9   retweets            768 non-null    int64  
 10  replies             768 non-null    int64  
 11  likes               768 non-null    int64  
 12  quote_count         768 non-null    int64  
 13  geo_name            768 non-null    object 
 14  states_abbrev       734 non-null    object 
 15  clean_text          768 non-null    object 
 16  no_stopwords_text   768 non-null    object 
 17  no_remotework_text  768 non-null    object 
 18  lematize_text       768 non-null    object 
 19  date                768 non-null    object 
 20  month               768 non-null    int64  
 21  tweet               768 non-null    int64  
 22  scores              768 non-null    object 
 23  compound_score      768 non-null    float64
 24  sentiment           768 non-null    object 
dtypes: float64(1), int64(9), object(15)
memory usage: 156.0+ KB</code></pre>
</div>
</div>
<div class="cell" data-execution_count="69">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="co"># topic model</span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> gensim</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> gensim.corpora <span class="im">as</span> corpora</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pprint <span class="im">import</span> pprint</span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pyLDAvis</span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pyLDAvis.gensim_models <span class="im">as</span> gensimvis</span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> gensim.corpora <span class="im">as</span> corpora</span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> sent_to_words(sentences):</span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a>    <span class="co">'''</span></span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a><span class="co">    tokenize words</span></span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a><span class="co">    '''</span></span>
<span id="cb22-12"><a href="#cb22-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> sentence <span class="kw">in</span> sentences:</span>
<span id="cb22-13"><a href="#cb22-13" aria-hidden="true" tabindex="-1"></a>        <span class="cf">yield</span>(gensim.utils.simple_preprocess(<span class="bu">str</span>(sentence), deacc<span class="op">=</span><span class="va">True</span>))            <span class="co">#deacc=True removes punctuations</span></span>
<span id="cb22-14"><a href="#cb22-14" aria-hidden="true" tabindex="-1"></a>data_words <span class="op">=</span> <span class="bu">list</span>(sent_to_words(df_second_peak[<span class="st">'lematize_text'</span>].values.tolist()))</span>
<span id="cb22-15"><a href="#cb22-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Create Dictionary</span></span>
<span id="cb22-16"><a href="#cb22-16" aria-hidden="true" tabindex="-1"></a>id2word <span class="op">=</span> corpora.Dictionary(data_words)</span>
<span id="cb22-17"><a href="#cb22-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Create Corpus</span></span>
<span id="cb22-18"><a href="#cb22-18" aria-hidden="true" tabindex="-1"></a>texts <span class="op">=</span> data_words</span>
<span id="cb22-19"><a href="#cb22-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Term Document Frequency</span></span>
<span id="cb22-20"><a href="#cb22-20" aria-hidden="true" tabindex="-1"></a>corpus <span class="op">=</span> [id2word.doc2bow(text) <span class="cf">for</span> text <span class="kw">in</span> texts]</span>
<span id="cb22-21"><a href="#cb22-21" aria-hidden="true" tabindex="-1"></a><span class="co"># number of topics</span></span>
<span id="cb22-22"><a href="#cb22-22" aria-hidden="true" tabindex="-1"></a>num_topics <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb22-23"><a href="#cb22-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Build LDA model</span></span>
<span id="cb22-24"><a href="#cb22-24" aria-hidden="true" tabindex="-1"></a>lda_model <span class="op">=</span> gensim.models.ldamodel.LdaModel(corpus<span class="op">=</span>corpus,</span>
<span id="cb22-25"><a href="#cb22-25" aria-hidden="true" tabindex="-1"></a>                                       id2word<span class="op">=</span>id2word,</span>
<span id="cb22-26"><a href="#cb22-26" aria-hidden="true" tabindex="-1"></a>                                       num_topics<span class="op">=</span>num_topics, </span>
<span id="cb22-27"><a href="#cb22-27" aria-hidden="true" tabindex="-1"></a>                                       random_state<span class="op">=</span><span class="dv">100</span>,</span>
<span id="cb22-28"><a href="#cb22-28" aria-hidden="true" tabindex="-1"></a>                                      update_every<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb22-29"><a href="#cb22-29" aria-hidden="true" tabindex="-1"></a>                                      chunksize<span class="op">=</span><span class="dv">100</span>,</span>
<span id="cb22-30"><a href="#cb22-30" aria-hidden="true" tabindex="-1"></a>                                      passes<span class="op">=</span><span class="dv">10</span>,</span>
<span id="cb22-31"><a href="#cb22-31" aria-hidden="true" tabindex="-1"></a>                                      alpha<span class="op">=</span><span class="st">'auto'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stderr">
<pre><code>INFO 2022-10-28 14:59:41,055 dictionary.py:201] adding document #0 to Dictionary&lt;0 unique tokens: []&gt;
INFO 2022-10-28 14:59:41,070 dictionary.py:206] built Dictionary&lt;4059 unique tokens: ['advice', 'blackintech', 'coding', 'comment', 'computerscience']...&gt; from 768 documents (total 10300 corpus positions)
INFO 2022-10-28 14:59:41,071 utils.py:448] Dictionary lifecycle event {'msg': "built Dictionary&lt;4059 unique tokens: ['advice', 'blackintech', 'coding', 'comment', 'computerscience']...&gt; from 768 documents (total 10300 corpus positions)", 'datetime': '2022-10-28T14:59:41.070998', 'gensim': '4.2.0', 'python': '3.9.7 (default, Sep 16 2021, 08:50:36) \n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}
INFO 2022-10-28 14:59:41,079 ldamodel.py:595] using autotuned alpha, starting with [0.2, 0.2, 0.2, 0.2, 0.2]
INFO 2022-10-28 14:59:41,079 ldamodel.py:576] using symmetric eta at 0.2
INFO 2022-10-28 14:59:41,080 ldamodel.py:481] using serial LDA version on this node
INFO 2022-10-28 14:59:41,083 ldamodel.py:947] running online (multi-pass) LDA training, 5 topics, 10 passes over the supplied corpus of 768 documents, updating model once every 100 documents, evaluating perplexity every 768 documents, iterating 50x with a convergence threshold of 0.001000
INFO 2022-10-28 14:59:41,083 ldamodel.py:1001] PROGRESS: pass 0, at document #100/768
INFO 2022-10-28 14:59:41,138 ldamodel.py:794] optimized alpha [0.15121561, 0.14029418, 0.13779749, 0.1766257, 0.14536503]
INFO 2022-10-28 14:59:41,139 ldamodel.py:233] merging changes from 100 documents into a model of 768 documents
INFO 2022-10-28 14:59:41,141 ldamodel.py:1196] topic #0 (0.151): 0.013*"edge" + 0.012*"amp" + 0.011*"dell" + 0.011*"remote" + 0.010*"work" + 0.009*"happen" + 0.009*"business" + 0.009*"tech" + 0.008*"make" + 0.008*"job"
INFO 2022-10-28 14:59:41,142 ldamodel.py:1196] topic #1 (0.140): 0.012*"work" + 0.011*"meeting" + 0.009*"coffee" + 0.008*"office" + 0.007*"see" + 0.007*"time" + 0.006*"need" + 0.006*"week" + 0.006*"fascinating" + 0.006*"hybridwork"
INFO 2022-10-28 14:59:41,142 ldamodel.py:1196] topic #2 (0.138): 0.011*"great" + 0.008*"amp" + 0.007*"job" + 0.006*"know" + 0.006*"edge" + 0.006*"remote" + 0.005*"park" + 0.005*"one" + 0.005*"java" + 0.005*"knowledge"
INFO 2022-10-28 14:59:41,143 ldamodel.py:1196] topic #3 (0.177): 0.023*"office" + 0.021*"remote" + 0.020*"work" + 0.009*"workplace" + 0.009*"amp" + 0.008*"today" + 0.007*"back" + 0.007*"airbnb" + 0.005*"great" + 0.005*"one"
INFO 2022-10-28 14:59:41,143 ldamodel.py:1196] topic #4 (0.145): 0.028*"california" + 0.013*"iphonography" + 0.013*"shotoniphone" + 0.013*"nature" + 0.013*"naturelovers" + 0.013*"mvt" + 0.011*"amp" + 0.008*"work" + 0.008*"milpitas" + 0.008*"autocruise"
INFO 2022-10-28 14:59:41,144 ldamodel.py:1074] topic diff=4.303751, rho=1.000000
INFO 2022-10-28 14:59:41,144 ldamodel.py:1001] PROGRESS: pass 0, at document #200/768
INFO 2022-10-28 14:59:41,183 ldamodel.py:794] optimized alpha [0.16121417, 0.15894547, 0.14214501, 0.18443114, 0.13119942]
INFO 2022-10-28 14:59:41,184 ldamodel.py:233] merging changes from 100 documents into a model of 768 documents
INFO 2022-10-28 14:59:41,186 ldamodel.py:1196] topic #0 (0.161): 0.015*"business" + 0.013*"workbnb" + 0.012*"work" + 0.011*"company" + 0.011*"job" + 0.011*"worker" + 0.010*"travel" + 0.010*"traveling" + 0.009*"life" + 0.009*"futureofwork"
INFO 2022-10-28 14:59:41,187 ldamodel.py:1196] topic #1 (0.159): 0.019*"work" + 0.013*"meeting" + 0.011*"time" + 0.010*"home" + 0.007*"office" + 0.007*"much" + 0.007*"internet" + 0.007*"coffee" + 0.006*"call" + 0.006*"experience"
INFO 2022-10-28 14:59:41,187 ldamodel.py:1196] topic #2 (0.142): 0.009*"entrepreneur" + 0.009*"blackintech" + 0.008*"amp" + 0.007*"long" + 0.007*"know" + 0.006*"day" + 0.006*"coming" + 0.006*"texas" + 0.006*"job" + 0.005*"one"
INFO 2022-10-28 14:59:41,188 ldamodel.py:1196] topic #3 (0.184): 0.036*"work" + 0.024*"remote" + 0.016*"office" + 0.015*"home" + 0.010*"job" + 0.009*"anywhere" + 0.008*"back" + 0.008*"working" + 0.007*"startup" + 0.007*"available"
INFO 2022-10-28 14:59:41,188 ldamodel.py:1196] topic #4 (0.131): 0.013*"california" + 0.010*"change" + 0.010*"grateful" + 0.009*"work" + 0.008*"lake" + 0.007*"able" + 0.007*"corporate" + 0.007*"amp" + 0.006*"many" + 0.006*"family"
INFO 2022-10-28 14:59:41,189 ldamodel.py:1074] topic diff=0.698342, rho=0.707107
INFO 2022-10-28 14:59:41,189 ldamodel.py:1001] PROGRESS: pass 0, at document #300/768
INFO 2022-10-28 14:59:41,226 ldamodel.py:794] optimized alpha [0.15998477, 0.16423175, 0.16239658, 0.18531369, 0.13525054]
INFO 2022-10-28 14:59:41,227 ldamodel.py:233] merging changes from 100 documents into a model of 768 documents
INFO 2022-10-28 14:59:41,229 ldamodel.py:1196] topic #0 (0.160): 0.021*"business" + 0.020*"work" + 0.011*"career" + 0.011*"dream" + 0.011*"like" + 0.011*"goal" + 0.010*"mentorship" + 0.010*"workathome" + 0.010*"profit" + 0.010*"finance"
INFO 2022-10-28 14:59:41,229 ldamodel.py:1196] topic #1 (0.164): 0.027*"work" + 0.015*"home" + 0.014*"time" + 0.012*"coffee" + 0.011*"meeting" + 0.011*"nowhiring" + 0.009*"usa" + 0.009*"california" + 0.008*"got" + 0.006*"choose"
INFO 2022-10-28 14:59:41,230 ldamodel.py:1196] topic #2 (0.162): 0.015*"entrepreneur" + 0.012*"follow" + 0.011*"day" + 0.010*"morning" + 0.009*"long" + 0.009*"job" + 0.009*"let" + 0.008*"realestate" + 0.008*"place" + 0.007*"home"
INFO 2022-10-28 14:59:41,230 ldamodel.py:1196] topic #3 (0.185): 0.049*"work" + 0.024*"home" + 0.015*"office" + 0.012*"remote" + 0.010*"like" + 0.009*"back" + 0.008*"comfort" + 0.008*"vacation" + 0.007*"today" + 0.007*"still"
INFO 2022-10-28 14:59:41,231 ldamodel.py:1196] topic #4 (0.135): 0.018*"california" + 0.009*"work" + 0.007*"home" + 0.007*"good" + 0.006*"time" + 0.006*"corporate" + 0.006*"amp" + 0.006*"thing" + 0.006*"grateful" + 0.005*"day"
INFO 2022-10-28 14:59:41,232 ldamodel.py:1074] topic diff=0.608546, rho=0.577350
INFO 2022-10-28 14:59:41,232 ldamodel.py:1001] PROGRESS: pass 0, at document #400/768
INFO 2022-10-28 14:59:41,265 ldamodel.py:794] optimized alpha [0.16158435, 0.17259955, 0.17474662, 0.21464582, 0.13420783]
INFO 2022-10-28 14:59:41,266 ldamodel.py:233] merging changes from 100 documents into a model of 768 documents
INFO 2022-10-28 14:59:41,268 ldamodel.py:1196] topic #0 (0.162): 0.021*"love" + 0.017*"work" + 0.015*"business" + 0.011*"saturday" + 0.011*"good" + 0.010*"get" + 0.009*"dream" + 0.008*"life" + 0.008*"go" + 0.008*"today"
INFO 2022-10-28 14:59:41,268 ldamodel.py:1196] topic #1 (0.173): 0.018*"work" + 0.015*"time" + 0.012*"home" + 0.009*"need" + 0.009*"meeting" + 0.008*"much" + 0.008*"coffee" + 0.007*"today" + 0.007*"california" + 0.007*"got"
INFO 2022-10-28 14:59:41,269 ldamodel.py:1196] topic #2 (0.175): 0.015*"entrepreneur" + 0.014*"day" + 0.012*"sunday" + 0.012*"job" + 0.011*"realestate" + 0.010*"let" + 0.009*"morning" + 0.008*"check" + 0.008*"businessowner" + 0.007*"follow"
INFO 2022-10-28 14:59:41,270 ldamodel.py:1196] topic #3 (0.215): 0.032*"work" + 0.021*"home" + 0.019*"office" + 0.011*"back" + 0.011*"today" + 0.009*"monday" + 0.009*"new" + 0.009*"like" + 0.008*"thursday" + 0.007*"working"
INFO 2022-10-28 14:59:41,270 ldamodel.py:1196] topic #4 (0.134): 0.019*"california" + 0.009*"group" + 0.008*"good" + 0.008*"home" + 0.008*"sold" + 0.007*"ready" + 0.007*"amazing" + 0.006*"listed" + 0.006*"realestateagent" + 0.006*"souza"
INFO 2022-10-28 14:59:41,271 ldamodel.py:1074] topic diff=0.594212, rho=0.500000
INFO 2022-10-28 14:59:41,271 ldamodel.py:1001] PROGRESS: pass 0, at document #500/768
INFO 2022-10-28 14:59:41,308 ldamodel.py:794] optimized alpha [0.1681245, 0.18190226, 0.17842254, 0.22165008, 0.1390742]
INFO 2022-10-28 14:59:41,310 ldamodel.py:233] merging changes from 100 documents into a model of 768 documents
INFO 2022-10-28 14:59:41,311 ldamodel.py:1196] topic #0 (0.168): 0.018*"love" + 0.017*"work" + 0.011*"business" + 0.010*"life" + 0.010*"trying" + 0.010*"get" + 0.009*"job" + 0.009*"go" + 0.008*"make" + 0.008*"good"
INFO 2022-10-28 14:59:41,312 ldamodel.py:1196] topic #1 (0.182): 0.019*"work" + 0.015*"time" + 0.012*"home" + 0.012*"need" + 0.008*"meeting" + 0.007*"today" + 0.007*"much" + 0.007*"zoom" + 0.007*"get" + 0.007*"even"</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>INFO 2022-10-28 14:59:41,313 ldamodel.py:1196] topic #2 (0.178): 0.015*"job" + 0.014*"realestate" + 0.013*"entrepreneur" + 0.013*"day" + 0.013*"another" + 0.009*"sunday" + 0.007*"morning" + 0.007*"way" + 0.006*"home" + 0.006*"let"
INFO 2022-10-28 14:59:41,314 ldamodel.py:1196] topic #3 (0.222): 0.036*"work" + 0.021*"home" + 0.016*"office" + 0.011*"working" + 0.011*"today" + 0.009*"back" + 0.009*"like" + 0.007*"new" + 0.007*"still" + 0.006*"week"
INFO 2022-10-28 14:59:41,314 ldamodel.py:1196] topic #4 (0.139): 0.013*"california" + 0.011*"done" + 0.011*"home" + 0.010*"group" + 0.010*"sold" + 0.010*"ready" + 0.009*"souza" + 0.009*"homesales" + 0.009*"listed" + 0.009*"soldgetting"
INFO 2022-10-28 14:59:41,315 ldamodel.py:1074] topic diff=0.520142, rho=0.447214
INFO 2022-10-28 14:59:41,315 ldamodel.py:1001] PROGRESS: pass 0, at document #600/768
INFO 2022-10-28 14:59:41,351 ldamodel.py:794] optimized alpha [0.17977357, 0.20402989, 0.17562437, 0.24766779, 0.14495757]
INFO 2022-10-28 14:59:41,352 ldamodel.py:233] merging changes from 100 documents into a model of 768 documents
INFO 2022-10-28 14:59:41,353 ldamodel.py:1196] topic #0 (0.180): 0.015*"go" + 0.015*"love" + 0.014*"work" + 0.012*"life" + 0.010*"trying" + 0.010*"get" + 0.010*"make" + 0.008*"today" + 0.007*"job" + 0.007*"day"
INFO 2022-10-28 14:59:41,354 ldamodel.py:1196] topic #1 (0.204): 0.015*"work" + 0.014*"time" + 0.012*"meeting" + 0.011*"need" + 0.010*"home" + 0.009*"today" + 0.008*"much" + 0.007*"get" + 0.006*"zoom" + 0.006*"win"
INFO 2022-10-28 14:59:41,355 ldamodel.py:1196] topic #2 (0.176): 0.015*"job" + 0.010*"day" + 0.009*"realestate" + 0.009*"entrepreneur" + 0.009*"another" + 0.008*"way" + 0.008*"let" + 0.007*"think" + 0.006*"long" + 0.006*"sunday"
INFO 2022-10-28 14:59:41,355 ldamodel.py:1196] topic #3 (0.248): 0.029*"work" + 0.020*"home" + 0.020*"office" + 0.016*"working" + 0.015*"today" + 0.009*"new" + 0.008*"like" + 0.008*"day" + 0.008*"back" + 0.007*"one"
INFO 2022-10-28 14:59:41,356 ldamodel.py:1196] topic #4 (0.145): 0.015*"california" + 0.011*"done" + 0.010*"home" + 0.008*"covid" + 0.007*"work" + 0.007*"group" + 0.006*"sold" + 0.006*"ready" + 0.006*"day" + 0.006*"angeles"
INFO 2022-10-28 14:59:41,357 ldamodel.py:1074] topic diff=0.611343, rho=0.408248
INFO 2022-10-28 14:59:41,357 ldamodel.py:1001] PROGRESS: pass 0, at document #700/768
INFO 2022-10-28 14:59:41,392 ldamodel.py:794] optimized alpha [0.18869899, 0.21525112, 0.17533925, 0.28178075, 0.14962877]
INFO 2022-10-28 14:59:41,393 ldamodel.py:233] merging changes from 100 documents into a model of 768 documents
INFO 2022-10-28 14:59:41,395 ldamodel.py:1196] topic #0 (0.189): 0.015*"work" + 0.013*"love" + 0.013*"go" + 0.011*"get" + 0.010*"today" + 0.010*"life" + 0.009*"day" + 0.007*"year" + 0.007*"job" + 0.007*"make"
INFO 2022-10-28 14:59:41,395 ldamodel.py:1196] topic #1 (0.215): 0.013*"work" + 0.013*"time" + 0.013*"meeting" + 0.011*"need" + 0.009*"home" + 0.008*"get" + 0.007*"first" + 0.007*"today" + 0.006*"zoom" + 0.006*"little"
INFO 2022-10-28 14:59:41,396 ldamodel.py:1196] topic #2 (0.175): 0.010*"job" + 0.009*"think" + 0.009*"tuesday" + 0.008*"way" + 0.008*"day" + 0.008*"spring" + 0.007*"long" + 0.007*"let" + 0.006*"realestate" + 0.006*"hybrid"
INFO 2022-10-28 14:59:41,397 ldamodel.py:1196] topic #3 (0.282): 0.028*"work" + 0.022*"office" + 0.020*"home" + 0.016*"working" + 0.014*"today" + 0.010*"day" + 0.010*"back" + 0.009*"thing" + 0.009*"one" + 0.008*"new"
INFO 2022-10-28 14:59:41,397 ldamodel.py:1196] topic #4 (0.150): 0.014*"california" + 0.010*"employee" + 0.009*"done" + 0.008*"going" + 0.008*"corporate" + 0.007*"work" + 0.007*"home" + 0.006*"angeles" + 0.006*"los" + 0.006*"year"
INFO 2022-10-28 14:59:41,397 ldamodel.py:1074] topic diff=0.558420, rho=0.377964
INFO 2022-10-28 14:59:41,424 ldamodel.py:847] -10.448 per-word bound, 1396.7 perplexity estimate based on a held-out corpus of 68 documents with 815 words
INFO 2022-10-28 14:59:41,425 ldamodel.py:1001] PROGRESS: pass 0, at document #768/768
INFO 2022-10-28 14:59:41,445 ldamodel.py:794] optimized alpha [0.1996359, 0.22733627, 0.18495363, 0.31522462, 0.14613664]
INFO 2022-10-28 14:59:41,446 ldamodel.py:233] merging changes from 68 documents into a model of 768 documents
INFO 2022-10-28 14:59:41,447 ldamodel.py:1196] topic #0 (0.200): 0.015*"go" + 0.014*"life" + 0.013*"work" + 0.012*"love" + 0.010*"make" + 0.010*"would" + 0.009*"day" + 0.008*"get" + 0.008*"today" + 0.007*"job"
INFO 2022-10-28 14:59:41,448 ldamodel.py:1196] topic #1 (0.227): 0.014*"time" + 0.012*"meeting" + 0.011*"work" + 0.010*"need" + 0.010*"zoom" + 0.010*"team" + 0.008*"home" + 0.007*"coffee" + 0.007*"got" + 0.006*"even"
INFO 2022-10-28 14:59:41,449 ldamodel.py:1196] topic #2 (0.185): 0.010*"morning" + 0.009*"day" + 0.009*"way" + 0.008*"job" + 0.008*"think" + 0.008*"long" + 0.008*"let" + 0.007*"another" + 0.007*"spring" + 0.006*"open"
INFO 2022-10-28 14:59:41,449 ldamodel.py:1196] topic #3 (0.315): 0.025*"work" + 0.024*"office" + 0.018*"home" + 0.017*"day" + 0.015*"back" + 0.013*"working" + 0.012*"new" + 0.010*"today" + 0.010*"one" + 0.007*"want"
INFO 2022-10-28 14:59:41,450 ldamodel.py:1196] topic #4 (0.146): 0.014*"california" + 0.011*"employee" + 0.010*"covid" + 0.008*"beach" + 0.007*"done" + 0.007*"going" + 0.006*"year" + 0.005*"corporate" + 0.005*"lunchtime" + 0.005*"work"
INFO 2022-10-28 14:59:41,450 ldamodel.py:1074] topic diff=0.476088, rho=0.353553
INFO 2022-10-28 14:59:41,451 ldamodel.py:1001] PROGRESS: pass 1, at document #100/768
INFO 2022-10-28 14:59:41,477 ldamodel.py:794] optimized alpha [0.18810043, 0.20171675, 0.17305338, 0.29309604, 0.14138676]
INFO 2022-10-28 14:59:41,478 ldamodel.py:233] merging changes from 100 documents into a model of 768 documents
INFO 2022-10-28 14:59:41,479 ldamodel.py:1196] topic #0 (0.188): 0.012*"work" + 0.011*"go" + 0.010*"life" + 0.010*"make" + 0.009*"love" + 0.008*"job" + 0.008*"people" + 0.007*"would" + 0.007*"amp" + 0.007*"business"
INFO 2022-10-28 14:59:41,480 ldamodel.py:1196] topic #1 (0.202): 0.012*"meeting" + 0.012*"time" + 0.012*"work" + 0.010*"need" + 0.008*"team" + 0.008*"zoom" + 0.008*"coffee" + 0.006*"home" + 0.006*"even" + 0.006*"see"
INFO 2022-10-28 14:59:41,481 ldamodel.py:1196] topic #2 (0.173): 0.010*"morning" + 0.008*"job" + 0.007*"way" + 0.006*"day" + 0.006*"another" + 0.006*"great" + 0.006*"world" + 0.006*"think" + 0.006*"long" + 0.006*"let"
INFO 2022-10-28 14:59:41,482 ldamodel.py:1196] topic #3 (0.293): 0.026*"office" + 0.025*"work" + 0.014*"home" + 0.013*"back" + 0.012*"day" + 0.011*"working" + 0.011*"new" + 0.010*"today" + 0.010*"remote" + 0.008*"one"
INFO 2022-10-28 14:59:41,482 ldamodel.py:1196] topic #4 (0.141): 0.022*"california" + 0.008*"park" + 0.008*"employee" + 0.007*"nature" + 0.007*"beach" + 0.007*"iphonography" + 0.007*"shotoniphone" + 0.007*"naturelovers" + 0.007*"mvt" + 0.006*"covid"
INFO 2022-10-28 14:59:41,483 ldamodel.py:1074] topic diff=0.450895, rho=0.321412
INFO 2022-10-28 14:59:41,483 ldamodel.py:1001] PROGRESS: pass 1, at document #200/768
INFO 2022-10-28 14:59:41,506 ldamodel.py:794] optimized alpha [0.1910355, 0.20958474, 0.17600764, 0.2929079, 0.1375881]
INFO 2022-10-28 14:59:41,507 ldamodel.py:233] merging changes from 100 documents into a model of 768 documents
INFO 2022-10-28 14:59:41,509 ldamodel.py:1196] topic #0 (0.191): 0.012*"work" + 0.011*"business" + 0.011*"life" + 0.010*"job" + 0.009*"company" + 0.009*"go" + 0.009*"make" + 0.008*"people" + 0.007*"workbnb" + 0.007*"travel"
INFO 2022-10-28 14:59:41,509 ldamodel.py:1196] topic #1 (0.210): 0.016*"work" + 0.013*"meeting" + 0.013*"time" + 0.009*"home" + 0.008*"need" + 0.007*"zoom" + 0.007*"coffee" + 0.006*"team" + 0.006*"much" + 0.006*"even"
INFO 2022-10-28 14:59:41,510 ldamodel.py:1196] topic #2 (0.176): 0.009*"morning" + 0.008*"job" + 0.008*"think" + 0.007*"another" + 0.007*"long" + 0.007*"day" + 0.006*"amp" + 0.006*"open" + 0.006*"way" + 0.006*"let"
INFO 2022-10-28 14:59:41,511 ldamodel.py:1196] topic #3 (0.293): 0.031*"work" + 0.023*"office" + 0.016*"home" + 0.013*"remote" + 0.013*"working" + 0.012*"day" + 0.011*"back" + 0.009*"new" + 0.007*"today" + 0.007*"like"
INFO 2022-10-28 14:59:41,511 ldamodel.py:1196] topic #4 (0.138): 0.017*"california" + 0.008*"change" + 0.007*"grateful" + 0.007*"beach" + 0.006*"corporate" + 0.006*"park" + 0.006*"family" + 0.005*"employee" + 0.005*"able" + 0.005*"nature"</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>INFO 2022-10-28 14:59:41,511 ldamodel.py:1074] topic diff=0.438547, rho=0.321412
INFO 2022-10-28 14:59:41,512 ldamodel.py:1001] PROGRESS: pass 1, at document #300/768
INFO 2022-10-28 14:59:41,537 ldamodel.py:794] optimized alpha [0.1882309, 0.20935552, 0.18632987, 0.27986538, 0.14232595]
INFO 2022-10-28 14:59:41,538 ldamodel.py:233] merging changes from 100 documents into a model of 768 documents
INFO 2022-10-28 14:59:41,539 ldamodel.py:1196] topic #0 (0.188): 0.017*"work" + 0.016*"business" + 0.009*"career" + 0.009*"money" + 0.009*"dream" + 0.009*"life" + 0.009*"love" + 0.008*"like" + 0.008*"company" + 0.008*"job"
INFO 2022-10-28 14:59:41,539 ldamodel.py:1196] topic #1 (0.209): 0.021*"work" + 0.014*"time" + 0.012*"meeting" + 0.011*"home" + 0.010*"coffee" + 0.007*"got" + 0.007*"nowhiring" + 0.007*"need" + 0.006*"team" + 0.006*"much"
INFO 2022-10-28 14:59:41,540 ldamodel.py:1196] topic #2 (0.186): 0.012*"morning" + 0.010*"day" + 0.009*"long" + 0.009*"entrepreneur" + 0.008*"follow" + 0.008*"let" + 0.007*"realestate" + 0.007*"job" + 0.007*"place" + 0.006*"think"
INFO 2022-10-28 14:59:41,540 ldamodel.py:1196] topic #3 (0.280): 0.040*"work" + 0.022*"office" + 0.021*"home" + 0.011*"working" + 0.011*"back" + 0.011*"like" + 0.010*"remote" + 0.009*"day" + 0.008*"today" + 0.008*"new"
INFO 2022-10-28 14:59:41,541 ldamodel.py:1196] topic #4 (0.142): 0.022*"california" + 0.008*"home" + 0.007*"done" + 0.006*"group" + 0.006*"sold" + 0.006*"corporate" + 0.006*"soldgetting" + 0.006*"listed" + 0.006*"realestateagent" + 0.006*"souza"
INFO 2022-10-28 14:59:41,541 ldamodel.py:1074] topic diff=0.399238, rho=0.321412
INFO 2022-10-28 14:59:41,542 ldamodel.py:1001] PROGRESS: pass 1, at document #400/768
INFO 2022-10-28 14:59:41,564 ldamodel.py:794] optimized alpha [0.18479933, 0.21177283, 0.19334303, 0.30272394, 0.13953488]
INFO 2022-10-28 14:59:41,565 ldamodel.py:233] merging changes from 100 documents into a model of 768 documents
INFO 2022-10-28 14:59:41,567 ldamodel.py:1196] topic #0 (0.185): 0.016*"love" + 0.015*"work" + 0.012*"business" + 0.010*"go" + 0.009*"good" + 0.009*"life" + 0.009*"get" + 0.009*"job" + 0.008*"dream" + 0.008*"saturday"
INFO 2022-10-28 14:59:41,567 ldamodel.py:1196] topic #1 (0.212): 0.016*"work" + 0.015*"time" + 0.011*"home" + 0.011*"meeting" + 0.010*"need" + 0.008*"much" + 0.008*"coffee" + 0.007*"got" + 0.007*"even" + 0.006*"zoom"
INFO 2022-10-28 14:59:41,568 ldamodel.py:1196] topic #2 (0.193): 0.011*"entrepreneur" + 0.011*"morning" + 0.010*"day" + 0.010*"realestate" + 0.010*"let" + 0.010*"sunday" + 0.008*"job" + 0.007*"check" + 0.007*"long" + 0.006*"follow"
INFO 2022-10-28 14:59:41,568 ldamodel.py:1196] topic #3 (0.303): 0.032*"work" + 0.021*"office" + 0.020*"home" + 0.011*"back" + 0.010*"day" + 0.010*"today" + 0.010*"like" + 0.010*"working" + 0.009*"new" + 0.008*"monday"
INFO 2022-10-28 14:59:41,569 ldamodel.py:1196] topic #4 (0.140): 0.021*"california" + 0.010*"home" + 0.010*"group" + 0.009*"sold" + 0.008*"done" + 0.007*"souza" + 0.007*"listed" + 0.007*"homesales" + 0.007*"soldgetting" + 0.007*"realestateagent"
INFO 2022-10-28 14:59:41,569 ldamodel.py:1074] topic diff=0.388357, rho=0.321412
INFO 2022-10-28 14:59:41,570 ldamodel.py:1001] PROGRESS: pass 1, at document #500/768
INFO 2022-10-28 14:59:41,590 ldamodel.py:794] optimized alpha [0.18758786, 0.21469162, 0.1944635, 0.2999581, 0.14217678]
INFO 2022-10-28 14:59:41,591 ldamodel.py:233] merging changes from 100 documents into a model of 768 documents
INFO 2022-10-28 14:59:41,593 ldamodel.py:1196] topic #0 (0.188): 0.015*"work" + 0.015*"love" + 0.010*"business" + 0.010*"life" + 0.010*"job" + 0.010*"go" + 0.009*"get" + 0.008*"make" + 0.008*"trying" + 0.008*"good"
INFO 2022-10-28 14:59:41,594 ldamodel.py:1196] topic #1 (0.215): 0.018*"work" + 0.015*"time" + 0.011*"need" + 0.011*"home" + 0.009*"meeting" + 0.008*"much" + 0.007*"zoom" + 0.007*"even" + 0.007*"coffee" + 0.006*"get"
INFO 2022-10-28 14:59:41,594 ldamodel.py:1196] topic #2 (0.194): 0.012*"another" + 0.011*"realestate" + 0.011*"entrepreneur" + 0.010*"day" + 0.010*"job" + 0.009*"morning" + 0.008*"sunday" + 0.007*"let" + 0.007*"way" + 0.006*"hiring"
INFO 2022-10-28 14:59:41,595 ldamodel.py:1196] topic #3 (0.300): 0.034*"work" + 0.020*"home" + 0.018*"office" + 0.011*"working" + 0.010*"today" + 0.009*"day" + 0.009*"back" + 0.009*"like" + 0.008*"new" + 0.008*"week"
INFO 2022-10-28 14:59:41,595 ldamodel.py:1196] topic #4 (0.142): 0.016*"california" + 0.012*"home" + 0.012*"done" + 0.011*"group" + 0.010*"sold" + 0.009*"realestateagent" + 0.009*"souza" + 0.009*"homesales" + 0.009*"realtorlife" + 0.009*"soldgetting"
INFO 2022-10-28 14:59:41,596 ldamodel.py:1074] topic diff=0.335128, rho=0.321412
INFO 2022-10-28 14:59:41,596 ldamodel.py:1001] PROGRESS: pass 1, at document #600/768
INFO 2022-10-28 14:59:41,618 ldamodel.py:794] optimized alpha [0.19467387, 0.23224805, 0.18951692, 0.31437692, 0.1462007]
INFO 2022-10-28 14:59:41,620 ldamodel.py:233] merging changes from 100 documents into a model of 768 documents
INFO 2022-10-28 14:59:41,621 ldamodel.py:1196] topic #0 (0.195): 0.015*"go" + 0.013*"work" + 0.013*"love" + 0.012*"life" + 0.009*"make" + 0.009*"job" + 0.009*"trying" + 0.009*"get" + 0.009*"today" + 0.008*"day"
INFO 2022-10-28 14:59:41,622 ldamodel.py:1196] topic #1 (0.232): 0.014*"work" + 0.013*"time" + 0.012*"meeting" + 0.011*"need" + 0.010*"home" + 0.008*"much" + 0.007*"today" + 0.007*"get" + 0.006*"zoom" + 0.006*"desk"
INFO 2022-10-28 14:59:41,623 ldamodel.py:1196] topic #2 (0.190): 0.010*"job" + 0.009*"day" + 0.009*"another" + 0.008*"realestate" + 0.008*"let" + 0.008*"way" + 0.008*"entrepreneur" + 0.007*"think" + 0.007*"morning" + 0.007*"long"
INFO 2022-10-28 14:59:41,623 ldamodel.py:1196] topic #3 (0.314): 0.030*"work" + 0.021*"office" + 0.020*"home" + 0.015*"working" + 0.013*"today" + 0.011*"day" + 0.009*"like" + 0.009*"new" + 0.009*"back" + 0.008*"one"
INFO 2022-10-28 14:59:41,624 ldamodel.py:1196] topic #4 (0.146): 0.017*"california" + 0.012*"done" + 0.010*"home" + 0.008*"group" + 0.008*"covid" + 0.007*"sold" + 0.007*"homesales" + 0.007*"souza" + 0.007*"cloudoffice" + 0.007*"realestateagent"
INFO 2022-10-28 14:59:41,624 ldamodel.py:1074] topic diff=0.390220, rho=0.321412
INFO 2022-10-28 14:59:41,625 ldamodel.py:1001] PROGRESS: pass 1, at document #700/768
INFO 2022-10-28 14:59:41,647 ldamodel.py:794] optimized alpha [0.19913414, 0.23720531, 0.1867905, 0.34187663, 0.14703542]
INFO 2022-10-28 14:59:41,649 ldamodel.py:233] merging changes from 100 documents into a model of 768 documents
INFO 2022-10-28 14:59:41,650 ldamodel.py:1196] topic #0 (0.199): 0.014*"work" + 0.013*"go" + 0.011*"love" + 0.010*"today" + 0.010*"life" + 0.009*"get" + 0.009*"day" + 0.009*"job" + 0.007*"make" + 0.007*"people"
INFO 2022-10-28 14:59:41,651 ldamodel.py:1196] topic #1 (0.237): 0.013*"work" + 0.013*"meeting" + 0.012*"time" + 0.011*"need" + 0.009*"home" + 0.008*"get" + 0.007*"first" + 0.006*"today" + 0.006*"zoom" + 0.006*"see"
INFO 2022-10-28 14:59:41,652 ldamodel.py:1196] topic #2 (0.187): 0.009*"think" + 0.008*"tuesday" + 0.008*"way" + 0.007*"spring" + 0.007*"job" + 0.007*"day" + 0.007*"morning" + 0.007*"let" + 0.007*"long" + 0.006*"another"
INFO 2022-10-28 14:59:41,652 ldamodel.py:1196] topic #3 (0.342): 0.029*"work" + 0.021*"office" + 0.019*"home" + 0.015*"working" + 0.013*"day" + 0.012*"today" + 0.009*"back" + 0.009*"one" + 0.009*"thing" + 0.008*"like"
INFO 2022-10-28 14:59:41,653 ldamodel.py:1196] topic #4 (0.147): 0.016*"california" + 0.010*"done" + 0.009*"employee" + 0.008*"home" + 0.007*"corporate" + 0.006*"angeles" + 0.006*"los" + 0.006*"work" + 0.005*"group" + 0.005*"covid"
INFO 2022-10-28 14:59:41,653 ldamodel.py:1074] topic diff=0.360543, rho=0.321412
INFO 2022-10-28 14:59:41,676 ldamodel.py:847] -9.439 per-word bound, 694.3 perplexity estimate based on a held-out corpus of 68 documents with 815 words
INFO 2022-10-28 14:59:41,677 ldamodel.py:1001] PROGRESS: pass 1, at document #768/768
INFO 2022-10-28 14:59:41,690 ldamodel.py:794] optimized alpha [0.20648462, 0.24206385, 0.19246857, 0.36442706, 0.14316475]
INFO 2022-10-28 14:59:41,691 ldamodel.py:233] merging changes from 68 documents into a model of 768 documents
INFO 2022-10-28 14:59:41,692 ldamodel.py:1196] topic #0 (0.206): 0.015*"go" + 0.014*"life" + 0.012*"work" + 0.011*"love" + 0.010*"make" + 0.009*"would" + 0.009*"job" + 0.009*"day" + 0.008*"today" + 0.007*"good"</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>INFO 2022-10-28 14:59:41,693 ldamodel.py:1196] topic #1 (0.242): 0.012*"meeting" + 0.011*"time" + 0.011*"work" + 0.010*"need" + 0.010*"team" + 0.010*"zoom" + 0.008*"home" + 0.007*"coffee" + 0.007*"got" + 0.006*"desk"
INFO 2022-10-28 14:59:41,694 ldamodel.py:1196] topic #2 (0.192): 0.011*"morning" + 0.008*"way" + 0.008*"new" + 0.008*"think" + 0.008*"day" + 0.008*"let" + 0.008*"long" + 0.007*"another" + 0.007*"spring" + 0.006*"open"
INFO 2022-10-28 14:59:41,694 ldamodel.py:1196] topic #3 (0.364): 0.026*"work" + 0.024*"office" + 0.018*"day" + 0.018*"home" + 0.014*"back" + 0.013*"working" + 0.010*"one" + 0.010*"new" + 0.010*"today" + 0.008*"week"
INFO 2022-10-28 14:59:41,695 ldamodel.py:1196] topic #4 (0.143): 0.015*"california" + 0.010*"employee" + 0.009*"covid" + 0.008*"beach" + 0.008*"done" + 0.006*"home" + 0.006*"afternoon" + 0.005*"lunchtime" + 0.005*"corporate" + 0.005*"environment"
INFO 2022-10-28 14:59:41,695 ldamodel.py:1074] topic diff=0.310045, rho=0.321412
INFO 2022-10-28 14:59:41,696 ldamodel.py:1001] PROGRESS: pass 2, at document #100/768
INFO 2022-10-28 14:59:41,718 ldamodel.py:794] optimized alpha [0.19503799, 0.21292374, 0.17921858, 0.33126903, 0.1383282]
INFO 2022-10-28 14:59:41,719 ldamodel.py:233] merging changes from 100 documents into a model of 768 documents
INFO 2022-10-28 14:59:41,721 ldamodel.py:1196] topic #0 (0.195): 0.011*"work" + 0.011*"go" + 0.010*"make" + 0.010*"life" + 0.010*"job" + 0.008*"people" + 0.008*"love" + 0.007*"edge" + 0.007*"would" + 0.007*"business"
INFO 2022-10-28 14:59:41,722 ldamodel.py:1196] topic #1 (0.213): 0.012*"meeting" + 0.012*"work" + 0.011*"time" + 0.010*"need" + 0.009*"team" + 0.008*"coffee" + 0.008*"zoom" + 0.006*"home" + 0.006*"even" + 0.006*"much"
INFO 2022-10-28 14:59:41,723 ldamodel.py:1196] topic #2 (0.179): 0.010*"morning" + 0.007*"way" + 0.007*"new" + 0.007*"another" + 0.007*"job" + 0.006*"world" + 0.006*"great" + 0.006*"think" + 0.006*"let" + 0.006*"long"
INFO 2022-10-28 14:59:41,723 ldamodel.py:1196] topic #3 (0.331): 0.026*"office" + 0.026*"work" + 0.014*"home" + 0.014*"day" + 0.012*"back" + 0.011*"working" + 0.010*"today" + 0.010*"new" + 0.009*"remote" + 0.009*"one"
INFO 2022-10-28 14:59:41,724 ldamodel.py:1196] topic #4 (0.138): 0.023*"california" + 0.009*"park" + 0.007*"employee" + 0.007*"beach" + 0.007*"nature" + 0.007*"iphonography" + 0.007*"shotoniphone" + 0.007*"naturelovers" + 0.007*"mvt" + 0.006*"covid"
INFO 2022-10-28 14:59:41,724 ldamodel.py:1074] topic diff=0.341216, rho=0.305995
INFO 2022-10-28 14:59:41,725 ldamodel.py:1001] PROGRESS: pass 2, at document #200/768
INFO 2022-10-28 14:59:41,748 ldamodel.py:794] optimized alpha [0.19696988, 0.22055255, 0.18136667, 0.32950586, 0.13531826]
INFO 2022-10-28 14:59:41,749 ldamodel.py:233] merging changes from 100 documents into a model of 768 documents
INFO 2022-10-28 14:59:41,751 ldamodel.py:1196] topic #0 (0.197): 0.012*"job" + 0.011*"work" + 0.011*"business" + 0.011*"life" + 0.009*"company" + 0.009*"go" + 0.009*"make" + 0.008*"people" + 0.007*"futureofwork" + 0.007*"travel"
INFO 2022-10-28 14:59:41,751 ldamodel.py:1196] topic #1 (0.221): 0.015*"work" + 0.013*"meeting" + 0.011*"time" + 0.009*"home" + 0.009*"need" + 0.007*"coffee" + 0.007*"zoom" + 0.007*"team" + 0.007*"much" + 0.006*"even"
INFO 2022-10-28 14:59:41,752 ldamodel.py:1196] topic #2 (0.181): 0.009*"morning" + 0.008*"think" + 0.008*"another" + 0.007*"long" + 0.007*"open" + 0.006*"job" + 0.006*"way" + 0.006*"let" + 0.006*"day" + 0.006*"new"
INFO 2022-10-28 14:59:41,753 ldamodel.py:1196] topic #3 (0.330): 0.032*"work" + 0.024*"office" + 0.016*"home" + 0.013*"day" + 0.013*"working" + 0.013*"remote" + 0.011*"back" + 0.009*"new" + 0.007*"today" + 0.007*"like"
INFO 2022-10-28 14:59:41,753 ldamodel.py:1196] topic #4 (0.135): 0.018*"california" + 0.008*"change" + 0.007*"grateful" + 0.007*"beach" + 0.006*"park" + 0.006*"corporate" + 0.005*"employee" + 0.005*"able" + 0.005*"family" + 0.005*"nature"
INFO 2022-10-28 14:59:41,754 ldamodel.py:1074] topic diff=0.332922, rho=0.305995
INFO 2022-10-28 14:59:41,754 ldamodel.py:1001] PROGRESS: pass 2, at document #300/768
INFO 2022-10-28 14:59:41,778 ldamodel.py:794] optimized alpha [0.19342166, 0.21853842, 0.18492366, 0.31284988, 0.14012122]
INFO 2022-10-28 14:59:41,779 ldamodel.py:233] merging changes from 100 documents into a model of 768 documents
INFO 2022-10-28 14:59:41,780 ldamodel.py:1196] topic #0 (0.193): 0.016*"work" + 0.016*"business" + 0.010*"job" + 0.009*"career" + 0.009*"money" + 0.009*"life" + 0.009*"company" + 0.009*"dream" + 0.008*"like" + 0.008*"success"
INFO 2022-10-28 14:59:41,781 ldamodel.py:1196] topic #1 (0.219): 0.020*"work" + 0.013*"time" + 0.012*"meeting" + 0.011*"home" + 0.010*"coffee" + 0.007*"got" + 0.007*"need" + 0.007*"nowhiring" + 0.007*"team" + 0.006*"much"
INFO 2022-10-28 14:59:41,782 ldamodel.py:1196] topic #2 (0.185): 0.012*"morning" + 0.009*"day" + 0.009*"long" + 0.008*"let" + 0.008*"entrepreneur" + 0.007*"place" + 0.006*"think" + 0.006*"texas" + 0.006*"way" + 0.006*"another"
INFO 2022-10-28 14:59:41,782 ldamodel.py:1196] topic #3 (0.313): 0.040*"work" + 0.022*"office" + 0.021*"home" + 0.011*"day" + 0.011*"working" + 0.011*"like" + 0.011*"back" + 0.010*"remote" + 0.008*"today" + 0.007*"new"
INFO 2022-10-28 14:59:41,783 ldamodel.py:1196] topic #4 (0.140): 0.022*"california" + 0.009*"home" + 0.008*"done" + 0.007*"job" + 0.006*"group" + 0.006*"sold" + 0.006*"homesales" + 0.006*"cloudoffice" + 0.006*"souza" + 0.006*"realestateagent"
INFO 2022-10-28 14:59:41,783 ldamodel.py:1074] topic diff=0.315184, rho=0.305995
INFO 2022-10-28 14:59:41,784 ldamodel.py:1001] PROGRESS: pass 2, at document #400/768
INFO 2022-10-28 14:59:41,804 ldamodel.py:794] optimized alpha [0.18947105, 0.22091793, 0.19067062, 0.33386186, 0.13684028]
INFO 2022-10-28 14:59:41,805 ldamodel.py:233] merging changes from 100 documents into a model of 768 documents
INFO 2022-10-28 14:59:41,807 ldamodel.py:1196] topic #0 (0.189): 0.015*"love" + 0.015*"work" + 0.012*"business" + 0.010*"job" + 0.010*"go" + 0.009*"life" + 0.009*"good" + 0.008*"dream" + 0.008*"entrepreneur" + 0.008*"get"
INFO 2022-10-28 14:59:41,808 ldamodel.py:1196] topic #1 (0.221): 0.016*"work" + 0.013*"time" + 0.011*"meeting" + 0.010*"home" + 0.010*"need" + 0.009*"much" + 0.008*"coffee" + 0.007*"got" + 0.007*"even" + 0.006*"zoom"
INFO 2022-10-28 14:59:41,808 ldamodel.py:1196] topic #2 (0.191): 0.011*"morning" + 0.011*"entrepreneur" + 0.010*"let" + 0.010*"sunday" + 0.009*"day" + 0.007*"check" + 0.007*"long" + 0.006*"another" + 0.006*"tuesday" + 0.006*"businessowner"
INFO 2022-10-28 14:59:41,809 ldamodel.py:1196] topic #3 (0.334): 0.032*"work" + 0.021*"office" + 0.020*"home" + 0.012*"day" + 0.011*"back" + 0.010*"today" + 0.010*"like" + 0.010*"working" + 0.009*"new" + 0.008*"monday"
INFO 2022-10-28 14:59:41,810 ldamodel.py:1196] topic #4 (0.137): 0.022*"california" + 0.010*"home" + 0.010*"done" + 0.010*"group" + 0.009*"sold" + 0.008*"job" + 0.007*"realtorlife" + 0.007*"listed" + 0.007*"souza" + 0.007*"homesales"
INFO 2022-10-28 14:59:41,810 ldamodel.py:1074] topic diff=0.309994, rho=0.305995
INFO 2022-10-28 14:59:41,811 ldamodel.py:1001] PROGRESS: pass 2, at document #500/768
INFO 2022-10-28 14:59:41,834 ldamodel.py:794] optimized alpha [0.19055578, 0.22279479, 0.18909073, 0.32956627, 0.1393638]
INFO 2022-10-28 14:59:41,835 ldamodel.py:233] merging changes from 100 documents into a model of 768 documents
INFO 2022-10-28 14:59:41,837 ldamodel.py:1196] topic #0 (0.191): 0.014*"work" + 0.014*"love" + 0.011*"job" + 0.010*"business" + 0.010*"life" + 0.010*"go" + 0.008*"make" + 0.008*"trying" + 0.008*"get" + 0.008*"good"
INFO 2022-10-28 14:59:41,837 ldamodel.py:1196] topic #1 (0.223): 0.017*"work" + 0.014*"time" + 0.012*"need" + 0.011*"home" + 0.010*"meeting" + 0.008*"much" + 0.007*"zoom" + 0.007*"get" + 0.007*"even" + 0.007*"coffee"
INFO 2022-10-28 14:59:41,838 ldamodel.py:1196] topic #2 (0.189): 0.012*"another" + 0.010*"entrepreneur" + 0.010*"morning" + 0.010*"day" + 0.008*"sunday" + 0.008*"job" + 0.007*"let" + 0.007*"way" + 0.006*"think" + 0.006*"hiring"
INFO 2022-10-28 14:59:41,839 ldamodel.py:1196] topic #3 (0.330): 0.035*"work" + 0.021*"home" + 0.019*"office" + 0.011*"day" + 0.011*"working" + 0.010*"today" + 0.009*"like" + 0.009*"back" + 0.008*"week" + 0.008*"new"</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>INFO 2022-10-28 14:59:41,839 ldamodel.py:1196] topic #4 (0.139): 0.017*"california" + 0.014*"done" + 0.012*"home" + 0.011*"group" + 0.010*"job" + 0.010*"sold" + 0.010*"realestate" + 0.009*"souza" + 0.009*"listed" + 0.009*"realtorlife"
INFO 2022-10-28 14:59:41,840 ldamodel.py:1074] topic diff=0.260716, rho=0.305995
INFO 2022-10-28 14:59:41,840 ldamodel.py:1001] PROGRESS: pass 2, at document #600/768
INFO 2022-10-28 14:59:41,862 ldamodel.py:794] optimized alpha [0.19722223, 0.23845957, 0.18507709, 0.3410467, 0.14272004]
INFO 2022-10-28 14:59:41,863 ldamodel.py:233] merging changes from 100 documents into a model of 768 documents
INFO 2022-10-28 14:59:41,865 ldamodel.py:1196] topic #0 (0.197): 0.015*"go" + 0.013*"work" + 0.012*"love" + 0.011*"life" + 0.011*"job" + 0.009*"make" + 0.009*"trying" + 0.009*"today" + 0.008*"get" + 0.008*"day"
INFO 2022-10-28 14:59:41,866 ldamodel.py:1196] topic #1 (0.238): 0.014*"work" + 0.012*"time" + 0.012*"meeting" + 0.011*"need" + 0.010*"home" + 0.008*"much" + 0.007*"get" + 0.007*"today" + 0.006*"zoom" + 0.006*"desk"
INFO 2022-10-28 14:59:41,866 ldamodel.py:1196] topic #2 (0.185): 0.009*"another" + 0.008*"day" + 0.008*"let" + 0.008*"way" + 0.008*"entrepreneur" + 0.008*"job" + 0.007*"think" + 0.007*"morning" + 0.007*"long" + 0.006*"tuesday"
INFO 2022-10-28 14:59:41,867 ldamodel.py:1196] topic #3 (0.341): 0.031*"work" + 0.021*"office" + 0.020*"home" + 0.014*"working" + 0.013*"today" + 0.013*"day" + 0.009*"like" + 0.008*"back" + 0.008*"new" + 0.008*"one"
INFO 2022-10-28 14:59:41,868 ldamodel.py:1196] topic #4 (0.143): 0.018*"california" + 0.014*"done" + 0.010*"home" + 0.008*"group" + 0.007*"covid" + 0.007*"job" + 0.007*"sold" + 0.007*"realestate" + 0.007*"listed" + 0.007*"cloudoffice"
INFO 2022-10-28 14:59:41,868 ldamodel.py:1074] topic diff=0.311222, rho=0.305995
INFO 2022-10-28 14:59:41,869 ldamodel.py:1001] PROGRESS: pass 2, at document #700/768
INFO 2022-10-28 14:59:41,889 ldamodel.py:794] optimized alpha [0.2007364, 0.2418768, 0.18307465, 0.3668733, 0.1433353]
INFO 2022-10-28 14:59:41,890 ldamodel.py:233] merging changes from 100 documents into a model of 768 documents
INFO 2022-10-28 14:59:41,891 ldamodel.py:1196] topic #0 (0.201): 0.013*"work" + 0.013*"go" + 0.011*"love" + 0.010*"today" + 0.010*"life" + 0.010*"job" + 0.009*"day" + 0.009*"get" + 0.008*"make" + 0.007*"trying"
INFO 2022-10-28 14:59:41,892 ldamodel.py:1196] topic #1 (0.242): 0.013*"work" + 0.013*"meeting" + 0.011*"time" + 0.011*"need" + 0.009*"home" + 0.008*"get" + 0.006*"zoom" + 0.006*"first" + 0.006*"today" + 0.006*"much"
INFO 2022-10-28 14:59:41,893 ldamodel.py:1196] topic #2 (0.183): 0.009*"think" + 0.008*"tuesday" + 0.008*"way" + 0.007*"spring" + 0.007*"morning" + 0.007*"let" + 0.007*"long" + 0.007*"day" + 0.006*"another" + 0.006*"hybrid"
INFO 2022-10-28 14:59:41,893 ldamodel.py:1196] topic #3 (0.367): 0.030*"work" + 0.022*"office" + 0.019*"home" + 0.014*"day" + 0.014*"working" + 0.013*"today" + 0.009*"one" + 0.009*"back" + 0.009*"thing" + 0.008*"like"
INFO 2022-10-28 14:59:41,894 ldamodel.py:1196] topic #4 (0.143): 0.016*"california" + 0.012*"done" + 0.009*"employee" + 0.009*"home" + 0.007*"corporate" + 0.006*"job" + 0.006*"los" + 0.006*"angeles" + 0.006*"group" + 0.005*"covid"
INFO 2022-10-28 14:59:41,894 ldamodel.py:1074] topic diff=0.284091, rho=0.305995
INFO 2022-10-28 14:59:41,916 ldamodel.py:847] -9.191 per-word bound, 584.6 perplexity estimate based on a held-out corpus of 68 documents with 815 words
INFO 2022-10-28 14:59:41,917 ldamodel.py:1001] PROGRESS: pass 2, at document #768/768
INFO 2022-10-28 14:59:41,928 ldamodel.py:794] optimized alpha [0.20661844, 0.24400021, 0.18827258, 0.3829082, 0.13927574]
INFO 2022-10-28 14:59:41,929 ldamodel.py:233] merging changes from 68 documents into a model of 768 documents
INFO 2022-10-28 14:59:41,931 ldamodel.py:1196] topic #0 (0.207): 0.014*"go" + 0.014*"life" + 0.012*"work" + 0.010*"love" + 0.010*"make" + 0.010*"job" + 0.009*"would" + 0.009*"day" + 0.009*"today" + 0.008*"good"
INFO 2022-10-28 14:59:41,931 ldamodel.py:1196] topic #1 (0.244): 0.012*"meeting" + 0.011*"work" + 0.011*"need" + 0.010*"team" + 0.010*"time" + 0.009*"zoom" + 0.008*"home" + 0.007*"coffee" + 0.007*"got" + 0.006*"desk"
INFO 2022-10-28 14:59:41,932 ldamodel.py:1196] topic #2 (0.188): 0.010*"morning" + 0.010*"new" + 0.008*"way" + 0.008*"think" + 0.008*"let" + 0.008*"long" + 0.008*"day" + 0.007*"another" + 0.007*"spring" + 0.006*"open"
INFO 2022-10-28 14:59:41,933 ldamodel.py:1196] topic #3 (0.383): 0.027*"work" + 0.024*"office" + 0.019*"day" + 0.018*"home" + 0.013*"back" + 0.012*"working" + 0.010*"one" + 0.010*"today" + 0.009*"new" + 0.009*"week"
INFO 2022-10-28 14:59:41,933 ldamodel.py:1196] topic #4 (0.139): 0.015*"california" + 0.010*"employee" + 0.009*"covid" + 0.009*"done" + 0.008*"beach" + 0.006*"home" + 0.006*"afternoon" + 0.005*"corporate" + 0.005*"environment" + 0.005*"lunchtime"
INFO 2022-10-28 14:59:41,933 ldamodel.py:1074] topic diff=0.239196, rho=0.305995
INFO 2022-10-28 14:59:41,934 ldamodel.py:1001] PROGRESS: pass 3, at document #100/768
INFO 2022-10-28 14:59:41,955 ldamodel.py:794] optimized alpha [0.19649082, 0.2157341, 0.17601363, 0.34872165, 0.13565457]
INFO 2022-10-28 14:59:41,956 ldamodel.py:233] merging changes from 100 documents into a model of 768 documents
INFO 2022-10-28 14:59:41,957 ldamodel.py:1196] topic #0 (0.196): 0.011*"work" + 0.011*"go" + 0.011*"job" + 0.010*"life" + 0.010*"make" + 0.008*"people" + 0.008*"love" + 0.007*"business" + 0.007*"would" + 0.007*"edge"
INFO 2022-10-28 14:59:41,958 ldamodel.py:1196] topic #1 (0.216): 0.012*"meeting" + 0.012*"work" + 0.010*"need" + 0.009*"time" + 0.009*"team" + 0.008*"zoom" + 0.008*"coffee" + 0.006*"home" + 0.006*"much" + 0.006*"even"
INFO 2022-10-28 14:59:41,959 ldamodel.py:1196] topic #2 (0.176): 0.010*"morning" + 0.008*"new" + 0.007*"way" + 0.007*"another" + 0.006*"world" + 0.006*"think" + 0.006*"let" + 0.006*"long" + 0.006*"great" + 0.006*"open"
INFO 2022-10-28 14:59:41,959 ldamodel.py:1196] topic #3 (0.349): 0.027*"work" + 0.026*"office" + 0.015*"day" + 0.015*"home" + 0.012*"back" + 0.011*"working" + 0.010*"today" + 0.009*"week" + 0.009*"one" + 0.009*"new"
INFO 2022-10-28 14:59:41,960 ldamodel.py:1196] topic #4 (0.136): 0.022*"california" + 0.009*"park" + 0.007*"employee" + 0.007*"beach" + 0.007*"nature" + 0.006*"iphonography" + 0.006*"shotoniphone" + 0.006*"naturelovers" + 0.006*"mvt" + 0.006*"covid"
INFO 2022-10-28 14:59:41,960 ldamodel.py:1074] topic diff=0.288534, rho=0.292603
INFO 2022-10-28 14:59:41,961 ldamodel.py:1001] PROGRESS: pass 3, at document #200/768
INFO 2022-10-28 14:59:41,983 ldamodel.py:794] optimized alpha [0.19915058, 0.22202091, 0.17671853, 0.34459117, 0.13262449]
INFO 2022-10-28 14:59:41,984 ldamodel.py:233] merging changes from 100 documents into a model of 768 documents
INFO 2022-10-28 14:59:41,986 ldamodel.py:1196] topic #0 (0.199): 0.013*"job" + 0.011*"work" + 0.011*"business" + 0.011*"life" + 0.009*"company" + 0.009*"make" + 0.009*"go" + 0.008*"people" + 0.008*"futureofwork" + 0.007*"worker"
INFO 2022-10-28 14:59:41,986 ldamodel.py:1196] topic #1 (0.222): 0.015*"work" + 0.013*"meeting" + 0.010*"time" + 0.009*"need" + 0.009*"home" + 0.007*"zoom" + 0.007*"coffee" + 0.007*"team" + 0.007*"much" + 0.006*"amp"
INFO 2022-10-28 14:59:41,987 ldamodel.py:1196] topic #2 (0.177): 0.009*"morning" + 0.008*"think" + 0.008*"another" + 0.007*"long" + 0.007*"new" + 0.007*"open" + 0.006*"way" + 0.006*"let" + 0.006*"day" + 0.006*"technology"
INFO 2022-10-28 14:59:41,988 ldamodel.py:1196] topic #3 (0.345): 0.032*"work" + 0.024*"office" + 0.017*"home" + 0.014*"day" + 0.013*"working" + 0.012*"remote" + 0.011*"back" + 0.008*"new" + 0.008*"today" + 0.007*"like"
INFO 2022-10-28 14:59:41,988 ldamodel.py:1196] topic #4 (0.133): 0.018*"california" + 0.008*"change" + 0.007*"grateful" + 0.007*"beach" + 0.006*"park" + 0.006*"corporate" + 0.005*"employee" + 0.005*"able" + 0.005*"nature" + 0.005*"family"
INFO 2022-10-28 14:59:41,989 ldamodel.py:1074] topic diff=0.278052, rho=0.292603
INFO 2022-10-28 14:59:41,989 ldamodel.py:1001] PROGRESS: pass 3, at document #300/768
INFO 2022-10-28 14:59:42,013 ldamodel.py:794] optimized alpha [0.19533515, 0.21971941, 0.1802001, 0.32623127, 0.13689247]</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>INFO 2022-10-28 14:59:42,014 ldamodel.py:233] merging changes from 100 documents into a model of 768 documents
INFO 2022-10-28 14:59:42,016 ldamodel.py:1196] topic #0 (0.195): 0.015*"business" + 0.015*"work" + 0.011*"job" + 0.009*"career" + 0.009*"life" + 0.009*"company" + 0.009*"money" + 0.008*"dream" + 0.008*"like" + 0.008*"success"
INFO 2022-10-28 14:59:42,016 ldamodel.py:1196] topic #1 (0.220): 0.019*"work" + 0.012*"meeting" + 0.012*"time" + 0.011*"home" + 0.010*"coffee" + 0.007*"need" + 0.007*"got" + 0.007*"team" + 0.007*"much" + 0.007*"nowhiring"
INFO 2022-10-28 14:59:42,017 ldamodel.py:1196] topic #2 (0.180): 0.012*"morning" + 0.009*"long" + 0.009*"day" + 0.008*"let" + 0.008*"entrepreneur" + 0.007*"place" + 0.006*"think" + 0.006*"another" + 0.006*"way" + 0.006*"texas"
INFO 2022-10-28 14:59:42,017 ldamodel.py:1196] topic #3 (0.326): 0.041*"work" + 0.022*"office" + 0.021*"home" + 0.012*"day" + 0.011*"working" + 0.011*"like" + 0.010*"back" + 0.010*"remote" + 0.009*"today" + 0.008*"time"
INFO 2022-10-28 14:59:42,018 ldamodel.py:1196] topic #4 (0.137): 0.022*"california" + 0.009*"home" + 0.008*"done" + 0.007*"job" + 0.006*"realestate" + 0.006*"group" + 0.006*"sold" + 0.006*"listed" + 0.006*"souza" + 0.006*"realestateagent"
INFO 2022-10-28 14:59:42,019 ldamodel.py:1074] topic diff=0.266040, rho=0.292603
INFO 2022-10-28 14:59:42,019 ldamodel.py:1001] PROGRESS: pass 3, at document #400/768
INFO 2022-10-28 14:59:42,038 ldamodel.py:794] optimized alpha [0.19145115, 0.22263739, 0.18601501, 0.34646887, 0.13494308]
INFO 2022-10-28 14:59:42,040 ldamodel.py:233] merging changes from 100 documents into a model of 768 documents
INFO 2022-10-28 14:59:42,041 ldamodel.py:1196] topic #0 (0.191): 0.014*"work" + 0.014*"love" + 0.012*"business" + 0.012*"job" + 0.010*"go" + 0.009*"life" + 0.009*"good" + 0.008*"entrepreneur" + 0.008*"dream" + 0.008*"saturday"
INFO 2022-10-28 14:59:42,042 ldamodel.py:1196] topic #1 (0.223): 0.015*"work" + 0.012*"time" + 0.011*"meeting" + 0.010*"need" + 0.010*"home" + 0.009*"much" + 0.008*"coffee" + 0.007*"got" + 0.007*"even" + 0.006*"zoom"
INFO 2022-10-28 14:59:42,043 ldamodel.py:1196] topic #2 (0.186): 0.011*"morning" + 0.011*"entrepreneur" + 0.010*"let" + 0.010*"sunday" + 0.009*"day" + 0.007*"check" + 0.007*"long" + 0.007*"another" + 0.006*"tuesday" + 0.006*"businessowner"
INFO 2022-10-28 14:59:42,043 ldamodel.py:1196] topic #3 (0.346): 0.033*"work" + 0.021*"office" + 0.020*"home" + 0.013*"day" + 0.010*"back" + 0.010*"today" + 0.010*"working" + 0.010*"like" + 0.009*"new" + 0.008*"monday"
INFO 2022-10-28 14:59:42,044 ldamodel.py:1196] topic #4 (0.135): 0.022*"california" + 0.010*"done" + 0.010*"home" + 0.009*"group" + 0.009*"realestate" + 0.009*"job" + 0.008*"sold" + 0.007*"realestateagent" + 0.007*"homesales" + 0.007*"cloudoffice"
INFO 2022-10-28 14:59:42,044 ldamodel.py:1074] topic diff=0.264161, rho=0.292603
INFO 2022-10-28 14:59:42,045 ldamodel.py:1001] PROGRESS: pass 3, at document #500/768
INFO 2022-10-28 14:59:42,065 ldamodel.py:794] optimized alpha [0.19159876, 0.2229233, 0.18592289, 0.344313, 0.13665171]
INFO 2022-10-28 14:59:42,066 ldamodel.py:233] merging changes from 100 documents into a model of 768 documents
INFO 2022-10-28 14:59:42,068 ldamodel.py:1196] topic #0 (0.192): 0.013*"work" + 0.013*"love" + 0.012*"job" + 0.010*"business" + 0.010*"life" + 0.010*"go" + 0.008*"make" + 0.008*"trying" + 0.008*"entrepreneur" + 0.008*"get"
INFO 2022-10-28 14:59:42,069 ldamodel.py:1196] topic #1 (0.223): 0.017*"work" + 0.013*"time" + 0.012*"need" + 0.011*"home" + 0.010*"meeting" + 0.008*"much" + 0.007*"get" + 0.007*"zoom" + 0.007*"coffee" + 0.007*"even"
INFO 2022-10-28 14:59:42,069 ldamodel.py:1196] topic #2 (0.186): 0.012*"another" + 0.010*"entrepreneur" + 0.010*"morning" + 0.009*"day" + 0.008*"sunday" + 0.007*"let" + 0.007*"way" + 0.007*"job" + 0.006*"think" + 0.006*"hiring"
INFO 2022-10-28 14:59:42,070 ldamodel.py:1196] topic #3 (0.344): 0.036*"work" + 0.021*"home" + 0.019*"office" + 0.012*"day" + 0.011*"working" + 0.010*"today" + 0.009*"like" + 0.009*"back" + 0.009*"week" + 0.007*"new"
INFO 2022-10-28 14:59:42,071 ldamodel.py:1196] topic #4 (0.137): 0.017*"california" + 0.015*"done" + 0.011*"home" + 0.011*"realestate" + 0.010*"group" + 0.010*"job" + 0.010*"sold" + 0.009*"listed" + 0.009*"souza" + 0.009*"cloudoffice"
INFO 2022-10-28 14:59:42,071 ldamodel.py:1074] topic diff=0.217299, rho=0.292603
INFO 2022-10-28 14:59:42,072 ldamodel.py:1001] PROGRESS: pass 3, at document #600/768
INFO 2022-10-28 14:59:42,093 ldamodel.py:794] optimized alpha [0.19781709, 0.23755448, 0.18241186, 0.35356525, 0.1395502]
INFO 2022-10-28 14:59:42,094 ldamodel.py:233] merging changes from 100 documents into a model of 768 documents
INFO 2022-10-28 14:59:42,096 ldamodel.py:1196] topic #0 (0.198): 0.014*"go" + 0.012*"work" + 0.012*"love" + 0.011*"job" + 0.011*"life" + 0.009*"make" + 0.009*"trying" + 0.009*"today" + 0.008*"get" + 0.008*"day"
INFO 2022-10-28 14:59:42,096 ldamodel.py:1196] topic #1 (0.238): 0.014*"work" + 0.012*"meeting" + 0.011*"time" + 0.011*"need" + 0.009*"home" + 0.008*"much" + 0.007*"get" + 0.006*"zoom" + 0.006*"today" + 0.006*"desk"
INFO 2022-10-28 14:59:42,097 ldamodel.py:1196] topic #2 (0.182): 0.009*"another" + 0.008*"let" + 0.008*"way" + 0.008*"day" + 0.008*"entrepreneur" + 0.007*"think" + 0.007*"morning" + 0.007*"job" + 0.007*"long" + 0.006*"tuesday"
INFO 2022-10-28 14:59:42,098 ldamodel.py:1196] topic #3 (0.354): 0.032*"work" + 0.021*"office" + 0.021*"home" + 0.014*"working" + 0.014*"day" + 0.013*"today" + 0.009*"like" + 0.008*"back" + 0.008*"new" + 0.008*"one"
INFO 2022-10-28 14:59:42,099 ldamodel.py:1196] topic #4 (0.140): 0.018*"california" + 0.014*"done" + 0.010*"home" + 0.008*"realestate" + 0.008*"group" + 0.008*"job" + 0.007*"covid" + 0.007*"sold" + 0.007*"realtorlife" + 0.007*"souza"
INFO 2022-10-28 14:59:42,099 ldamodel.py:1074] topic diff=0.265041, rho=0.292603
INFO 2022-10-28 14:59:42,099 ldamodel.py:1001] PROGRESS: pass 3, at document #700/768
INFO 2022-10-28 14:59:42,122 ldamodel.py:794] optimized alpha [0.20066427, 0.2404108, 0.18080637, 0.37801436, 0.14072503]
INFO 2022-10-28 14:59:42,123 ldamodel.py:233] merging changes from 100 documents into a model of 768 documents
INFO 2022-10-28 14:59:42,125 ldamodel.py:1196] topic #0 (0.201): 0.013*"work" + 0.012*"go" + 0.011*"love" + 0.010*"today" + 0.010*"life" + 0.010*"job" + 0.008*"day" + 0.008*"get" + 0.008*"make" + 0.007*"trying"
INFO 2022-10-28 14:59:42,126 ldamodel.py:1196] topic #1 (0.240): 0.013*"work" + 0.013*"meeting" + 0.011*"need" + 0.011*"time" + 0.008*"home" + 0.008*"get" + 0.006*"zoom" + 0.006*"much" + 0.006*"first" + 0.006*"today"
INFO 2022-10-28 14:59:42,127 ldamodel.py:1196] topic #2 (0.181): 0.009*"think" + 0.008*"tuesday" + 0.008*"way" + 0.007*"morning" + 0.007*"spring" + 0.007*"let" + 0.007*"long" + 0.007*"day" + 0.006*"another" + 0.006*"hybrid"
INFO 2022-10-28 14:59:42,127 ldamodel.py:1196] topic #3 (0.378): 0.031*"work" + 0.022*"office" + 0.019*"home" + 0.015*"day" + 0.014*"working" + 0.013*"today" + 0.009*"one" + 0.009*"back" + 0.008*"thing" + 0.008*"like"
INFO 2022-10-28 14:59:42,128 ldamodel.py:1196] topic #4 (0.141): 0.016*"california" + 0.013*"done" + 0.009*"employee" + 0.008*"home" + 0.007*"corporate" + 0.007*"job" + 0.006*"realestate" + 0.006*"angeles" + 0.006*"los" + 0.006*"group"
INFO 2022-10-28 14:59:42,129 ldamodel.py:1074] topic diff=0.238868, rho=0.292603
INFO 2022-10-28 14:59:42,148 ldamodel.py:847] -9.061 per-word bound, 533.9 perplexity estimate based on a held-out corpus of 68 documents with 815 words
INFO 2022-10-28 14:59:42,149 ldamodel.py:1001] PROGRESS: pass 3, at document #768/768
INFO 2022-10-28 14:59:42,160 ldamodel.py:794] optimized alpha [0.20581722, 0.24198253, 0.18566324, 0.38889664, 0.13699433]
INFO 2022-10-28 14:59:42,162 ldamodel.py:233] merging changes from 68 documents into a model of 768 documents
INFO 2022-10-28 14:59:42,163 ldamodel.py:1196] topic #0 (0.206): 0.014*"go" + 0.014*"life" + 0.012*"work" + 0.010*"make" + 0.010*"love" + 0.010*"job" + 0.009*"would" + 0.009*"today" + 0.009*"day" + 0.008*"good"
INFO 2022-10-28 14:59:42,164 ldamodel.py:1196] topic #1 (0.242): 0.012*"meeting" + 0.011*"work" + 0.011*"need" + 0.010*"team" + 0.009*"zoom" + 0.009*"time" + 0.008*"home" + 0.007*"coffee" + 0.007*"got" + 0.006*"desk"</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>INFO 2022-10-28 14:59:42,165 ldamodel.py:1196] topic #2 (0.186): 0.011*"new" + 0.010*"morning" + 0.008*"way" + 0.008*"think" + 0.008*"let" + 0.008*"long" + 0.007*"another" + 0.007*"day" + 0.006*"spring" + 0.006*"open"
INFO 2022-10-28 14:59:42,165 ldamodel.py:1196] topic #3 (0.389): 0.028*"work" + 0.024*"office" + 0.020*"day" + 0.018*"home" + 0.013*"back" + 0.012*"working" + 0.010*"one" + 0.010*"today" + 0.009*"week" + 0.008*"new"
INFO 2022-10-28 14:59:42,166 ldamodel.py:1196] topic #4 (0.137): 0.015*"california" + 0.010*"done" + 0.010*"employee" + 0.009*"covid" + 0.008*"beach" + 0.006*"home" + 0.005*"afternoon" + 0.005*"corporate" + 0.005*"environment" + 0.005*"lunchtime"
INFO 2022-10-28 14:59:42,167 ldamodel.py:1074] topic diff=0.200569, rho=0.292603
INFO 2022-10-28 14:59:42,167 ldamodel.py:1001] PROGRESS: pass 4, at document #100/768
INFO 2022-10-28 14:59:42,189 ldamodel.py:794] optimized alpha [0.19585069, 0.21535587, 0.17435808, 0.35555747, 0.13378218]
INFO 2022-10-28 14:59:42,190 ldamodel.py:233] merging changes from 100 documents into a model of 768 documents
INFO 2022-10-28 14:59:42,192 ldamodel.py:1196] topic #0 (0.196): 0.011*"job" + 0.011*"work" + 0.010*"go" + 0.010*"life" + 0.010*"make" + 0.008*"people" + 0.008*"love" + 0.007*"business" + 0.007*"would" + 0.007*"company"
INFO 2022-10-28 14:59:42,192 ldamodel.py:1196] topic #1 (0.215): 0.012*"meeting" + 0.011*"work" + 0.010*"need" + 0.009*"team" + 0.009*"time" + 0.008*"zoom" + 0.008*"coffee" + 0.006*"much" + 0.006*"home" + 0.006*"even"
INFO 2022-10-28 14:59:42,193 ldamodel.py:1196] topic #2 (0.174): 0.010*"morning" + 0.009*"new" + 0.007*"way" + 0.007*"another" + 0.006*"world" + 0.006*"think" + 0.006*"let" + 0.006*"long" + 0.006*"open" + 0.006*"great"
INFO 2022-10-28 14:59:42,193 ldamodel.py:1196] topic #3 (0.356): 0.027*"work" + 0.026*"office" + 0.015*"day" + 0.015*"home" + 0.012*"back" + 0.011*"working" + 0.010*"today" + 0.010*"week" + 0.009*"one" + 0.009*"remote"
INFO 2022-10-28 14:59:42,194 ldamodel.py:1196] topic #4 (0.134): 0.022*"california" + 0.008*"park" + 0.007*"employee" + 0.007*"beach" + 0.006*"nature" + 0.006*"done" + 0.006*"naturelovers" + 0.006*"shotoniphone" + 0.006*"iphonography" + 0.006*"mvt"
INFO 2022-10-28 14:59:42,195 ldamodel.py:1074] topic diff=0.256748, rho=0.280828
INFO 2022-10-28 14:59:42,195 ldamodel.py:1001] PROGRESS: pass 4, at document #200/768
INFO 2022-10-28 14:59:42,213 ldamodel.py:794] optimized alpha [0.19896886, 0.22130443, 0.17521787, 0.35106468, 0.13105777]
INFO 2022-10-28 14:59:42,215 ldamodel.py:233] merging changes from 100 documents into a model of 768 documents
INFO 2022-10-28 14:59:42,216 ldamodel.py:1196] topic #0 (0.199): 0.013*"job" + 0.011*"work" + 0.011*"life" + 0.011*"business" + 0.009*"company" + 0.009*"make" + 0.008*"go" + 0.008*"people" + 0.008*"futureofwork" + 0.007*"worker"
INFO 2022-10-28 14:59:42,217 ldamodel.py:1196] topic #1 (0.221): 0.014*"work" + 0.013*"meeting" + 0.010*"time" + 0.009*"need" + 0.008*"home" + 0.007*"zoom" + 0.007*"coffee" + 0.007*"team" + 0.007*"much" + 0.007*"amp"
INFO 2022-10-28 14:59:42,218 ldamodel.py:1196] topic #2 (0.175): 0.009*"morning" + 0.008*"think" + 0.008*"another" + 0.008*"new" + 0.007*"long" + 0.007*"open" + 0.006*"way" + 0.006*"let" + 0.006*"day" + 0.006*"technology"
INFO 2022-10-28 14:59:42,218 ldamodel.py:1196] topic #3 (0.351): 0.033*"work" + 0.024*"office" + 0.017*"home" + 0.015*"day" + 0.013*"working" + 0.012*"remote" + 0.011*"back" + 0.008*"today" + 0.008*"new" + 0.007*"week"
INFO 2022-10-28 14:59:42,219 ldamodel.py:1196] topic #4 (0.131): 0.018*"california" + 0.008*"change" + 0.007*"grateful" + 0.007*"beach" + 0.006*"park" + 0.006*"corporate" + 0.006*"employee" + 0.005*"able" + 0.005*"nature" + 0.005*"done"
INFO 2022-10-28 14:59:42,219 ldamodel.py:1074] topic diff=0.245085, rho=0.280828
INFO 2022-10-28 14:59:42,220 ldamodel.py:1001] PROGRESS: pass 4, at document #300/768
INFO 2022-10-28 14:59:42,241 ldamodel.py:794] optimized alpha [0.19523726, 0.21909595, 0.17859928, 0.33215046, 0.1351897]
INFO 2022-10-28 14:59:42,242 ldamodel.py:233] merging changes from 100 documents into a model of 768 documents
INFO 2022-10-28 14:59:42,244 ldamodel.py:1196] topic #0 (0.195): 0.015*"business" + 0.015*"work" + 0.011*"job" + 0.009*"life" + 0.009*"career" + 0.009*"company" + 0.009*"money" + 0.008*"dream" + 0.008*"like" + 0.008*"would"
INFO 2022-10-28 14:59:42,245 ldamodel.py:1196] topic #1 (0.219): 0.018*"work" + 0.012*"meeting" + 0.011*"time" + 0.010*"home" + 0.010*"coffee" + 0.008*"need" + 0.007*"got" + 0.007*"team" + 0.007*"much" + 0.006*"nowhiring"
INFO 2022-10-28 14:59:42,245 ldamodel.py:1196] topic #2 (0.179): 0.012*"morning" + 0.009*"long" + 0.009*"day" + 0.008*"let" + 0.008*"entrepreneur" + 0.007*"place" + 0.006*"think" + 0.006*"another" + 0.006*"way" + 0.006*"texas"
INFO 2022-10-28 14:59:42,246 ldamodel.py:1196] topic #3 (0.332): 0.041*"work" + 0.023*"office" + 0.021*"home" + 0.013*"day" + 0.012*"working" + 0.011*"like" + 0.010*"back" + 0.009*"remote" + 0.009*"today" + 0.008*"time"
INFO 2022-10-28 14:59:42,247 ldamodel.py:1196] topic #4 (0.135): 0.022*"california" + 0.008*"done" + 0.008*"home" + 0.007*"job" + 0.006*"realestate" + 0.006*"group" + 0.006*"sold" + 0.006*"corporate" + 0.006*"souza" + 0.006*"listed"
INFO 2022-10-28 14:59:42,247 ldamodel.py:1074] topic diff=0.236147, rho=0.280828
INFO 2022-10-28 14:59:42,248 ldamodel.py:1001] PROGRESS: pass 4, at document #400/768
INFO 2022-10-28 14:59:42,267 ldamodel.py:794] optimized alpha [0.19259767, 0.22206187, 0.18423861, 0.352042, 0.13315527]
INFO 2022-10-28 14:59:42,269 ldamodel.py:233] merging changes from 100 documents into a model of 768 documents
INFO 2022-10-28 14:59:42,271 ldamodel.py:1196] topic #0 (0.193): 0.014*"work" + 0.013*"love" + 0.012*"business" + 0.012*"job" + 0.010*"good" + 0.009*"go" + 0.009*"life" + 0.008*"entrepreneur" + 0.008*"dream" + 0.008*"company"
INFO 2022-10-28 14:59:42,271 ldamodel.py:1196] topic #1 (0.222): 0.015*"work" + 0.012*"time" + 0.011*"meeting" + 0.010*"need" + 0.010*"home" + 0.009*"much" + 0.008*"coffee" + 0.007*"got" + 0.007*"even" + 0.006*"zoom"
INFO 2022-10-28 14:59:42,272 ldamodel.py:1196] topic #2 (0.184): 0.011*"morning" + 0.011*"entrepreneur" + 0.010*"let" + 0.009*"sunday" + 0.009*"day" + 0.007*"long" + 0.007*"check" + 0.007*"another" + 0.006*"tuesday" + 0.006*"businessowner"
INFO 2022-10-28 14:59:42,273 ldamodel.py:1196] topic #3 (0.352): 0.034*"work" + 0.022*"office" + 0.020*"home" + 0.014*"day" + 0.011*"today" + 0.010*"back" + 0.010*"working" + 0.009*"like" + 0.008*"new" + 0.008*"monday"
INFO 2022-10-28 14:59:42,274 ldamodel.py:1196] topic #4 (0.133): 0.022*"california" + 0.010*"done" + 0.010*"home" + 0.009*"group" + 0.009*"realestate" + 0.009*"job" + 0.008*"sold" + 0.007*"realtorlife" + 0.007*"cloudoffice" + 0.007*"soldgetting"
INFO 2022-10-28 14:59:42,274 ldamodel.py:1074] topic diff=0.235534, rho=0.280828
INFO 2022-10-28 14:59:42,275 ldamodel.py:1001] PROGRESS: pass 4, at document #500/768
INFO 2022-10-28 14:59:42,292 ldamodel.py:794] optimized alpha [0.19253674, 0.22237869, 0.18447535, 0.35046908, 0.13455795]
INFO 2022-10-28 14:59:42,293 ldamodel.py:233] merging changes from 100 documents into a model of 768 documents
INFO 2022-10-28 14:59:42,295 ldamodel.py:1196] topic #0 (0.193): 0.013*"work" + 0.013*"love" + 0.012*"job" + 0.011*"business" + 0.010*"life" + 0.009*"go" + 0.008*"make" + 0.008*"good" + 0.008*"trying" + 0.008*"entrepreneur"
INFO 2022-10-28 14:59:42,296 ldamodel.py:1196] topic #1 (0.222): 0.016*"work" + 0.012*"time" + 0.012*"need" + 0.010*"home" + 0.010*"meeting" + 0.008*"much" + 0.007*"get" + 0.007*"zoom" + 0.007*"coffee" + 0.007*"even"
INFO 2022-10-28 14:59:42,297 ldamodel.py:1196] topic #2 (0.184): 0.012*"another" + 0.010*"entrepreneur" + 0.010*"morning" + 0.009*"day" + 0.008*"sunday" + 0.007*"let" + 0.007*"way" + 0.007*"job" + 0.006*"think" + 0.006*"hiring"
INFO 2022-10-28 14:59:42,297 ldamodel.py:1196] topic #3 (0.350): 0.036*"work" + 0.021*"home" + 0.019*"office" + 0.013*"day" + 0.011*"working" + 0.011*"today" + 0.009*"back" + 0.009*"week" + 0.009*"like" + 0.007*"new"
INFO 2022-10-28 14:59:42,298 ldamodel.py:1196] topic #4 (0.135): 0.017*"california" + 0.015*"done" + 0.011*"realestate" + 0.011*"home" + 0.010*"group" + 0.010*"job" + 0.010*"sold" + 0.009*"cloudoffice" + 0.009*"souza" + 0.009*"homesales"</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>INFO 2022-10-28 14:59:42,298 ldamodel.py:1074] topic diff=0.192729, rho=0.280828
INFO 2022-10-28 14:59:42,299 ldamodel.py:1001] PROGRESS: pass 4, at document #600/768
INFO 2022-10-28 14:59:42,317 ldamodel.py:794] optimized alpha [0.19841008, 0.2352511, 0.18128434, 0.35965866, 0.13781807]
INFO 2022-10-28 14:59:42,319 ldamodel.py:233] merging changes from 100 documents into a model of 768 documents
INFO 2022-10-28 14:59:42,320 ldamodel.py:1196] topic #0 (0.198): 0.014*"go" + 0.012*"job" + 0.012*"work" + 0.012*"love" + 0.011*"life" + 0.009*"make" + 0.009*"trying" + 0.009*"today" + 0.008*"get" + 0.008*"business"
INFO 2022-10-28 14:59:42,321 ldamodel.py:1196] topic #1 (0.235): 0.013*"work" + 0.012*"meeting" + 0.011*"need" + 0.011*"time" + 0.009*"home" + 0.008*"much" + 0.007*"get" + 0.006*"zoom" + 0.006*"today" + 0.006*"desk"
INFO 2022-10-28 14:59:42,322 ldamodel.py:1196] topic #2 (0.181): 0.009*"another" + 0.008*"let" + 0.008*"way" + 0.008*"entrepreneur" + 0.008*"day" + 0.007*"morning" + 0.007*"think" + 0.007*"long" + 0.007*"job" + 0.006*"tuesday"
INFO 2022-10-28 14:59:42,322 ldamodel.py:1196] topic #3 (0.360): 0.033*"work" + 0.021*"office" + 0.021*"home" + 0.014*"day" + 0.014*"working" + 0.013*"today" + 0.009*"like" + 0.008*"back" + 0.008*"week" + 0.008*"one"
INFO 2022-10-28 14:59:42,323 ldamodel.py:1196] topic #4 (0.138): 0.018*"california" + 0.014*"done" + 0.010*"home" + 0.009*"realestate" + 0.008*"group" + 0.008*"job" + 0.007*"sold" + 0.007*"covid" + 0.007*"realestateagent" + 0.007*"homesales"
INFO 2022-10-28 14:59:42,323 ldamodel.py:1074] topic diff=0.236024, rho=0.280828
INFO 2022-10-28 14:59:42,324 ldamodel.py:1001] PROGRESS: pass 4, at document #700/768
INFO 2022-10-28 14:59:42,343 ldamodel.py:794] optimized alpha [0.20081022, 0.23853008, 0.17988364, 0.38380885, 0.13870381]
INFO 2022-10-28 14:59:42,344 ldamodel.py:233] merging changes from 100 documents into a model of 768 documents
INFO 2022-10-28 14:59:42,346 ldamodel.py:1196] topic #0 (0.201): 0.012*"work" + 0.012*"go" + 0.011*"love" + 0.010*"job" + 0.010*"life" + 0.010*"today" + 0.008*"day" + 0.008*"get" + 0.008*"make" + 0.007*"trying"
INFO 2022-10-28 14:59:42,346 ldamodel.py:1196] topic #1 (0.239): 0.013*"meeting" + 0.013*"work" + 0.011*"need" + 0.010*"time" + 0.008*"home" + 0.008*"get" + 0.006*"zoom" + 0.006*"much" + 0.006*"first" + 0.006*"today"
INFO 2022-10-28 14:59:42,347 ldamodel.py:1196] topic #2 (0.180): 0.009*"think" + 0.008*"tuesday" + 0.008*"way" + 0.007*"morning" + 0.007*"let" + 0.007*"spring" + 0.007*"long" + 0.007*"another" + 0.006*"day" + 0.006*"entrepreneur"
INFO 2022-10-28 14:59:42,348 ldamodel.py:1196] topic #3 (0.384): 0.031*"work" + 0.022*"office" + 0.020*"home" + 0.015*"day" + 0.014*"working" + 0.013*"today" + 0.009*"one" + 0.009*"back" + 0.008*"thing" + 0.008*"like"
INFO 2022-10-28 14:59:42,348 ldamodel.py:1196] topic #4 (0.139): 0.017*"california" + 0.014*"done" + 0.009*"employee" + 0.008*"home" + 0.007*"corporate" + 0.007*"job" + 0.006*"realestate" + 0.006*"los" + 0.006*"angeles" + 0.006*"group"
INFO 2022-10-28 14:59:42,349 ldamodel.py:1074] topic diff=0.212027, rho=0.280828
INFO 2022-10-28 14:59:42,369 ldamodel.py:847] -8.978 per-word bound, 504.1 perplexity estimate based on a held-out corpus of 68 documents with 815 words
INFO 2022-10-28 14:59:42,369 ldamodel.py:1001] PROGRESS: pass 4, at document #768/768
INFO 2022-10-28 14:59:42,380 ldamodel.py:794] optimized alpha [0.2054994, 0.23974824, 0.18391265, 0.39152512, 0.13525668]
INFO 2022-10-28 14:59:42,381 ldamodel.py:233] merging changes from 68 documents into a model of 768 documents
INFO 2022-10-28 14:59:42,383 ldamodel.py:1196] topic #0 (0.205): 0.013*"life" + 0.013*"go" + 0.011*"work" + 0.010*"make" + 0.010*"job" + 0.010*"love" + 0.009*"would" + 0.009*"today" + 0.009*"day" + 0.008*"good"
INFO 2022-10-28 14:59:42,383 ldamodel.py:1196] topic #1 (0.240): 0.012*"meeting" + 0.011*"work" + 0.011*"need" + 0.010*"team" + 0.009*"zoom" + 0.008*"time" + 0.008*"home" + 0.007*"coffee" + 0.007*"got" + 0.006*"desk"
INFO 2022-10-28 14:59:42,384 ldamodel.py:1196] topic #2 (0.184): 0.011*"new" + 0.009*"morning" + 0.008*"way" + 0.008*"think" + 0.008*"let" + 0.008*"long" + 0.007*"another" + 0.007*"day" + 0.006*"spring" + 0.006*"open"
INFO 2022-10-28 14:59:42,385 ldamodel.py:1196] topic #3 (0.392): 0.029*"work" + 0.024*"office" + 0.020*"day" + 0.019*"home" + 0.013*"back" + 0.012*"working" + 0.010*"today" + 0.010*"one" + 0.009*"week" + 0.008*"new"
INFO 2022-10-28 14:59:42,385 ldamodel.py:1196] topic #4 (0.135): 0.015*"california" + 0.010*"done" + 0.010*"employee" + 0.009*"covid" + 0.008*"beach" + 0.006*"home" + 0.005*"corporate" + 0.005*"job" + 0.005*"afternoon" + 0.005*"environment"
INFO 2022-10-28 14:59:42,385 ldamodel.py:1074] topic diff=0.177835, rho=0.280828
INFO 2022-10-28 14:59:42,386 ldamodel.py:1001] PROGRESS: pass 5, at document #100/768
INFO 2022-10-28 14:59:42,406 ldamodel.py:794] optimized alpha [0.19597629, 0.2146576, 0.17326759, 0.3591145, 0.13234633]
INFO 2022-10-28 14:59:42,408 ldamodel.py:233] merging changes from 100 documents into a model of 768 documents
INFO 2022-10-28 14:59:42,409 ldamodel.py:1196] topic #0 (0.196): 0.011*"job" + 0.011*"work" + 0.010*"life" + 0.010*"go" + 0.010*"make" + 0.008*"people" + 0.008*"love" + 0.007*"business" + 0.007*"would" + 0.007*"company"
INFO 2022-10-28 14:59:42,410 ldamodel.py:1196] topic #1 (0.215): 0.012*"meeting" + 0.011*"work" + 0.010*"need" + 0.009*"team" + 0.008*"time" + 0.008*"zoom" + 0.008*"coffee" + 0.006*"much" + 0.006*"home" + 0.006*"even"
INFO 2022-10-28 14:59:42,411 ldamodel.py:1196] topic #2 (0.173): 0.009*"morning" + 0.009*"new" + 0.007*"way" + 0.007*"another" + 0.006*"world" + 0.006*"think" + 0.006*"let" + 0.006*"long" + 0.006*"open" + 0.006*"great"
INFO 2022-10-28 14:59:42,411 ldamodel.py:1196] topic #3 (0.359): 0.028*"work" + 0.026*"office" + 0.016*"day" + 0.015*"home" + 0.012*"back" + 0.012*"working" + 0.010*"today" + 0.010*"week" + 0.009*"one" + 0.009*"remote"
INFO 2022-10-28 14:59:42,412 ldamodel.py:1196] topic #4 (0.132): 0.022*"california" + 0.008*"park" + 0.007*"employee" + 0.007*"beach" + 0.007*"done" + 0.006*"nature" + 0.006*"shotoniphone" + 0.006*"iphonography" + 0.006*"mvt" + 0.006*"naturelovers"
INFO 2022-10-28 14:59:42,412 ldamodel.py:1074] topic diff=0.235561, rho=0.270369
INFO 2022-10-28 14:59:42,413 ldamodel.py:1001] PROGRESS: pass 5, at document #200/768
INFO 2022-10-28 14:59:42,432 ldamodel.py:794] optimized alpha [0.19902112, 0.22039168, 0.17421843, 0.35515276, 0.12955007]
INFO 2022-10-28 14:59:42,434 ldamodel.py:233] merging changes from 100 documents into a model of 768 documents
INFO 2022-10-28 14:59:42,435 ldamodel.py:1196] topic #0 (0.199): 0.013*"job" + 0.011*"work" + 0.011*"life" + 0.010*"business" + 0.009*"company" + 0.009*"make" + 0.008*"go" + 0.008*"people" + 0.008*"futureofwork" + 0.007*"worker"
INFO 2022-10-28 14:59:42,436 ldamodel.py:1196] topic #1 (0.220): 0.014*"work" + 0.013*"meeting" + 0.010*"time" + 0.009*"need" + 0.008*"home" + 0.007*"zoom" + 0.007*"team" + 0.007*"coffee" + 0.007*"much" + 0.007*"amp"
INFO 2022-10-28 14:59:42,437 ldamodel.py:1196] topic #2 (0.174): 0.009*"morning" + 0.008*"think" + 0.008*"new" + 0.008*"another" + 0.007*"long" + 0.007*"open" + 0.006*"way" + 0.006*"let" + 0.006*"day" + 0.006*"world"
INFO 2022-10-28 14:59:42,437 ldamodel.py:1196] topic #3 (0.355): 0.033*"work" + 0.024*"office" + 0.017*"home" + 0.015*"day" + 0.013*"working" + 0.011*"remote" + 0.011*"back" + 0.008*"today" + 0.008*"week" + 0.008*"new"
INFO 2022-10-28 14:59:42,438 ldamodel.py:1196] topic #4 (0.130): 0.018*"california" + 0.008*"change" + 0.007*"beach" + 0.007*"grateful" + 0.006*"park" + 0.006*"corporate" + 0.006*"employee" + 0.005*"done" + 0.005*"able" + 0.005*"nature"
INFO 2022-10-28 14:59:42,439 ldamodel.py:1074] topic diff=0.223777, rho=0.270369
INFO 2022-10-28 14:59:42,439 ldamodel.py:1001] PROGRESS: pass 5, at document #300/768
INFO 2022-10-28 14:59:42,458 ldamodel.py:794] optimized alpha [0.19536804, 0.2183272, 0.17751165, 0.3364991, 0.13325478]
INFO 2022-10-28 14:59:42,460 ldamodel.py:233] merging changes from 100 documents into a model of 768 documents
INFO 2022-10-28 14:59:42,461 ldamodel.py:1196] topic #0 (0.195): 0.015*"business" + 0.014*"work" + 0.011*"job" + 0.009*"life" + 0.009*"company" + 0.009*"career" + 0.008*"money" + 0.008*"dream" + 0.008*"like" + 0.008*"would"</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>INFO 2022-10-28 14:59:42,462 ldamodel.py:1196] topic #1 (0.218): 0.018*"work" + 0.012*"meeting" + 0.011*"time" + 0.010*"home" + 0.009*"coffee" + 0.008*"need" + 0.007*"got" + 0.007*"team" + 0.007*"much" + 0.006*"nowhiring"
INFO 2022-10-28 14:59:42,462 ldamodel.py:1196] topic #2 (0.178): 0.011*"morning" + 0.009*"long" + 0.008*"day" + 0.008*"let" + 0.008*"entrepreneur" + 0.007*"place" + 0.006*"think" + 0.006*"another" + 0.006*"way" + 0.006*"tuesday"
INFO 2022-10-28 14:59:42,463 ldamodel.py:1196] topic #3 (0.336): 0.041*"work" + 0.023*"office" + 0.021*"home" + 0.013*"day" + 0.012*"working" + 0.010*"like" + 0.010*"back" + 0.009*"remote" + 0.009*"today" + 0.008*"time"
INFO 2022-10-28 14:59:42,463 ldamodel.py:1196] topic #4 (0.133): 0.022*"california" + 0.009*"done" + 0.008*"home" + 0.008*"job" + 0.006*"realestate" + 0.006*"group" + 0.006*"sold" + 0.006*"corporate" + 0.006*"listed" + 0.006*"cloudoffice"
INFO 2022-10-28 14:59:42,464 ldamodel.py:1074] topic diff=0.216919, rho=0.270369
INFO 2022-10-28 14:59:42,464 ldamodel.py:1001] PROGRESS: pass 5, at document #400/768
INFO 2022-10-28 14:59:42,483 ldamodel.py:794] optimized alpha [0.19290099, 0.22126092, 0.18293439, 0.35638568, 0.13152678]
INFO 2022-10-28 14:59:42,486 ldamodel.py:233] merging changes from 100 documents into a model of 768 documents
INFO 2022-10-28 14:59:42,488 ldamodel.py:1196] topic #0 (0.193): 0.014*"work" + 0.013*"love" + 0.012*"business" + 0.012*"job" + 0.010*"good" + 0.009*"life" + 0.009*"go" + 0.008*"entrepreneur" + 0.008*"dream" + 0.008*"company"
INFO 2022-10-28 14:59:42,489 ldamodel.py:1196] topic #1 (0.221): 0.015*"work" + 0.011*"time" + 0.011*"meeting" + 0.010*"need" + 0.010*"home" + 0.009*"much" + 0.008*"coffee" + 0.007*"got" + 0.007*"even" + 0.006*"zoom"
INFO 2022-10-28 14:59:42,490 ldamodel.py:1196] topic #2 (0.183): 0.011*"morning" + 0.010*"entrepreneur" + 0.010*"let" + 0.009*"sunday" + 0.008*"day" + 0.007*"long" + 0.007*"check" + 0.007*"another" + 0.006*"tuesday" + 0.006*"think"
INFO 2022-10-28 14:59:42,491 ldamodel.py:1196] topic #3 (0.356): 0.034*"work" + 0.022*"office" + 0.020*"home" + 0.014*"day" + 0.011*"today" + 0.010*"back" + 0.010*"working" + 0.009*"like" + 0.008*"new" + 0.008*"monday"
INFO 2022-10-28 14:59:42,491 ldamodel.py:1196] topic #4 (0.132): 0.022*"california" + 0.010*"done" + 0.009*"home" + 0.009*"realestate" + 0.009*"group" + 0.009*"job" + 0.008*"sold" + 0.007*"realestateagent" + 0.007*"homesales" + 0.007*"listed"
INFO 2022-10-28 14:59:42,492 ldamodel.py:1074] topic diff=0.214803, rho=0.270369
INFO 2022-10-28 14:59:42,492 ldamodel.py:1001] PROGRESS: pass 5, at document #500/768
INFO 2022-10-28 14:59:42,508 ldamodel.py:794] optimized alpha [0.1927621, 0.22167122, 0.18330927, 0.35477424, 0.13266602]
INFO 2022-10-28 14:59:42,510 ldamodel.py:233] merging changes from 100 documents into a model of 768 documents
INFO 2022-10-28 14:59:42,511 ldamodel.py:1196] topic #0 (0.193): 0.013*"work" + 0.013*"love" + 0.012*"job" + 0.011*"business" + 0.010*"life" + 0.009*"go" + 0.008*"make" + 0.008*"good" + 0.008*"trying" + 0.008*"entrepreneur"
INFO 2022-10-28 14:59:42,512 ldamodel.py:1196] topic #1 (0.222): 0.016*"work" + 0.012*"time" + 0.012*"need" + 0.010*"home" + 0.010*"meeting" + 0.008*"much" + 0.007*"get" + 0.007*"zoom" + 0.007*"coffee" + 0.007*"even"
INFO 2022-10-28 14:59:42,513 ldamodel.py:1196] topic #2 (0.183): 0.012*"another" + 0.010*"entrepreneur" + 0.009*"morning" + 0.009*"day" + 0.008*"sunday" + 0.007*"let" + 0.007*"way" + 0.007*"job" + 0.006*"think" + 0.006*"hiring"
INFO 2022-10-28 14:59:42,513 ldamodel.py:1196] topic #3 (0.355): 0.036*"work" + 0.021*"home" + 0.019*"office" + 0.013*"day" + 0.011*"working" + 0.011*"today" + 0.009*"week" + 0.009*"back" + 0.009*"like" + 0.007*"new"
INFO 2022-10-28 14:59:42,514 ldamodel.py:1196] topic #4 (0.133): 0.017*"california" + 0.015*"done" + 0.011*"realestate" + 0.011*"home" + 0.010*"job" + 0.010*"group" + 0.009*"sold" + 0.009*"souza" + 0.009*"listed" + 0.009*"soldgetting"
INFO 2022-10-28 14:59:42,514 ldamodel.py:1074] topic diff=0.176607, rho=0.270369
INFO 2022-10-28 14:59:42,515 ldamodel.py:1001] PROGRESS: pass 5, at document #600/768
INFO 2022-10-28 14:59:42,531 ldamodel.py:794] optimized alpha [0.19835773, 0.23393618, 0.18036823, 0.36332086, 0.13593931]
INFO 2022-10-28 14:59:42,532 ldamodel.py:233] merging changes from 100 documents into a model of 768 documents
INFO 2022-10-28 14:59:42,534 ldamodel.py:1196] topic #0 (0.198): 0.014*"go" + 0.012*"job" + 0.012*"work" + 0.012*"love" + 0.011*"life" + 0.009*"make" + 0.009*"trying" + 0.009*"today" + 0.008*"get" + 0.008*"business"
INFO 2022-10-28 14:59:42,534 ldamodel.py:1196] topic #1 (0.234): 0.013*"work" + 0.012*"meeting" + 0.011*"need" + 0.011*"time" + 0.009*"home" + 0.008*"much" + 0.007*"get" + 0.006*"zoom" + 0.006*"desk" + 0.006*"today"
INFO 2022-10-28 14:59:42,535 ldamodel.py:1196] topic #2 (0.180): 0.009*"another" + 0.008*"let" + 0.008*"way" + 0.008*"entrepreneur" + 0.008*"day" + 0.007*"think" + 0.007*"morning" + 0.007*"long" + 0.007*"job" + 0.006*"tuesday"
INFO 2022-10-28 14:59:42,536 ldamodel.py:1196] topic #3 (0.363): 0.033*"work" + 0.021*"office" + 0.021*"home" + 0.014*"day" + 0.014*"working" + 0.013*"today" + 0.009*"like" + 0.008*"back" + 0.008*"week" + 0.008*"one"
INFO 2022-10-28 14:59:42,536 ldamodel.py:1196] topic #4 (0.136): 0.018*"california" + 0.014*"done" + 0.010*"home" + 0.009*"realestate" + 0.008*"job" + 0.008*"group" + 0.007*"sold" + 0.007*"covid" + 0.007*"realtorlife" + 0.007*"soldgetting"
INFO 2022-10-28 14:59:42,536 ldamodel.py:1074] topic diff=0.216015, rho=0.270369
INFO 2022-10-28 14:59:42,537 ldamodel.py:1001] PROGRESS: pass 5, at document #700/768
INFO 2022-10-28 14:59:42,554 ldamodel.py:794] optimized alpha [0.20064622, 0.23724364, 0.17910582, 0.3865669, 0.1369112]
INFO 2022-10-28 14:59:42,555 ldamodel.py:233] merging changes from 100 documents into a model of 768 documents
INFO 2022-10-28 14:59:42,556 ldamodel.py:1196] topic #0 (0.201): 0.012*"work" + 0.012*"go" + 0.011*"job" + 0.010*"love" + 0.010*"life" + 0.010*"today" + 0.008*"day" + 0.008*"get" + 0.008*"make" + 0.007*"trying"
INFO 2022-10-28 14:59:42,557 ldamodel.py:1196] topic #1 (0.237): 0.013*"work" + 0.013*"meeting" + 0.011*"need" + 0.010*"time" + 0.008*"home" + 0.008*"get" + 0.006*"zoom" + 0.006*"much" + 0.006*"first" + 0.006*"amp"
INFO 2022-10-28 14:59:42,558 ldamodel.py:1196] topic #2 (0.179): 0.009*"think" + 0.008*"tuesday" + 0.008*"way" + 0.007*"let" + 0.007*"morning" + 0.007*"spring" + 0.007*"long" + 0.007*"another" + 0.006*"day" + 0.006*"entrepreneur"
INFO 2022-10-28 14:59:42,558 ldamodel.py:1196] topic #3 (0.387): 0.032*"work" + 0.022*"office" + 0.020*"home" + 0.015*"day" + 0.014*"working" + 0.013*"today" + 0.009*"one" + 0.009*"back" + 0.008*"like" + 0.008*"thing"
INFO 2022-10-28 14:59:42,559 ldamodel.py:1196] topic #4 (0.137): 0.017*"california" + 0.014*"done" + 0.009*"employee" + 0.008*"home" + 0.007*"corporate" + 0.007*"job" + 0.006*"realestate" + 0.006*"group" + 0.006*"angeles" + 0.006*"los"
INFO 2022-10-28 14:59:42,559 ldamodel.py:1074] topic diff=0.194438, rho=0.270369
INFO 2022-10-28 14:59:42,576 ldamodel.py:847] -8.920 per-word bound, 484.3 perplexity estimate based on a held-out corpus of 68 documents with 815 words
INFO 2022-10-28 14:59:42,577 ldamodel.py:1001] PROGRESS: pass 5, at document #768/768
INFO 2022-10-28 14:59:42,587 ldamodel.py:794] optimized alpha [0.20507452, 0.23781128, 0.18294454, 0.3928784, 0.13372941]
INFO 2022-10-28 14:59:42,588 ldamodel.py:233] merging changes from 68 documents into a model of 768 documents
INFO 2022-10-28 14:59:42,589 ldamodel.py:1196] topic #0 (0.205): 0.013*"life" + 0.013*"go" + 0.011*"work" + 0.010*"job" + 0.010*"make" + 0.010*"love" + 0.009*"would" + 0.009*"today" + 0.009*"day" + 0.008*"good"
INFO 2022-10-28 14:59:42,590 ldamodel.py:1196] topic #1 (0.238): 0.012*"meeting" + 0.011*"work" + 0.011*"need" + 0.009*"team" + 0.009*"zoom" + 0.008*"time" + 0.008*"home" + 0.007*"coffee" + 0.007*"got" + 0.006*"desk"
INFO 2022-10-28 14:59:42,590 ldamodel.py:1196] topic #2 (0.183): 0.011*"new" + 0.009*"morning" + 0.008*"way" + 0.008*"think" + 0.008*"let" + 0.008*"long" + 0.007*"another" + 0.007*"day" + 0.006*"spring" + 0.006*"tuesday"</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>INFO 2022-10-28 14:59:42,591 ldamodel.py:1196] topic #3 (0.393): 0.029*"work" + 0.024*"office" + 0.020*"day" + 0.019*"home" + 0.013*"back" + 0.012*"working" + 0.010*"today" + 0.010*"one" + 0.009*"week" + 0.008*"new"
INFO 2022-10-28 14:59:42,591 ldamodel.py:1196] topic #4 (0.134): 0.015*"california" + 0.010*"done" + 0.010*"employee" + 0.009*"covid" + 0.008*"beach" + 0.006*"home" + 0.005*"corporate" + 0.005*"job" + 0.005*"afternoon" + 0.005*"ready"
INFO 2022-10-28 14:59:42,592 ldamodel.py:1074] topic diff=0.162709, rho=0.270369
INFO 2022-10-28 14:59:42,592 ldamodel.py:1001] PROGRESS: pass 6, at document #100/768
INFO 2022-10-28 14:59:42,610 ldamodel.py:794] optimized alpha [0.1959316, 0.21406846, 0.17277643, 0.36133376, 0.13107122]
INFO 2022-10-28 14:59:42,611 ldamodel.py:233] merging changes from 100 documents into a model of 768 documents
INFO 2022-10-28 14:59:42,612 ldamodel.py:1196] topic #0 (0.196): 0.011*"job" + 0.011*"work" + 0.010*"life" + 0.010*"go" + 0.010*"make" + 0.008*"love" + 0.008*"people" + 0.007*"business" + 0.007*"would" + 0.007*"day"
INFO 2022-10-28 14:59:42,613 ldamodel.py:1196] topic #1 (0.214): 0.012*"meeting" + 0.011*"work" + 0.010*"need" + 0.009*"team" + 0.008*"time" + 0.008*"zoom" + 0.008*"coffee" + 0.007*"much" + 0.006*"home" + 0.006*"even"
INFO 2022-10-28 14:59:42,613 ldamodel.py:1196] topic #2 (0.173): 0.009*"new" + 0.009*"morning" + 0.007*"way" + 0.007*"another" + 0.006*"world" + 0.006*"think" + 0.006*"let" + 0.006*"long" + 0.006*"open" + 0.006*"day"
INFO 2022-10-28 14:59:42,614 ldamodel.py:1196] topic #3 (0.361): 0.028*"work" + 0.026*"office" + 0.016*"day" + 0.015*"home" + 0.012*"working" + 0.012*"back" + 0.011*"today" + 0.010*"week" + 0.009*"one" + 0.008*"remote"
INFO 2022-10-28 14:59:42,614 ldamodel.py:1196] topic #4 (0.131): 0.022*"california" + 0.008*"park" + 0.007*"employee" + 0.007*"beach" + 0.007*"done" + 0.006*"nature" + 0.006*"shotoniphone" + 0.006*"mvt" + 0.006*"iphonography" + 0.006*"naturelovers"
INFO 2022-10-28 14:59:42,615 ldamodel.py:1074] topic diff=0.219755, rho=0.260998
INFO 2022-10-28 14:59:42,615 ldamodel.py:1001] PROGRESS: pass 6, at document #200/768
INFO 2022-10-28 14:59:42,632 ldamodel.py:794] optimized alpha [0.19886135, 0.21960117, 0.17372741, 0.35719207, 0.12851612]
INFO 2022-10-28 14:59:42,633 ldamodel.py:233] merging changes from 100 documents into a model of 768 documents
INFO 2022-10-28 14:59:42,634 ldamodel.py:1196] topic #0 (0.199): 0.013*"job" + 0.011*"work" + 0.011*"life" + 0.010*"business" + 0.009*"company" + 0.009*"make" + 0.008*"go" + 0.008*"people" + 0.007*"futureofwork" + 0.007*"worker"
INFO 2022-10-28 14:59:42,635 ldamodel.py:1196] topic #1 (0.220): 0.014*"work" + 0.013*"meeting" + 0.010*"time" + 0.009*"need" + 0.008*"home" + 0.007*"zoom" + 0.007*"team" + 0.007*"coffee" + 0.007*"much" + 0.007*"amp"
INFO 2022-10-28 14:59:42,636 ldamodel.py:1196] topic #2 (0.174): 0.008*"morning" + 0.008*"think" + 0.008*"new" + 0.008*"another" + 0.007*"long" + 0.007*"open" + 0.006*"way" + 0.006*"let" + 0.006*"day" + 0.006*"entrepreneur"
INFO 2022-10-28 14:59:42,636 ldamodel.py:1196] topic #3 (0.357): 0.033*"work" + 0.025*"office" + 0.017*"home" + 0.015*"day" + 0.013*"working" + 0.011*"remote" + 0.011*"back" + 0.008*"today" + 0.008*"week" + 0.008*"one"
INFO 2022-10-28 14:59:42,637 ldamodel.py:1196] topic #4 (0.129): 0.018*"california" + 0.008*"change" + 0.007*"beach" + 0.007*"grateful" + 0.006*"park" + 0.006*"corporate" + 0.006*"employee" + 0.005*"done" + 0.005*"able" + 0.005*"nature"
INFO 2022-10-28 14:59:42,637 ldamodel.py:1074] topic diff=0.208448, rho=0.260998
INFO 2022-10-28 14:59:42,637 ldamodel.py:1001] PROGRESS: pass 6, at document #300/768
INFO 2022-10-28 14:59:42,656 ldamodel.py:794] optimized alpha [0.19528283, 0.216983, 0.17688212, 0.33885255, 0.13209762]
INFO 2022-10-28 14:59:42,657 ldamodel.py:233] merging changes from 100 documents into a model of 768 documents
INFO 2022-10-28 14:59:42,659 ldamodel.py:1196] topic #0 (0.195): 0.015*"business" + 0.014*"work" + 0.011*"job" + 0.009*"life" + 0.009*"company" + 0.008*"career" + 0.008*"money" + 0.008*"dream" + 0.008*"like" + 0.008*"love"
INFO 2022-10-28 14:59:42,660 ldamodel.py:1196] topic #1 (0.217): 0.018*"work" + 0.012*"meeting" + 0.011*"time" + 0.010*"home" + 0.009*"coffee" + 0.008*"need" + 0.007*"got" + 0.007*"team" + 0.007*"much" + 0.006*"amp"
INFO 2022-10-28 14:59:42,660 ldamodel.py:1196] topic #2 (0.177): 0.011*"morning" + 0.009*"long" + 0.008*"let" + 0.008*"day" + 0.008*"entrepreneur" + 0.007*"place" + 0.006*"think" + 0.006*"another" + 0.006*"way" + 0.006*"new"
INFO 2022-10-28 14:59:42,661 ldamodel.py:1196] topic #3 (0.339): 0.040*"work" + 0.023*"office" + 0.021*"home" + 0.013*"day" + 0.012*"working" + 0.010*"back" + 0.010*"like" + 0.009*"today" + 0.009*"remote" + 0.008*"time"
INFO 2022-10-28 14:59:42,662 ldamodel.py:1196] topic #4 (0.132): 0.021*"california" + 0.009*"done" + 0.008*"home" + 0.008*"job" + 0.006*"realestate" + 0.006*"group" + 0.006*"beach" + 0.006*"corporate" + 0.006*"sold" + 0.006*"soldgetting"
INFO 2022-10-28 14:59:42,662 ldamodel.py:1074] topic diff=0.203055, rho=0.260998
INFO 2022-10-28 14:59:42,663 ldamodel.py:1001] PROGRESS: pass 6, at document #400/768
INFO 2022-10-28 14:59:42,679 ldamodel.py:794] optimized alpha [0.19291091, 0.21989615, 0.18211198, 0.35813025, 0.13053894]
INFO 2022-10-28 14:59:42,680 ldamodel.py:233] merging changes from 100 documents into a model of 768 documents
INFO 2022-10-28 14:59:42,681 ldamodel.py:1196] topic #0 (0.193): 0.013*"work" + 0.013*"love" + 0.012*"job" + 0.012*"business" + 0.010*"good" + 0.009*"life" + 0.009*"go" + 0.008*"entrepreneur" + 0.008*"dream" + 0.008*"today"
INFO 2022-10-28 14:59:42,682 ldamodel.py:1196] topic #1 (0.220): 0.015*"work" + 0.011*"time" + 0.011*"meeting" + 0.010*"need" + 0.009*"home" + 0.009*"much" + 0.008*"coffee" + 0.007*"got" + 0.007*"even" + 0.006*"zoom"
INFO 2022-10-28 14:59:42,682 ldamodel.py:1196] topic #2 (0.182): 0.010*"morning" + 0.010*"entrepreneur" + 0.010*"let" + 0.009*"sunday" + 0.008*"day" + 0.007*"long" + 0.007*"check" + 0.007*"another" + 0.006*"tuesday" + 0.006*"think"
INFO 2022-10-28 14:59:42,683 ldamodel.py:1196] topic #3 (0.358): 0.034*"work" + 0.022*"office" + 0.020*"home" + 0.014*"day" + 0.011*"today" + 0.010*"back" + 0.010*"working" + 0.009*"like" + 0.008*"new" + 0.008*"week"
INFO 2022-10-28 14:59:42,684 ldamodel.py:1196] topic #4 (0.131): 0.021*"california" + 0.010*"done" + 0.009*"home" + 0.009*"realestate" + 0.009*"group" + 0.009*"job" + 0.008*"sold" + 0.007*"realtorlife" + 0.007*"soldgetting" + 0.007*"listed"
INFO 2022-10-28 14:59:42,684 ldamodel.py:1074] topic diff=0.199969, rho=0.260998
INFO 2022-10-28 14:59:42,684 ldamodel.py:1001] PROGRESS: pass 6, at document #500/768
INFO 2022-10-28 14:59:42,700 ldamodel.py:794] optimized alpha [0.1927535, 0.2204291, 0.18255763, 0.35677198, 0.13170552]
INFO 2022-10-28 14:59:42,701 ldamodel.py:233] merging changes from 100 documents into a model of 768 documents
INFO 2022-10-28 14:59:42,703 ldamodel.py:1196] topic #0 (0.193): 0.013*"work" + 0.012*"love" + 0.012*"job" + 0.011*"business" + 0.010*"life" + 0.009*"go" + 0.008*"make" + 0.008*"good" + 0.008*"trying" + 0.008*"entrepreneur"
INFO 2022-10-28 14:59:42,703 ldamodel.py:1196] topic #1 (0.220): 0.016*"work" + 0.012*"need" + 0.011*"time" + 0.010*"home" + 0.010*"meeting" + 0.008*"much" + 0.007*"get" + 0.007*"zoom" + 0.007*"coffee" + 0.007*"even"
INFO 2022-10-28 14:59:42,703 ldamodel.py:1196] topic #2 (0.183): 0.011*"another" + 0.010*"entrepreneur" + 0.009*"morning" + 0.008*"day" + 0.008*"sunday" + 0.008*"let" + 0.007*"way" + 0.006*"job" + 0.006*"think" + 0.006*"hiring"
INFO 2022-10-28 14:59:42,704 ldamodel.py:1196] topic #3 (0.357): 0.036*"work" + 0.021*"home" + 0.020*"office" + 0.013*"day" + 0.011*"working" + 0.011*"today" + 0.009*"week" + 0.009*"back" + 0.009*"like" + 0.007*"one"
INFO 2022-10-28 14:59:42,705 ldamodel.py:1196] topic #4 (0.132): 0.017*"california" + 0.014*"done" + 0.011*"realestate" + 0.011*"home" + 0.010*"job" + 0.010*"group" + 0.009*"sold" + 0.009*"realestateagent" + 0.009*"soldgetting" + 0.009*"souza"
INFO 2022-10-28 14:59:42,705 ldamodel.py:1074] topic diff=0.164970, rho=0.260998
INFO 2022-10-28 14:59:42,705 ldamodel.py:1001] PROGRESS: pass 6, at document #600/768</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>INFO 2022-10-28 14:59:42,724 ldamodel.py:794] optimized alpha [0.19811966, 0.23223309, 0.1797873, 0.36490142, 0.13491707]
INFO 2022-10-28 14:59:42,725 ldamodel.py:233] merging changes from 100 documents into a model of 768 documents
INFO 2022-10-28 14:59:42,726 ldamodel.py:1196] topic #0 (0.198): 0.014*"go" + 0.012*"job" + 0.012*"work" + 0.011*"love" + 0.011*"life" + 0.009*"make" + 0.009*"trying" + 0.009*"today" + 0.008*"business" + 0.008*"get"
INFO 2022-10-28 14:59:42,727 ldamodel.py:1196] topic #1 (0.232): 0.013*"work" + 0.012*"meeting" + 0.011*"need" + 0.010*"time" + 0.009*"home" + 0.008*"much" + 0.007*"get" + 0.007*"zoom" + 0.006*"desk" + 0.006*"got"
INFO 2022-10-28 14:59:42,728 ldamodel.py:1196] topic #2 (0.180): 0.009*"another" + 0.008*"let" + 0.008*"way" + 0.008*"entrepreneur" + 0.008*"day" + 0.007*"think" + 0.007*"morning" + 0.007*"long" + 0.006*"job" + 0.006*"tuesday"
INFO 2022-10-28 14:59:42,728 ldamodel.py:1196] topic #3 (0.365): 0.033*"work" + 0.022*"office" + 0.021*"home" + 0.014*"day" + 0.014*"working" + 0.013*"today" + 0.009*"like" + 0.008*"back" + 0.008*"week" + 0.008*"one"
INFO 2022-10-28 14:59:42,729 ldamodel.py:1196] topic #4 (0.135): 0.018*"california" + 0.014*"done" + 0.010*"home" + 0.009*"realestate" + 0.008*"job" + 0.008*"group" + 0.007*"sold" + 0.007*"covid" + 0.007*"listed" + 0.007*"souza"
INFO 2022-10-28 14:59:42,730 ldamodel.py:1074] topic diff=0.201322, rho=0.260998
INFO 2022-10-28 14:59:42,730 ldamodel.py:1001] PROGRESS: pass 6, at document #700/768
INFO 2022-10-28 14:59:42,747 ldamodel.py:794] optimized alpha [0.2002721, 0.23434874, 0.17858233, 0.38781577, 0.13587499]
INFO 2022-10-28 14:59:42,748 ldamodel.py:233] merging changes from 100 documents into a model of 768 documents
INFO 2022-10-28 14:59:42,750 ldamodel.py:1196] topic #0 (0.200): 0.012*"work" + 0.012*"go" + 0.011*"job" + 0.010*"love" + 0.010*"life" + 0.010*"today" + 0.008*"day" + 0.008*"get" + 0.008*"make" + 0.007*"business"
INFO 2022-10-28 14:59:42,751 ldamodel.py:1196] topic #1 (0.234): 0.013*"work" + 0.013*"meeting" + 0.011*"need" + 0.009*"time" + 0.008*"home" + 0.008*"get" + 0.006*"zoom" + 0.006*"much" + 0.006*"first" + 0.006*"amp"
INFO 2022-10-28 14:59:42,751 ldamodel.py:1196] topic #2 (0.179): 0.009*"think" + 0.008*"tuesday" + 0.008*"way" + 0.007*"let" + 0.007*"morning" + 0.007*"long" + 0.007*"spring" + 0.007*"another" + 0.006*"day" + 0.006*"entrepreneur"
INFO 2022-10-28 14:59:42,752 ldamodel.py:1196] topic #3 (0.388): 0.032*"work" + 0.022*"office" + 0.020*"home" + 0.015*"day" + 0.014*"working" + 0.013*"today" + 0.009*"one" + 0.009*"back" + 0.008*"like" + 0.008*"week"
INFO 2022-10-28 14:59:42,753 ldamodel.py:1196] topic #4 (0.136): 0.017*"california" + 0.014*"done" + 0.008*"employee" + 0.008*"home" + 0.007*"job" + 0.007*"corporate" + 0.007*"realestate" + 0.006*"group" + 0.006*"los" + 0.006*"angeles"
INFO 2022-10-28 14:59:42,753 ldamodel.py:1074] topic diff=0.181898, rho=0.260998
INFO 2022-10-28 14:59:42,771 ldamodel.py:847] -8.878 per-word bound, 470.6 perplexity estimate based on a held-out corpus of 68 documents with 815 words
INFO 2022-10-28 14:59:42,771 ldamodel.py:1001] PROGRESS: pass 6, at document #768/768
INFO 2022-10-28 14:59:42,781 ldamodel.py:794] optimized alpha [0.2045087, 0.23507273, 0.18228084, 0.3933233, 0.13286781]
INFO 2022-10-28 14:59:42,782 ldamodel.py:233] merging changes from 68 documents into a model of 768 documents
INFO 2022-10-28 14:59:42,783 ldamodel.py:1196] topic #0 (0.205): 0.013*"life" + 0.013*"go" + 0.011*"work" + 0.010*"job" + 0.010*"love" + 0.010*"make" + 0.009*"would" + 0.009*"today" + 0.009*"day" + 0.008*"good"
INFO 2022-10-28 14:59:42,784 ldamodel.py:1196] topic #1 (0.235): 0.012*"meeting" + 0.011*"work" + 0.011*"need" + 0.009*"team" + 0.009*"zoom" + 0.008*"time" + 0.008*"home" + 0.007*"coffee" + 0.007*"got" + 0.006*"desk"
INFO 2022-10-28 14:59:42,784 ldamodel.py:1196] topic #2 (0.182): 0.011*"new" + 0.009*"morning" + 0.008*"way" + 0.008*"think" + 0.008*"let" + 0.008*"long" + 0.007*"another" + 0.007*"day" + 0.006*"spring" + 0.006*"tuesday"
INFO 2022-10-28 14:59:42,785 ldamodel.py:1196] topic #3 (0.393): 0.029*"work" + 0.024*"office" + 0.020*"day" + 0.019*"home" + 0.013*"back" + 0.012*"working" + 0.011*"today" + 0.010*"one" + 0.009*"week" + 0.008*"time"
INFO 2022-10-28 14:59:42,785 ldamodel.py:1196] topic #4 (0.133): 0.015*"california" + 0.010*"done" + 0.009*"employee" + 0.009*"covid" + 0.008*"beach" + 0.007*"home" + 0.005*"job" + 0.005*"corporate" + 0.005*"realestate" + 0.005*"ready"
INFO 2022-10-28 14:59:42,786 ldamodel.py:1074] topic diff=0.151879, rho=0.260998
INFO 2022-10-28 14:59:42,786 ldamodel.py:1001] PROGRESS: pass 7, at document #100/768
INFO 2022-10-28 14:59:42,823 ldamodel.py:794] optimized alpha [0.19574709, 0.213153, 0.17250809, 0.36277947, 0.1303821]
INFO 2022-10-28 14:59:42,824 ldamodel.py:233] merging changes from 100 documents into a model of 768 documents
INFO 2022-10-28 14:59:42,826 ldamodel.py:1196] topic #0 (0.196): 0.011*"job" + 0.011*"work" + 0.010*"life" + 0.010*"go" + 0.010*"make" + 0.008*"love" + 0.008*"people" + 0.007*"business" + 0.007*"day" + 0.007*"would"
INFO 2022-10-28 14:59:42,827 ldamodel.py:1196] topic #1 (0.213): 0.012*"meeting" + 0.012*"work" + 0.010*"need" + 0.008*"team" + 0.008*"time" + 0.008*"zoom" + 0.008*"coffee" + 0.007*"much" + 0.006*"home" + 0.006*"even"
INFO 2022-10-28 14:59:42,828 ldamodel.py:1196] topic #2 (0.173): 0.009*"new" + 0.009*"morning" + 0.007*"way" + 0.007*"another" + 0.006*"think" + 0.006*"let" + 0.006*"world" + 0.006*"long" + 0.006*"open" + 0.006*"day"
INFO 2022-10-28 14:59:42,828 ldamodel.py:1196] topic #3 (0.363): 0.028*"work" + 0.026*"office" + 0.016*"day" + 0.016*"home" + 0.012*"working" + 0.012*"back" + 0.011*"today" + 0.010*"week" + 0.009*"one" + 0.008*"remote"
INFO 2022-10-28 14:59:42,829 ldamodel.py:1196] topic #4 (0.130): 0.022*"california" + 0.008*"park" + 0.007*"employee" + 0.007*"beach" + 0.007*"done" + 0.006*"nature" + 0.006*"covid" + 0.006*"naturelovers" + 0.006*"iphonography" + 0.006*"shotoniphone"
INFO 2022-10-28 14:59:42,830 ldamodel.py:1074] topic diff=0.207325, rho=0.252538
INFO 2022-10-28 14:59:42,830 ldamodel.py:1001] PROGRESS: pass 7, at document #200/768
INFO 2022-10-28 14:59:42,849 ldamodel.py:794] optimized alpha [0.19854744, 0.21851476, 0.17341262, 0.3581374, 0.12796117]
INFO 2022-10-28 14:59:42,850 ldamodel.py:233] merging changes from 100 documents into a model of 768 documents
INFO 2022-10-28 14:59:42,852 ldamodel.py:1196] topic #0 (0.199): 0.013*"job" + 0.011*"work" + 0.011*"life" + 0.010*"business" + 0.009*"make" + 0.009*"company" + 0.008*"go" + 0.008*"people" + 0.007*"futureofwork" + 0.007*"worker"
INFO 2022-10-28 14:59:42,852 ldamodel.py:1196] topic #1 (0.219): 0.014*"work" + 0.013*"meeting" + 0.009*"need" + 0.009*"time" + 0.008*"home" + 0.007*"zoom" + 0.007*"team" + 0.007*"coffee" + 0.007*"much" + 0.007*"amp"
INFO 2022-10-28 14:59:42,853 ldamodel.py:1196] topic #2 (0.173): 0.008*"morning" + 0.008*"think" + 0.008*"new" + 0.008*"another" + 0.007*"long" + 0.007*"open" + 0.006*"way" + 0.006*"let" + 0.006*"day" + 0.006*"entrepreneur"
INFO 2022-10-28 14:59:42,854 ldamodel.py:1196] topic #3 (0.358): 0.033*"work" + 0.025*"office" + 0.017*"home" + 0.015*"day" + 0.013*"working" + 0.011*"remote" + 0.011*"back" + 0.008*"today" + 0.008*"week" + 0.008*"one"
INFO 2022-10-28 14:59:42,854 ldamodel.py:1196] topic #4 (0.128): 0.018*"california" + 0.007*"change" + 0.007*"beach" + 0.007*"grateful" + 0.006*"park" + 0.006*"corporate" + 0.006*"employee" + 0.006*"done" + 0.005*"able" + 0.005*"nature"
INFO 2022-10-28 14:59:42,855 ldamodel.py:1074] topic diff=0.196952, rho=0.252538
INFO 2022-10-28 14:59:42,855 ldamodel.py:1001] PROGRESS: pass 7, at document #300/768
INFO 2022-10-28 14:59:42,877 ldamodel.py:794] optimized alpha [0.19501221, 0.21510164, 0.17639047, 0.33951125, 0.13136804]
INFO 2022-10-28 14:59:42,879 ldamodel.py:233] merging changes from 100 documents into a model of 768 documents
INFO 2022-10-28 14:59:42,880 ldamodel.py:1196] topic #0 (0.195): 0.014*"business" + 0.014*"work" + 0.011*"job" + 0.009*"life" + 0.008*"company" + 0.008*"career" + 0.008*"money" + 0.008*"dream" + 0.008*"love" + 0.008*"would"
INFO 2022-10-28 14:59:42,881 ldamodel.py:1196] topic #1 (0.215): 0.018*"work" + 0.012*"meeting" + 0.010*"time" + 0.010*"home" + 0.009*"coffee" + 0.008*"need" + 0.007*"got" + 0.007*"team" + 0.007*"much" + 0.006*"amp"</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>INFO 2022-10-28 14:59:42,882 ldamodel.py:1196] topic #2 (0.176): 0.011*"morning" + 0.009*"long" + 0.008*"let" + 0.008*"day" + 0.008*"entrepreneur" + 0.007*"place" + 0.006*"think" + 0.006*"another" + 0.006*"way" + 0.006*"new"
INFO 2022-10-28 14:59:42,882 ldamodel.py:1196] topic #3 (0.340): 0.040*"work" + 0.023*"office" + 0.021*"home" + 0.014*"day" + 0.012*"working" + 0.010*"back" + 0.010*"like" + 0.009*"today" + 0.009*"time" + 0.009*"remote"
INFO 2022-10-28 14:59:42,883 ldamodel.py:1196] topic #4 (0.131): 0.021*"california" + 0.009*"done" + 0.008*"home" + 0.007*"job" + 0.006*"realestate" + 0.006*"beach" + 0.006*"group" + 0.006*"corporate" + 0.006*"sold" + 0.005*"souza"
INFO 2022-10-28 14:59:42,883 ldamodel.py:1074] topic diff=0.192486, rho=0.252538
INFO 2022-10-28 14:59:42,884 ldamodel.py:1001] PROGRESS: pass 7, at document #400/768
INFO 2022-10-28 14:59:42,905 ldamodel.py:794] optimized alpha [0.1926478, 0.21691357, 0.18134464, 0.35671562, 0.12983914]
INFO 2022-10-28 14:59:42,907 ldamodel.py:233] merging changes from 100 documents into a model of 768 documents
INFO 2022-10-28 14:59:42,908 ldamodel.py:1196] topic #0 (0.193): 0.013*"work" + 0.013*"love" + 0.012*"job" + 0.012*"business" + 0.009*"life" + 0.009*"good" + 0.009*"go" + 0.009*"today" + 0.008*"entrepreneur" + 0.008*"dream"
INFO 2022-10-28 14:59:42,909 ldamodel.py:1196] topic #1 (0.217): 0.015*"work" + 0.011*"meeting" + 0.010*"need" + 0.009*"home" + 0.009*"time" + 0.009*"much" + 0.008*"coffee" + 0.007*"got" + 0.007*"even" + 0.006*"zoom"
INFO 2022-10-28 14:59:42,909 ldamodel.py:1196] topic #2 (0.181): 0.010*"morning" + 0.010*"entrepreneur" + 0.010*"let" + 0.009*"sunday" + 0.008*"day" + 0.007*"long" + 0.007*"check" + 0.007*"another" + 0.006*"tuesday" + 0.006*"think"
INFO 2022-10-28 14:59:42,910 ldamodel.py:1196] topic #3 (0.357): 0.034*"work" + 0.022*"office" + 0.020*"home" + 0.014*"day" + 0.010*"back" + 0.010*"working" + 0.010*"today" + 0.009*"like" + 0.009*"time" + 0.008*"new"
INFO 2022-10-28 14:59:42,910 ldamodel.py:1196] topic #4 (0.130): 0.021*"california" + 0.010*"done" + 0.009*"home" + 0.009*"realestate" + 0.009*"group" + 0.009*"job" + 0.008*"sold" + 0.007*"realestateagent" + 0.007*"realtorlife" + 0.007*"cloudoffice"
INFO 2022-10-28 14:59:42,911 ldamodel.py:1074] topic diff=0.189258, rho=0.252538
INFO 2022-10-28 14:59:42,911 ldamodel.py:1001] PROGRESS: pass 7, at document #500/768
INFO 2022-10-28 14:59:42,931 ldamodel.py:794] optimized alpha [0.19246511, 0.21768646, 0.18184827, 0.3557921, 0.1309934]
INFO 2022-10-28 14:59:42,932 ldamodel.py:233] merging changes from 100 documents into a model of 768 documents
INFO 2022-10-28 14:59:42,934 ldamodel.py:1196] topic #0 (0.192): 0.013*"love" + 0.013*"work" + 0.012*"job" + 0.011*"business" + 0.010*"life" + 0.009*"go" + 0.008*"make" + 0.008*"good" + 0.008*"today" + 0.008*"trying"
INFO 2022-10-28 14:59:42,935 ldamodel.py:1196] topic #1 (0.218): 0.016*"work" + 0.012*"need" + 0.010*"meeting" + 0.010*"home" + 0.009*"time" + 0.008*"much" + 0.007*"coffee" + 0.007*"zoom" + 0.007*"get" + 0.007*"even"
INFO 2022-10-28 14:59:42,935 ldamodel.py:1196] topic #2 (0.182): 0.011*"another" + 0.010*"entrepreneur" + 0.009*"morning" + 0.008*"day" + 0.008*"sunday" + 0.008*"let" + 0.007*"way" + 0.006*"job" + 0.006*"think" + 0.006*"tuesday"
INFO 2022-10-28 14:59:42,936 ldamodel.py:1196] topic #3 (0.356): 0.036*"work" + 0.021*"home" + 0.020*"office" + 0.013*"day" + 0.012*"working" + 0.010*"today" + 0.009*"week" + 0.009*"back" + 0.009*"like" + 0.008*"time"
INFO 2022-10-28 14:59:42,936 ldamodel.py:1196] topic #4 (0.131): 0.017*"california" + 0.014*"done" + 0.011*"realestate" + 0.011*"home" + 0.010*"job" + 0.010*"group" + 0.009*"sold" + 0.008*"soldgetting" + 0.008*"realestateagent" + 0.008*"souza"
INFO 2022-10-28 14:59:42,937 ldamodel.py:1074] topic diff=0.156125, rho=0.252538
INFO 2022-10-28 14:59:42,937 ldamodel.py:1001] PROGRESS: pass 7, at document #600/768
INFO 2022-10-28 14:59:42,955 ldamodel.py:794] optimized alpha [0.19763182, 0.22909868, 0.17920485, 0.36370614, 0.13410874]
INFO 2022-10-28 14:59:42,956 ldamodel.py:233] merging changes from 100 documents into a model of 768 documents
INFO 2022-10-28 14:59:42,958 ldamodel.py:1196] topic #0 (0.198): 0.013*"go" + 0.012*"job" + 0.012*"love" + 0.012*"work" + 0.011*"life" + 0.009*"today" + 0.009*"make" + 0.009*"trying" + 0.008*"business" + 0.008*"get"
INFO 2022-10-28 14:59:42,958 ldamodel.py:1196] topic #1 (0.229): 0.014*"work" + 0.012*"meeting" + 0.011*"need" + 0.009*"home" + 0.009*"time" + 0.008*"much" + 0.007*"get" + 0.007*"zoom" + 0.006*"got" + 0.006*"desk"
INFO 2022-10-28 14:59:42,959 ldamodel.py:1196] topic #2 (0.179): 0.009*"another" + 0.008*"let" + 0.008*"entrepreneur" + 0.008*"way" + 0.008*"day" + 0.007*"think" + 0.007*"morning" + 0.007*"long" + 0.006*"job" + 0.006*"tuesday"
INFO 2022-10-28 14:59:42,960 ldamodel.py:1196] topic #3 (0.364): 0.033*"work" + 0.022*"office" + 0.021*"home" + 0.014*"day" + 0.014*"working" + 0.013*"today" + 0.009*"like" + 0.009*"back" + 0.008*"week" + 0.008*"one"
INFO 2022-10-28 14:59:42,960 ldamodel.py:1196] topic #4 (0.134): 0.018*"california" + 0.014*"done" + 0.010*"home" + 0.009*"realestate" + 0.008*"job" + 0.008*"group" + 0.007*"sold" + 0.007*"covid" + 0.007*"souza" + 0.007*"soldgetting"
INFO 2022-10-28 14:59:42,961 ldamodel.py:1074] topic diff=0.190397, rho=0.252538
INFO 2022-10-28 14:59:42,961 ldamodel.py:1001] PROGRESS: pass 7, at document #700/768
INFO 2022-10-28 14:59:42,978 ldamodel.py:794] optimized alpha [0.19961515, 0.23169112, 0.17800336, 0.38491225, 0.13434616]
INFO 2022-10-28 14:59:42,979 ldamodel.py:233] merging changes from 100 documents into a model of 768 documents
INFO 2022-10-28 14:59:42,981 ldamodel.py:1196] topic #0 (0.200): 0.012*"work" + 0.012*"go" + 0.011*"love" + 0.011*"job" + 0.011*"today" + 0.010*"life" + 0.008*"day" + 0.008*"get" + 0.008*"make" + 0.007*"business"
INFO 2022-10-28 14:59:42,982 ldamodel.py:1196] topic #1 (0.232): 0.013*"work" + 0.013*"meeting" + 0.011*"need" + 0.008*"home" + 0.008*"time" + 0.008*"get" + 0.006*"zoom" + 0.006*"much" + 0.006*"amp" + 0.006*"first"
INFO 2022-10-28 14:59:42,983 ldamodel.py:1196] topic #2 (0.178): 0.009*"think" + 0.008*"tuesday" + 0.008*"way" + 0.007*"let" + 0.007*"morning" + 0.007*"long" + 0.007*"another" + 0.007*"spring" + 0.006*"day" + 0.006*"entrepreneur"
INFO 2022-10-28 14:59:42,984 ldamodel.py:1196] topic #3 (0.385): 0.032*"work" + 0.023*"office" + 0.020*"home" + 0.015*"day" + 0.014*"working" + 0.012*"today" + 0.009*"one" + 0.009*"back" + 0.008*"like" + 0.008*"week"
INFO 2022-10-28 14:59:42,984 ldamodel.py:1196] topic #4 (0.134): 0.017*"california" + 0.014*"done" + 0.008*"employee" + 0.008*"home" + 0.007*"job" + 0.007*"corporate" + 0.007*"realestate" + 0.006*"group" + 0.006*"los" + 0.006*"angeles"
INFO 2022-10-28 14:59:42,985 ldamodel.py:1074] topic diff=0.172179, rho=0.252538
INFO 2022-10-28 14:59:43,003 ldamodel.py:847] -8.844 per-word bound, 459.4 perplexity estimate based on a held-out corpus of 68 documents with 815 words
INFO 2022-10-28 14:59:43,003 ldamodel.py:1001] PROGRESS: pass 7, at document #768/768
INFO 2022-10-28 14:59:43,013 ldamodel.py:794] optimized alpha [0.20366377, 0.23252155, 0.18160377, 0.39002174, 0.13150887]
INFO 2022-10-28 14:59:43,015 ldamodel.py:233] merging changes from 68 documents into a model of 768 documents
INFO 2022-10-28 14:59:43,017 ldamodel.py:1196] topic #0 (0.204): 0.013*"life" + 0.013*"go" + 0.011*"work" + 0.011*"job" + 0.010*"love" + 0.010*"make" + 0.009*"today" + 0.009*"would" + 0.009*"day" + 0.008*"good"
INFO 2022-10-28 14:59:43,017 ldamodel.py:1196] topic #1 (0.233): 0.012*"meeting" + 0.011*"work" + 0.011*"need" + 0.009*"team" + 0.009*"zoom" + 0.008*"home" + 0.007*"coffee" + 0.007*"got" + 0.007*"time" + 0.006*"desk"
INFO 2022-10-28 14:59:43,018 ldamodel.py:1196] topic #2 (0.182): 0.011*"new" + 0.009*"morning" + 0.008*"way" + 0.008*"think" + 0.008*"let" + 0.007*"long" + 0.007*"another" + 0.007*"day" + 0.006*"spring" + 0.006*"tuesday"
INFO 2022-10-28 14:59:43,019 ldamodel.py:1196] topic #3 (0.390): 0.029*"work" + 0.024*"office" + 0.019*"day" + 0.019*"home" + 0.013*"back" + 0.013*"working" + 0.010*"today" + 0.010*"one" + 0.009*"week" + 0.009*"time"
INFO 2022-10-28 14:59:43,019 ldamodel.py:1196] topic #4 (0.132): 0.015*"california" + 0.011*"done" + 0.009*"employee" + 0.008*"covid" + 0.008*"beach" + 0.007*"home" + 0.006*"job" + 0.005*"corporate" + 0.005*"realestate" + 0.005*"ready"</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>INFO 2022-10-28 14:59:43,020 ldamodel.py:1074] topic diff=0.143590, rho=0.252538
INFO 2022-10-28 14:59:43,020 ldamodel.py:1001] PROGRESS: pass 8, at document #100/768
INFO 2022-10-28 14:59:43,040 ldamodel.py:794] optimized alpha [0.19523601, 0.21186434, 0.17213966, 0.36104685, 0.12920968]
INFO 2022-10-28 14:59:43,041 ldamodel.py:233] merging changes from 100 documents into a model of 768 documents
INFO 2022-10-28 14:59:43,043 ldamodel.py:1196] topic #0 (0.195): 0.011*"job" + 0.011*"work" + 0.010*"life" + 0.010*"go" + 0.010*"make" + 0.008*"love" + 0.008*"people" + 0.007*"business" + 0.007*"day" + 0.007*"today"
INFO 2022-10-28 14:59:43,043 ldamodel.py:1196] topic #1 (0.212): 0.012*"meeting" + 0.012*"work" + 0.010*"need" + 0.008*"team" + 0.008*"zoom" + 0.008*"coffee" + 0.007*"time" + 0.007*"much" + 0.007*"home" + 0.006*"even"
INFO 2022-10-28 14:59:43,044 ldamodel.py:1196] topic #2 (0.172): 0.009*"new" + 0.009*"morning" + 0.007*"way" + 0.007*"another" + 0.006*"think" + 0.006*"let" + 0.006*"world" + 0.006*"long" + 0.006*"open" + 0.006*"day"
INFO 2022-10-28 14:59:43,045 ldamodel.py:1196] topic #3 (0.361): 0.028*"work" + 0.026*"office" + 0.016*"home" + 0.016*"day" + 0.012*"working" + 0.012*"back" + 0.010*"today" + 0.010*"week" + 0.009*"one" + 0.008*"time"
INFO 2022-10-28 14:59:43,045 ldamodel.py:1196] topic #4 (0.129): 0.021*"california" + 0.008*"park" + 0.007*"done" + 0.007*"employee" + 0.007*"beach" + 0.006*"nature" + 0.006*"covid" + 0.006*"shotoniphone" + 0.006*"mvt" + 0.006*"iphonography"
INFO 2022-10-28 14:59:43,046 ldamodel.py:1074] topic diff=0.197428, rho=0.244851
INFO 2022-10-28 14:59:43,046 ldamodel.py:1001] PROGRESS: pass 8, at document #200/768
INFO 2022-10-28 14:59:43,067 ldamodel.py:794] optimized alpha [0.19790609, 0.2170534, 0.17298535, 0.35618418, 0.12694]
INFO 2022-10-28 14:59:43,068 ldamodel.py:233] merging changes from 100 documents into a model of 768 documents
INFO 2022-10-28 14:59:43,070 ldamodel.py:1196] topic #0 (0.198): 0.013*"job" + 0.011*"work" + 0.011*"life" + 0.010*"business" + 0.009*"make" + 0.009*"company" + 0.008*"go" + 0.008*"people" + 0.007*"futureofwork" + 0.007*"worker"
INFO 2022-10-28 14:59:43,070 ldamodel.py:1196] topic #1 (0.217): 0.014*"work" + 0.013*"meeting" + 0.009*"need" + 0.008*"time" + 0.008*"home" + 0.007*"zoom" + 0.007*"team" + 0.007*"coffee" + 0.007*"much" + 0.007*"amp"
INFO 2022-10-28 14:59:43,071 ldamodel.py:1196] topic #2 (0.173): 0.008*"morning" + 0.008*"think" + 0.008*"new" + 0.008*"another" + 0.007*"long" + 0.007*"open" + 0.006*"way" + 0.006*"let" + 0.006*"day" + 0.006*"entrepreneur"
INFO 2022-10-28 14:59:43,072 ldamodel.py:1196] topic #3 (0.356): 0.033*"work" + 0.025*"office" + 0.017*"home" + 0.015*"day" + 0.013*"working" + 0.011*"remote" + 0.011*"back" + 0.008*"today" + 0.008*"week" + 0.008*"one"
INFO 2022-10-28 14:59:43,072 ldamodel.py:1196] topic #4 (0.127): 0.018*"california" + 0.007*"beach" + 0.007*"change" + 0.006*"grateful" + 0.006*"park" + 0.006*"corporate" + 0.006*"done" + 0.006*"employee" + 0.005*"able" + 0.005*"nature"
INFO 2022-10-28 14:59:43,073 ldamodel.py:1074] topic diff=0.187709, rho=0.244851
INFO 2022-10-28 14:59:43,074 ldamodel.py:1001] PROGRESS: pass 8, at document #300/768
INFO 2022-10-28 14:59:43,092 ldamodel.py:794] optimized alpha [0.19442382, 0.213719, 0.17579472, 0.33734345, 0.1299374]
INFO 2022-10-28 14:59:43,094 ldamodel.py:233] merging changes from 100 documents into a model of 768 documents
INFO 2022-10-28 14:59:43,095 ldamodel.py:1196] topic #0 (0.194): 0.014*"business" + 0.014*"work" + 0.011*"job" + 0.009*"life" + 0.008*"company" + 0.008*"love" + 0.008*"career" + 0.008*"money" + 0.008*"dream" + 0.008*"would"
INFO 2022-10-28 14:59:43,096 ldamodel.py:1196] topic #1 (0.214): 0.017*"work" + 0.012*"meeting" + 0.010*"home" + 0.009*"coffee" + 0.009*"time" + 0.008*"need" + 0.007*"got" + 0.007*"team" + 0.007*"much" + 0.006*"amp"
INFO 2022-10-28 14:59:43,097 ldamodel.py:1196] topic #2 (0.176): 0.011*"morning" + 0.009*"long" + 0.008*"let" + 0.008*"day" + 0.008*"entrepreneur" + 0.006*"think" + 0.006*"place" + 0.006*"another" + 0.006*"way" + 0.006*"new"
INFO 2022-10-28 14:59:43,097 ldamodel.py:1196] topic #3 (0.337): 0.040*"work" + 0.024*"office" + 0.021*"home" + 0.014*"day" + 0.012*"working" + 0.010*"back" + 0.010*"like" + 0.010*"time" + 0.009*"remote" + 0.009*"today"
INFO 2022-10-28 14:59:43,098 ldamodel.py:1196] topic #4 (0.130): 0.020*"california" + 0.009*"done" + 0.008*"home" + 0.007*"job" + 0.006*"realestate" + 0.006*"beach" + 0.006*"group" + 0.006*"corporate" + 0.006*"sold" + 0.005*"listed"
INFO 2022-10-28 14:59:43,098 ldamodel.py:1074] topic diff=0.183588, rho=0.244851
INFO 2022-10-28 14:59:43,099 ldamodel.py:1001] PROGRESS: pass 8, at document #400/768
INFO 2022-10-28 14:59:43,117 ldamodel.py:794] optimized alpha [0.19212124, 0.21544354, 0.18057248, 0.35385057, 0.12853988]
INFO 2022-10-28 14:59:43,119 ldamodel.py:233] merging changes from 100 documents into a model of 768 documents
INFO 2022-10-28 14:59:43,120 ldamodel.py:1196] topic #0 (0.192): 0.014*"love" + 0.013*"work" + 0.012*"job" + 0.012*"business" + 0.009*"life" + 0.009*"good" + 0.009*"go" + 0.009*"today" + 0.008*"entrepreneur" + 0.008*"dream"
INFO 2022-10-28 14:59:43,121 ldamodel.py:1196] topic #1 (0.215): 0.015*"work" + 0.011*"meeting" + 0.010*"need" + 0.009*"home" + 0.008*"much" + 0.008*"time" + 0.008*"coffee" + 0.007*"got" + 0.007*"even" + 0.006*"zoom"
INFO 2022-10-28 14:59:43,122 ldamodel.py:1196] topic #2 (0.181): 0.010*"morning" + 0.010*"entrepreneur" + 0.010*"let" + 0.009*"sunday" + 0.008*"day" + 0.007*"long" + 0.007*"check" + 0.007*"another" + 0.006*"monday" + 0.006*"tuesday"
INFO 2022-10-28 14:59:43,122 ldamodel.py:1196] topic #3 (0.354): 0.034*"work" + 0.022*"office" + 0.020*"home" + 0.014*"day" + 0.010*"working" + 0.010*"back" + 0.010*"today" + 0.009*"like" + 0.009*"time" + 0.008*"new"
INFO 2022-10-28 14:59:43,123 ldamodel.py:1196] topic #4 (0.129): 0.021*"california" + 0.010*"done" + 0.009*"home" + 0.009*"realestate" + 0.009*"group" + 0.009*"job" + 0.008*"sold" + 0.007*"realestateagent" + 0.007*"homesales" + 0.007*"cloudoffice"
INFO 2022-10-28 14:59:43,123 ldamodel.py:1074] topic diff=0.180732, rho=0.244851
INFO 2022-10-28 14:59:43,124 ldamodel.py:1001] PROGRESS: pass 8, at document #500/768
INFO 2022-10-28 14:59:43,143 ldamodel.py:794] optimized alpha [0.19191836, 0.21626358, 0.18108477, 0.35319152, 0.12971099]
INFO 2022-10-28 14:59:43,144 ldamodel.py:233] merging changes from 100 documents into a model of 768 documents
INFO 2022-10-28 14:59:43,145 ldamodel.py:1196] topic #0 (0.192): 0.013*"love" + 0.013*"work" + 0.012*"job" + 0.011*"business" + 0.010*"life" + 0.009*"go" + 0.008*"today" + 0.008*"make" + 0.008*"good" + 0.008*"trying"
INFO 2022-10-28 14:59:43,146 ldamodel.py:1196] topic #1 (0.216): 0.016*"work" + 0.011*"need" + 0.010*"meeting" + 0.010*"home" + 0.009*"time" + 0.008*"much" + 0.007*"coffee" + 0.007*"zoom" + 0.007*"get" + 0.007*"even"
INFO 2022-10-28 14:59:43,147 ldamodel.py:1196] topic #2 (0.181): 0.011*"another" + 0.010*"entrepreneur" + 0.009*"morning" + 0.008*"day" + 0.008*"sunday" + 0.008*"let" + 0.007*"way" + 0.006*"think" + 0.006*"job" + 0.006*"tuesday"
INFO 2022-10-28 14:59:43,148 ldamodel.py:1196] topic #3 (0.353): 0.036*"work" + 0.021*"home" + 0.020*"office" + 0.013*"day" + 0.012*"working" + 0.010*"today" + 0.009*"week" + 0.009*"back" + 0.009*"like" + 0.008*"time"
INFO 2022-10-28 14:59:43,148 ldamodel.py:1196] topic #4 (0.130): 0.017*"california" + 0.014*"done" + 0.011*"realestate" + 0.010*"home" + 0.010*"job" + 0.010*"group" + 0.009*"sold" + 0.008*"realtorlife" + 0.008*"homesales" + 0.008*"soldgetting"
INFO 2022-10-28 14:59:43,149 ldamodel.py:1074] topic diff=0.149108, rho=0.244851
INFO 2022-10-28 14:59:43,149 ldamodel.py:1001] PROGRESS: pass 8, at document #600/768
INFO 2022-10-28 14:59:43,167 ldamodel.py:794] optimized alpha [0.19691882, 0.22730732, 0.17855841, 0.36111742, 0.13276738]
INFO 2022-10-28 14:59:43,169 ldamodel.py:233] merging changes from 100 documents into a model of 768 documents
INFO 2022-10-28 14:59:43,170 ldamodel.py:1196] topic #0 (0.197): 0.013*"go" + 0.012*"love" + 0.012*"job" + 0.011*"work" + 0.011*"life" + 0.010*"today" + 0.009*"make" + 0.009*"trying" + 0.008*"business" + 0.008*"day"</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>INFO 2022-10-28 14:59:43,171 ldamodel.py:1196] topic #1 (0.227): 0.014*"work" + 0.012*"meeting" + 0.011*"need" + 0.009*"home" + 0.008*"time" + 0.008*"much" + 0.007*"get" + 0.007*"zoom" + 0.006*"got" + 0.006*"coffee"
INFO 2022-10-28 14:59:43,172 ldamodel.py:1196] topic #2 (0.179): 0.009*"another" + 0.008*"let" + 0.008*"entrepreneur" + 0.008*"way" + 0.008*"day" + 0.007*"morning" + 0.007*"think" + 0.007*"long" + 0.006*"job" + 0.006*"tuesday"
INFO 2022-10-28 14:59:43,172 ldamodel.py:1196] topic #3 (0.361): 0.033*"work" + 0.022*"office" + 0.021*"home" + 0.014*"day" + 0.014*"working" + 0.012*"today" + 0.009*"like" + 0.009*"back" + 0.009*"week" + 0.008*"time"
INFO 2022-10-28 14:59:43,173 ldamodel.py:1196] topic #4 (0.133): 0.018*"california" + 0.014*"done" + 0.010*"home" + 0.008*"realestate" + 0.008*"job" + 0.008*"group" + 0.007*"sold" + 0.007*"covid" + 0.007*"realestateagent" + 0.007*"soldgetting"
INFO 2022-10-28 14:59:43,173 ldamodel.py:1074] topic diff=0.181754, rho=0.244851
INFO 2022-10-28 14:59:43,174 ldamodel.py:1001] PROGRESS: pass 8, at document #700/768
INFO 2022-10-28 14:59:43,193 ldamodel.py:794] optimized alpha [0.19879279, 0.22984152, 0.17738771, 0.3815902, 0.13269831]
INFO 2022-10-28 14:59:43,195 ldamodel.py:233] merging changes from 100 documents into a model of 768 documents
INFO 2022-10-28 14:59:43,197 ldamodel.py:1196] topic #0 (0.199): 0.012*"work" + 0.012*"go" + 0.011*"love" + 0.011*"today" + 0.011*"job" + 0.010*"life" + 0.008*"day" + 0.008*"get" + 0.008*"make" + 0.007*"business"
INFO 2022-10-28 14:59:43,197 ldamodel.py:1196] topic #1 (0.230): 0.013*"work" + 0.013*"meeting" + 0.011*"need" + 0.008*"home" + 0.008*"get" + 0.008*"time" + 0.006*"zoom" + 0.006*"much" + 0.006*"amp" + 0.005*"today"
INFO 2022-10-28 14:59:43,198 ldamodel.py:1196] topic #2 (0.177): 0.009*"think" + 0.008*"tuesday" + 0.008*"way" + 0.007*"let" + 0.007*"morning" + 0.007*"another" + 0.007*"long" + 0.007*"spring" + 0.006*"day" + 0.006*"entrepreneur"
INFO 2022-10-28 14:59:43,198 ldamodel.py:1196] topic #3 (0.382): 0.032*"work" + 0.023*"office" + 0.020*"home" + 0.015*"day" + 0.014*"working" + 0.012*"today" + 0.009*"one" + 0.009*"back" + 0.008*"like" + 0.008*"week"
INFO 2022-10-28 14:59:43,199 ldamodel.py:1196] topic #4 (0.133): 0.016*"california" + 0.013*"done" + 0.008*"home" + 0.008*"employee" + 0.007*"job" + 0.007*"corporate" + 0.007*"realestate" + 0.006*"group" + 0.006*"sold" + 0.006*"angeles"
INFO 2022-10-28 14:59:43,199 ldamodel.py:1074] topic diff=0.164128, rho=0.244851
INFO 2022-10-28 14:59:43,219 ldamodel.py:847] -8.813 per-word bound, 449.7 perplexity estimate based on a held-out corpus of 68 documents with 815 words
INFO 2022-10-28 14:59:43,220 ldamodel.py:1001] PROGRESS: pass 8, at document #768/768
INFO 2022-10-28 14:59:43,229 ldamodel.py:794] optimized alpha [0.20266965, 0.23068245, 0.18151493, 0.38633075, 0.12919497]
INFO 2022-10-28 14:59:43,231 ldamodel.py:233] merging changes from 68 documents into a model of 768 documents
INFO 2022-10-28 14:59:43,232 ldamodel.py:1196] topic #0 (0.203): 0.013*"life" + 0.013*"go" + 0.011*"work" + 0.011*"love" + 0.011*"job" + 0.010*"make" + 0.009*"today" + 0.009*"would" + 0.009*"day" + 0.008*"good"
INFO 2022-10-28 14:59:43,233 ldamodel.py:1196] topic #1 (0.231): 0.012*"meeting" + 0.011*"work" + 0.011*"need" + 0.009*"team" + 0.009*"zoom" + 0.008*"home" + 0.007*"coffee" + 0.007*"got" + 0.006*"time" + 0.006*"even"
INFO 2022-10-28 14:59:43,233 ldamodel.py:1196] topic #2 (0.182): 0.011*"new" + 0.010*"morning" + 0.008*"way" + 0.008*"think" + 0.008*"let" + 0.007*"another" + 0.007*"long" + 0.007*"day" + 0.007*"monday" + 0.006*"spring"
INFO 2022-10-28 14:59:43,234 ldamodel.py:1196] topic #3 (0.386): 0.030*"work" + 0.024*"office" + 0.019*"day" + 0.019*"home" + 0.013*"working" + 0.013*"back" + 0.010*"today" + 0.010*"one" + 0.009*"time" + 0.009*"week"
INFO 2022-10-28 14:59:43,235 ldamodel.py:1196] topic #4 (0.129): 0.014*"california" + 0.011*"done" + 0.009*"employee" + 0.008*"covid" + 0.008*"beach" + 0.007*"home" + 0.006*"job" + 0.005*"corporate" + 0.005*"realestate" + 0.005*"ready"
INFO 2022-10-28 14:59:43,235 ldamodel.py:1074] topic diff=0.137091, rho=0.244851
INFO 2022-10-28 14:59:43,236 ldamodel.py:1001] PROGRESS: pass 9, at document #100/768
INFO 2022-10-28 14:59:43,254 ldamodel.py:794] optimized alpha [0.19455388, 0.21093568, 0.1722666, 0.35874233, 0.12715667]
INFO 2022-10-28 14:59:43,255 ldamodel.py:233] merging changes from 100 documents into a model of 768 documents
INFO 2022-10-28 14:59:43,257 ldamodel.py:1196] topic #0 (0.195): 0.011*"job" + 0.011*"work" + 0.010*"life" + 0.010*"go" + 0.010*"make" + 0.008*"love" + 0.007*"people" + 0.007*"today" + 0.007*"business" + 0.007*"day"
INFO 2022-10-28 14:59:43,258 ldamodel.py:1196] topic #1 (0.211): 0.012*"meeting" + 0.012*"work" + 0.010*"need" + 0.008*"team" + 0.008*"zoom" + 0.008*"coffee" + 0.007*"home" + 0.007*"much" + 0.007*"time" + 0.006*"even"
INFO 2022-10-28 14:59:43,258 ldamodel.py:1196] topic #2 (0.172): 0.010*"morning" + 0.009*"new" + 0.007*"way" + 0.007*"another" + 0.006*"think" + 0.006*"let" + 0.006*"long" + 0.006*"world" + 0.006*"day" + 0.006*"open"
INFO 2022-10-28 14:59:43,259 ldamodel.py:1196] topic #3 (0.359): 0.029*"work" + 0.027*"office" + 0.016*"home" + 0.016*"day" + 0.012*"working" + 0.012*"back" + 0.010*"today" + 0.010*"week" + 0.010*"one" + 0.009*"time"
INFO 2022-10-28 14:59:43,260 ldamodel.py:1196] topic #4 (0.127): 0.021*"california" + 0.008*"park" + 0.007*"done" + 0.007*"employee" + 0.007*"beach" + 0.006*"covid" + 0.006*"nature" + 0.006*"naturelovers" + 0.006*"mvt" + 0.006*"iphonography"
INFO 2022-10-28 14:59:43,260 ldamodel.py:1074] topic diff=0.189207, rho=0.237826
INFO 2022-10-28 14:59:43,261 ldamodel.py:1001] PROGRESS: pass 9, at document #200/768
INFO 2022-10-28 14:59:43,280 ldamodel.py:794] optimized alpha [0.19714257, 0.21597257, 0.17302631, 0.35419002, 0.12512289]
INFO 2022-10-28 14:59:43,282 ldamodel.py:233] merging changes from 100 documents into a model of 768 documents
INFO 2022-10-28 14:59:43,283 ldamodel.py:1196] topic #0 (0.197): 0.013*"job" + 0.011*"work" + 0.010*"life" + 0.010*"business" + 0.009*"make" + 0.009*"company" + 0.008*"go" + 0.008*"people" + 0.007*"futureofwork" + 0.007*"worker"
INFO 2022-10-28 14:59:43,284 ldamodel.py:1196] topic #1 (0.216): 0.014*"work" + 0.013*"meeting" + 0.009*"need" + 0.008*"home" + 0.008*"time" + 0.007*"zoom" + 0.007*"amp" + 0.007*"team" + 0.007*"coffee" + 0.007*"much"
INFO 2022-10-28 14:59:43,285 ldamodel.py:1196] topic #2 (0.173): 0.009*"morning" + 0.008*"new" + 0.008*"think" + 0.008*"another" + 0.007*"long" + 0.007*"open" + 0.006*"way" + 0.006*"let" + 0.006*"day" + 0.006*"entrepreneur"
INFO 2022-10-28 14:59:43,286 ldamodel.py:1196] topic #3 (0.354): 0.033*"work" + 0.025*"office" + 0.017*"home" + 0.015*"day" + 0.013*"working" + 0.011*"remote" + 0.011*"back" + 0.008*"today" + 0.008*"week" + 0.008*"one"
INFO 2022-10-28 14:59:43,286 ldamodel.py:1196] topic #4 (0.125): 0.017*"california" + 0.007*"beach" + 0.007*"change" + 0.006*"grateful" + 0.006*"park" + 0.006*"corporate" + 0.006*"done" + 0.006*"employee" + 0.005*"able" + 0.005*"covid"
INFO 2022-10-28 14:59:43,287 ldamodel.py:1074] topic diff=0.179994, rho=0.237826
INFO 2022-10-28 14:59:43,287 ldamodel.py:1001] PROGRESS: pass 9, at document #300/768
INFO 2022-10-28 14:59:43,306 ldamodel.py:794] optimized alpha [0.19365858, 0.21272981, 0.17560671, 0.33543524, 0.12665784]
INFO 2022-10-28 14:59:43,307 ldamodel.py:233] merging changes from 100 documents into a model of 768 documents
INFO 2022-10-28 14:59:43,309 ldamodel.py:1196] topic #0 (0.194): 0.014*"business" + 0.014*"work" + 0.011*"job" + 0.009*"life" + 0.008*"company" + 0.008*"love" + 0.008*"career" + 0.008*"money" + 0.008*"dream" + 0.007*"would"
INFO 2022-10-28 14:59:43,309 ldamodel.py:1196] topic #1 (0.213): 0.018*"work" + 0.012*"meeting" + 0.010*"home" + 0.009*"coffee" + 0.009*"time" + 0.008*"need" + 0.007*"got" + 0.007*"team" + 0.007*"much" + 0.006*"amp"
INFO 2022-10-28 14:59:43,310 ldamodel.py:1196] topic #2 (0.176): 0.011*"morning" + 0.009*"long" + 0.008*"day" + 0.008*"let" + 0.007*"entrepreneur" + 0.006*"think" + 0.006*"place" + 0.006*"another" + 0.006*"way" + 0.006*"new"
INFO 2022-10-28 14:59:43,311 ldamodel.py:1196] topic #3 (0.335): 0.039*"work" + 0.024*"office" + 0.021*"home" + 0.014*"day" + 0.012*"working" + 0.010*"back" + 0.010*"like" + 0.010*"time" + 0.009*"remote" + 0.009*"today"</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>INFO 2022-10-28 14:59:43,312 ldamodel.py:1196] topic #4 (0.127): 0.017*"california" + 0.009*"done" + 0.008*"home" + 0.007*"job" + 0.006*"realestate" + 0.006*"beach" + 0.006*"group" + 0.006*"corporate" + 0.006*"sold" + 0.005*"realtorlife"
INFO 2022-10-28 14:59:43,312 ldamodel.py:1074] topic diff=0.175399, rho=0.237826
INFO 2022-10-28 14:59:43,313 ldamodel.py:1001] PROGRESS: pass 9, at document #400/768
INFO 2022-10-28 14:59:43,330 ldamodel.py:794] optimized alpha [0.19129007, 0.21349482, 0.1801305, 0.35095918, 0.12550944]
INFO 2022-10-28 14:59:43,331 ldamodel.py:233] merging changes from 100 documents into a model of 768 documents
INFO 2022-10-28 14:59:43,332 ldamodel.py:1196] topic #0 (0.191): 0.014*"love" + 0.013*"work" + 0.012*"job" + 0.012*"business" + 0.009*"life" + 0.009*"go" + 0.009*"good" + 0.009*"today" + 0.008*"entrepreneur" + 0.008*"dream"
INFO 2022-10-28 14:59:43,333 ldamodel.py:1196] topic #1 (0.213): 0.015*"work" + 0.011*"meeting" + 0.010*"need" + 0.009*"home" + 0.008*"much" + 0.008*"time" + 0.008*"coffee" + 0.007*"got" + 0.007*"even" + 0.006*"zoom"
INFO 2022-10-28 14:59:43,333 ldamodel.py:1196] topic #2 (0.180): 0.011*"morning" + 0.010*"entrepreneur" + 0.010*"let" + 0.009*"sunday" + 0.008*"day" + 0.007*"monday" + 0.007*"long" + 0.007*"another" + 0.007*"check" + 0.006*"tuesday"
INFO 2022-10-28 14:59:43,334 ldamodel.py:1196] topic #3 (0.351): 0.034*"work" + 0.023*"office" + 0.020*"home" + 0.014*"day" + 0.010*"working" + 0.010*"back" + 0.010*"today" + 0.009*"like" + 0.009*"time" + 0.008*"new"
INFO 2022-10-28 14:59:43,334 ldamodel.py:1196] topic #4 (0.126): 0.018*"california" + 0.010*"done" + 0.009*"home" + 0.009*"realestate" + 0.009*"group" + 0.009*"job" + 0.008*"sold" + 0.007*"homesales" + 0.007*"realestateagent" + 0.007*"souza"
INFO 2022-10-28 14:59:43,334 ldamodel.py:1074] topic diff=0.173647, rho=0.237826
INFO 2022-10-28 14:59:43,335 ldamodel.py:1001] PROGRESS: pass 9, at document #500/768
INFO 2022-10-28 14:59:43,352 ldamodel.py:794] optimized alpha [0.19107221, 0.21438576, 0.18058686, 0.3504023, 0.12678832]
INFO 2022-10-28 14:59:43,354 ldamodel.py:233] merging changes from 100 documents into a model of 768 documents
INFO 2022-10-28 14:59:43,355 ldamodel.py:1196] topic #0 (0.191): 0.013*"love" + 0.013*"work" + 0.012*"job" + 0.011*"business" + 0.010*"life" + 0.009*"go" + 0.009*"today" + 0.008*"make" + 0.008*"good" + 0.008*"trying"
INFO 2022-10-28 14:59:43,355 ldamodel.py:1196] topic #1 (0.214): 0.016*"work" + 0.011*"need" + 0.010*"meeting" + 0.010*"home" + 0.009*"time" + 0.008*"much" + 0.007*"coffee" + 0.007*"zoom" + 0.007*"get" + 0.007*"even"
INFO 2022-10-28 14:59:43,356 ldamodel.py:1196] topic #2 (0.181): 0.011*"another" + 0.010*"entrepreneur" + 0.010*"morning" + 0.008*"day" + 0.008*"let" + 0.007*"sunday" + 0.007*"way" + 0.006*"think" + 0.006*"monday" + 0.006*"job"
INFO 2022-10-28 14:59:43,356 ldamodel.py:1196] topic #3 (0.350): 0.036*"work" + 0.021*"home" + 0.021*"office" + 0.013*"day" + 0.012*"working" + 0.010*"today" + 0.009*"back" + 0.009*"week" + 0.009*"like" + 0.008*"time"
INFO 2022-10-28 14:59:43,357 ldamodel.py:1196] topic #4 (0.127): 0.015*"california" + 0.014*"done" + 0.011*"realestate" + 0.010*"home" + 0.010*"job" + 0.010*"group" + 0.009*"sold" + 0.008*"soldgetting" + 0.008*"souza" + 0.008*"cloudoffice"
INFO 2022-10-28 14:59:43,357 ldamodel.py:1074] topic diff=0.143247, rho=0.237826
INFO 2022-10-28 14:59:43,358 ldamodel.py:1001] PROGRESS: pass 9, at document #600/768
INFO 2022-10-28 14:59:43,375 ldamodel.py:794] optimized alpha [0.19586122, 0.22453654, 0.17769693, 0.3584203, 0.12983666]
INFO 2022-10-28 14:59:43,376 ldamodel.py:233] merging changes from 100 documents into a model of 768 documents
INFO 2022-10-28 14:59:43,378 ldamodel.py:1196] topic #0 (0.196): 0.013*"go" + 0.012*"love" + 0.012*"job" + 0.011*"work" + 0.011*"life" + 0.010*"today" + 0.009*"make" + 0.009*"trying" + 0.008*"business" + 0.008*"day"
INFO 2022-10-28 14:59:43,378 ldamodel.py:1196] topic #1 (0.225): 0.014*"work" + 0.012*"meeting" + 0.011*"need" + 0.009*"home" + 0.008*"time" + 0.008*"much" + 0.007*"get" + 0.007*"zoom" + 0.006*"got" + 0.006*"coffee"
INFO 2022-10-28 14:59:43,379 ldamodel.py:1196] topic #2 (0.178): 0.009*"another" + 0.008*"let" + 0.008*"entrepreneur" + 0.008*"way" + 0.008*"morning" + 0.008*"day" + 0.007*"think" + 0.007*"long" + 0.006*"job" + 0.006*"sunday"
INFO 2022-10-28 14:59:43,379 ldamodel.py:1196] topic #3 (0.358): 0.033*"work" + 0.022*"office" + 0.021*"home" + 0.014*"day" + 0.014*"working" + 0.012*"today" + 0.009*"like" + 0.009*"back" + 0.009*"week" + 0.008*"time"
INFO 2022-10-28 14:59:43,380 ldamodel.py:1196] topic #4 (0.130): 0.016*"california" + 0.014*"done" + 0.009*"home" + 0.008*"realestate" + 0.008*"job" + 0.008*"group" + 0.007*"sold" + 0.007*"covid" + 0.007*"homesales" + 0.007*"souza"
INFO 2022-10-28 14:59:43,380 ldamodel.py:1074] topic diff=0.174264, rho=0.237826
INFO 2022-10-28 14:59:43,381 ldamodel.py:1001] PROGRESS: pass 9, at document #700/768
INFO 2022-10-28 14:59:43,398 ldamodel.py:794] optimized alpha [0.19765125, 0.22712718, 0.17655128, 0.3781686, 0.12992127]
INFO 2022-10-28 14:59:43,399 ldamodel.py:233] merging changes from 100 documents into a model of 768 documents
INFO 2022-10-28 14:59:43,400 ldamodel.py:1196] topic #0 (0.198): 0.012*"work" + 0.012*"go" + 0.011*"love" + 0.011*"today" + 0.011*"job" + 0.010*"life" + 0.008*"day" + 0.008*"get" + 0.008*"make" + 0.007*"business"
INFO 2022-10-28 14:59:43,401 ldamodel.py:1196] topic #1 (0.227): 0.013*"work" + 0.012*"meeting" + 0.011*"need" + 0.008*"home" + 0.008*"get" + 0.007*"time" + 0.006*"zoom" + 0.006*"much" + 0.006*"amp" + 0.005*"today"
INFO 2022-10-28 14:59:43,401 ldamodel.py:1196] topic #2 (0.177): 0.009*"think" + 0.008*"tuesday" + 0.008*"way" + 0.008*"morning" + 0.007*"let" + 0.007*"another" + 0.007*"long" + 0.006*"spring" + 0.006*"day" + 0.006*"entrepreneur"
INFO 2022-10-28 14:59:43,402 ldamodel.py:1196] topic #3 (0.378): 0.032*"work" + 0.023*"office" + 0.020*"home" + 0.015*"day" + 0.014*"working" + 0.012*"today" + 0.009*"one" + 0.009*"back" + 0.008*"like" + 0.008*"week"
INFO 2022-10-28 14:59:43,402 ldamodel.py:1196] topic #4 (0.130): 0.015*"california" + 0.013*"done" + 0.008*"home" + 0.008*"employee" + 0.007*"job" + 0.007*"corporate" + 0.007*"realestate" + 0.006*"group" + 0.006*"sold" + 0.006*"los"
INFO 2022-10-28 14:59:43,402 ldamodel.py:1074] topic diff=0.157306, rho=0.237826
INFO 2022-10-28 14:59:43,419 ldamodel.py:847] -8.788 per-word bound, 441.9 perplexity estimate based on a held-out corpus of 68 documents with 815 words
INFO 2022-10-28 14:59:43,420 ldamodel.py:1001] PROGRESS: pass 9, at document #768/768
INFO 2022-10-28 14:59:43,428 ldamodel.py:794] optimized alpha [0.20140053, 0.22808264, 0.18056208, 0.38278764, 0.12674119]
INFO 2022-10-28 14:59:43,429 ldamodel.py:233] merging changes from 68 documents into a model of 768 documents
INFO 2022-10-28 14:59:43,430 ldamodel.py:1196] topic #0 (0.201): 0.013*"life" + 0.013*"go" + 0.011*"work" + 0.011*"love" + 0.011*"job" + 0.010*"make" + 0.010*"today" + 0.009*"day" + 0.009*"would" + 0.008*"good"
INFO 2022-10-28 14:59:43,431 ldamodel.py:1196] topic #1 (0.228): 0.012*"meeting" + 0.012*"work" + 0.011*"need" + 0.009*"team" + 0.009*"zoom" + 0.008*"home" + 0.007*"coffee" + 0.007*"got" + 0.006*"time" + 0.006*"even"
INFO 2022-10-28 14:59:43,432 ldamodel.py:1196] topic #2 (0.181): 0.010*"new" + 0.010*"morning" + 0.008*"way" + 0.008*"think" + 0.008*"let" + 0.007*"another" + 0.007*"long" + 0.007*"monday" + 0.007*"day" + 0.006*"spring"
INFO 2022-10-28 14:59:43,432 ldamodel.py:1196] topic #3 (0.383): 0.030*"work" + 0.024*"office" + 0.019*"day" + 0.019*"home" + 0.013*"working" + 0.012*"back" + 0.010*"today" + 0.010*"one" + 0.009*"time" + 0.009*"week"
INFO 2022-10-28 14:59:43,433 ldamodel.py:1196] topic #4 (0.127): 0.014*"california" + 0.011*"done" + 0.009*"employee" + 0.008*"covid" + 0.008*"beach" + 0.007*"home" + 0.006*"job" + 0.005*"corporate" + 0.005*"realestate" + 0.005*"ready"
INFO 2022-10-28 14:59:43,433 ldamodel.py:1074] topic diff=0.131422, rho=0.237826
INFO 2022-10-28 14:59:43,434 utils.py:448] LdaModel lifecycle event {'msg': 'trained LdaModel&lt;num_terms=4059, num_topics=5, decay=0.5, chunksize=100&gt; in 2.35s', 'datetime': '2022-10-28T14:59:43.434209', 'gensim': '4.2.0', 'python': '3.9.7 (default, Sep 16 2021, 08:50:36) \n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}</code></pre>
</div>
</div>
<div class="cell" data-execution_count="70">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a>pyLDAvis.enable_notebook()</span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a>vis <span class="op">=</span> gensimvis.prepare(lda_model, corpus, id2word, mds<span class="op">=</span><span class="st">'mmds'</span>)</span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a>vis</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="70">


<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v1.0.0.css">


<div id="ldavis_el15491403284190108166636547180"></div>
<script type="text/javascript">

var ldavis_el15491403284190108166636547180_data = {"mdsDat": {"x": [0.1589602020717858, -0.018824869698685305, -0.10119957236710611, -0.20296746414213143, 0.16403170413613707], "y": [-0.17190164014035095, 0.20504646152931325, -0.1658491647902364, 0.04261534441936311, 0.09008899898191099], "topics": [1, 2, 3, 4, 5], "cluster": [1, 1, 1, 1, 1], "Freq": [30.523374916910463, 20.697000273602782, 18.7350757350278, 16.547770547353124, 13.496778527105835]}, "tinfo": {"Term": ["office", "back", "life", "work", "home", "meeting", "day", "california", "go", "need", "working", "love", "done", "team", "zoom", "make", "new", "morning", "would", "time", "employee", "going", "week", "way", "today", "covid", "think", "let", "coffee", "job", "office", "back", "going", "want", "two", "thing", "still", "mom", "say", "lunch", "dog", "view", "feel", "many", "selfcare", "catsoftwitter", "commute", "gas", "stay", "return", "bad", "save", "expert", "also", "live", "staff", "weekend", "health", "favorite", "laptop", "week", "friday", "one", "working", "best", "next", "home", "work", "day", "like", "time", "year", "look", "today", "new", "remote", "little", "meeting", "need", "zoom", "team", "coffee", "got", "even", "desk", "much", "video", "phone", "florida", "wednesday", "real", "sure", "away", "co", "news", "bos", "night", "person", "definitely", "oh", "old", "shop", "win", "hope", "market", "giveaway", "smart", "run", "full", "see", "house", "email", "first", "since", "work", "get", "time", "home", "amp", "know", "working", "today", "hour", "life", "would", "company", "pandemic", "trying", "dream", "yes", "money", "may", "travel", "virginia", "never", "laptoplifestyle", "lucky", "follow", "believe", "larkspur", "thankful", "career", "pool", "tech", "interview", "decided", "profit", "finance", "watch", "find", "saturday", "commercial", "slicer", "someone", "make", "good", "go", "love", "people", "better", "job", "business", "worker", "help", "every", "today", "get", "work", "day", "right", "entrepreneur", "like", "let", "way", "think", "long", "another", "spring", "tuesday", "open", "world", "hybrid", "reason", "sunday", "technology", "motivation", "please", "womeninbusiness", "big", "texas", "use", "place", "damn", "poolside", "food", "software", "screen", "light", "businessowner", "face", "accessory", "might", "morning", "google", "check", "monday", "beautiful", "new", "entrepreneur", "day", "job", "get", "go", "business", "done", "employee", "covid", "beach", "corporate", "ready", "group", "sold", "afternoon", "angeles", "los", "lunchtime", "cloudoffice", "homesales", "listed", "realestateagent", "realtorlife", "soldgetting", "souza", "park", "millennial", "seattle", "thinking", "meme", "running", "nowspinning", "seward", "artwork", "beachlife", "blackmayavoodoo", "environment", "california", "realestate", "icon", "souzagroup", "job", "home"], "Freq": [77.0, 39.0, 25.0, 143.0, 85.0, 25.0, 89.0, 25.0, 30.0, 23.0, 50.0, 30.0, 15.0, 19.0, 19.0, 23.0, 47.0, 20.0, 17.0, 42.0, 13.0, 23.0, 31.0, 14.0, 60.0, 12.0, 13.0, 13.0, 15.0, 40.0, 76.7035088980114, 39.239536302706455, 23.081180423304634, 19.897690236316937, 19.1228132231354, 18.885467253105762, 17.415167221175572, 17.494728087321196, 15.437677464538018, 14.049182604720906, 13.333124561437845, 11.940239909420207, 11.824112081564172, 10.357955890495612, 10.223105016965894, 9.536241251210534, 9.055440787570568, 8.638588404042366, 8.646768482054854, 8.782467009306135, 7.872287479808865, 7.665531707554786, 7.424902726349666, 7.41128756294633, 7.350023719619513, 7.282570832928437, 7.143600274472161, 7.095602431487207, 6.938891168716777, 6.724319121472332, 28.220213601921344, 16.65917282923879, 31.311655036330034, 39.607177922509955, 14.50548236221716, 10.778073717246517, 59.575920279843466, 92.80344840643261, 59.955622299229404, 22.512256912533623, 28.73561634455266, 18.908443207347908, 14.869888550717285, 31.53175220472332, 24.448016925337985, 11.88324434662053, 10.57294298062445, 25.087794736079687, 22.774292976462927, 18.972280500628145, 19.15478702639374, 15.158312035691809, 14.13700313504542, 13.059796709463841, 12.980655288413331, 12.686621739766514, 11.446733851384064, 8.218699683792451, 8.149887228750051, 8.000656253688431, 7.62901102321441, 8.098597782643274, 7.674101104331216, 7.325977723887196, 6.936208905483327, 6.914486310704619, 6.9088364010424215, 7.886100029483445, 6.6080133316832095, 6.834362620373472, 6.652689956351925, 6.211466904877575, 5.990899553958984, 5.807208249632056, 5.701619513599512, 5.546196618742065, 5.546196618742065, 6.425383712041113, 5.723042315227385, 9.183967615429822, 7.034770370937167, 7.173245025846853, 9.122662894161506, 8.779464261470126, 24.93158265064305, 12.894863819954043, 13.098997145667036, 16.672604962881735, 11.563435780541143, 9.03102744464602, 10.733908132177769, 10.323673964112853, 7.2139166324127615, 24.9598456878467, 16.58529744406829, 10.858408103352229, 10.40368792620689, 9.925394970826302, 8.737142017423855, 8.570435128459428, 8.10687280067044, 7.794726911098689, 7.604002440589192, 7.114196268224683, 7.3239421457285685, 6.894791419453664, 6.218171900632147, 6.07479202484189, 5.8131290644530935, 5.5404835059782505, 5.558487706211602, 5.37005554528462, 6.048452030864045, 5.375174827013977, 5.499164423570088, 5.114823362444734, 4.896316207626256, 4.845014660634729, 5.735893238017828, 5.17919269152318, 4.791166502370427, 4.641236336222762, 4.641236336222762, 8.144681980597493, 19.194182977402704, 14.784417341350109, 24.238581395607653, 20.600005853599104, 12.986381284037126, 9.092561428189331, 20.452210743338565, 10.47608213600923, 8.518186464925378, 6.77032781533002, 7.449800814778459, 18.476126660549617, 13.200374808501635, 21.835757510342273, 16.621634729406495, 7.099826425539934, 7.672298169793393, 7.3419836375525405, 13.171156864441201, 13.684762354762684, 13.229985410976246, 12.60476513306856, 12.695652900070005, 10.371412989830139, 10.076626580582284, 9.62497833352742, 9.15512062703254, 8.77493079741317, 6.221366226625421, 6.143091266348948, 6.127431909039461, 7.973850301773632, 5.806700413082612, 5.736946825829621, 5.48372438278865, 5.443713256550139, 5.360196419672018, 5.415771661310379, 5.4981503573683375, 4.855733358993108, 5.0767199871935595, 4.666836111197108, 4.428097184722898, 4.554109374315895, 4.267630837477419, 4.338297556539055, 4.18432551700695, 4.2564018163312145, 16.889282757965912, 4.599449285398597, 7.445573588955146, 12.454723409674143, 5.261358731104913, 17.74490750157199, 8.059537860508897, 12.338454467437012, 6.608397203245759, 6.455271626185554, 5.712953801426895, 5.514153379235097, 14.901904650212952, 12.668559635771702, 11.576501222802865, 10.90546597601412, 7.528044939693576, 7.126420188902826, 6.827904948998241, 6.349594117854673, 6.631852519820508, 6.230040685600287, 6.230040685600287, 6.188102277371004, 5.877436972110929, 5.877436972110929, 5.877436972110929, 5.877436972110929, 5.877436972110929, 5.877436972110929, 5.877436972110929, 5.563904564743152, 5.177924261149702, 5.052756383968672, 4.657888322780348, 4.508911327972261, 4.467998641867534, 4.299684082335744, 4.299684082335744, 4.298748017840883, 4.298748017840883, 4.298748017840883, 6.443174026092952, 18.8762169866287, 7.433499836322629, 5.871831590049381, 5.871831590049381, 7.95367980951225, 9.080632195141165], "Total": [77.0, 39.0, 25.0, 143.0, 85.0, 25.0, 89.0, 25.0, 30.0, 23.0, 50.0, 30.0, 15.0, 19.0, 19.0, 23.0, 47.0, 20.0, 17.0, 42.0, 13.0, 23.0, 31.0, 14.0, 60.0, 12.0, 13.0, 13.0, 15.0, 40.0, 77.61697624415847, 39.82945299637641, 23.679979013595307, 20.49327942054272, 19.714431387200808, 19.47462675042288, 18.007364350210484, 18.102923485532806, 16.046435012732676, 14.637672215316208, 13.920746948136312, 12.523091534728714, 12.425592085529063, 10.945428064575648, 10.811931994696257, 10.116949892353121, 9.636986866628073, 9.220783600057514, 9.242194030272161, 9.39248729673607, 8.46957012445533, 8.255205751848282, 8.010443607944307, 8.000450955962872, 7.945943255902773, 7.881821169491513, 7.737462226925031, 7.699896537442726, 7.536900282729879, 7.30727547091094, 31.7483542697034, 19.028456942991298, 38.56894345155426, 50.77603850034197, 16.85324590411125, 12.265829854773145, 85.62239292627176, 143.3810722247685, 89.21145511742472, 30.28834089681485, 42.27075603056421, 26.14798281161079, 19.518324715429646, 60.62168477875825, 47.43672573821573, 22.02915750749583, 14.821970593851438, 25.681503006188404, 23.382452082265335, 19.56717442975368, 19.76113380439698, 15.755354552868837, 14.739666663859829, 13.663082578087838, 13.588763197742841, 13.290772367247992, 12.039997229775162, 8.825824591791083, 8.763125620877053, 8.618942318516021, 8.226516425563872, 8.741938342659045, 8.28453913013921, 7.931129989472444, 7.529364952377478, 7.511235162747997, 7.5196876775793315, 8.591830117052401, 7.199415037942262, 7.449076192566238, 7.280391504081368, 6.80923381960945, 6.581336494130377, 6.4177548965493605, 6.303225586866897, 6.135133945585388, 6.135133945585388, 7.111461530564714, 6.3367538148315905, 10.56914534844328, 8.26796766895419, 9.229474111462965, 14.49890744790166, 14.238271210846053, 143.3810722247685, 38.97489217568379, 42.27075603056421, 85.62239292627176, 32.67228089308426, 16.895389338927092, 50.77603850034197, 60.62168477875825, 20.35840537961053, 25.563550133091077, 17.203499086220997, 11.489907442558899, 11.016926245309437, 10.528961446376835, 9.327274322900003, 9.200704783334269, 8.71315704858524, 8.404178034716193, 8.204024486428898, 7.705638461803962, 7.932852095692331, 7.504235978726239, 6.810491272386728, 6.668649888465295, 6.4272747678474325, 6.13852695535612, 6.160319839034754, 5.95987536255749, 6.720399246337561, 5.983145405937329, 6.1389961558474875, 5.725998504706779, 5.485547350874256, 5.434767403164172, 6.439725475860375, 5.825864457889348, 5.407328335562078, 5.24809223808381, 5.24809223808381, 9.270456082014698, 23.314818666566705, 17.896842046822545, 30.432964335737108, 30.08186498956159, 17.869769757655234, 12.397039759014309, 40.35502481136187, 16.439579123267034, 12.061085476951805, 8.562546897257155, 10.308912931343544, 60.62168477875825, 38.97489217568379, 143.3810722247685, 89.21145511742472, 10.436498190488036, 16.181769563085464, 30.28834089681485, 13.7852180101064, 14.325917088130266, 13.865967538824654, 13.219346650785752, 13.31506516835477, 10.972704880224592, 10.679350683987298, 10.231966237157819, 9.773535748551469, 9.395777895391662, 6.83312941909021, 6.7584370711855195, 6.74630602585086, 8.785191439290724, 6.408288251130819, 6.3535230340517534, 6.0908194513921, 6.053735889315672, 5.976335756395019, 6.048266653242887, 6.142645309591025, 5.479998799922184, 5.73126544749245, 5.270960364186121, 5.029746867802246, 5.175555708859089, 4.863868924865421, 4.950161339785421, 4.781596497274734, 4.873955744965954, 20.160207682478347, 5.349619303319815, 9.649656819453241, 20.561136091487853, 6.473778996892366, 47.43672573821573, 16.181769563085464, 89.21145511742472, 40.35502481136187, 38.97489217568379, 30.432964335737108, 16.439579123267034, 15.51718269266807, 13.3388504468618, 12.215583302956398, 11.520690799033842, 8.133689544164689, 7.750410023175039, 7.42926602217094, 6.953325332380993, 7.272287442650156, 6.831743052724166, 6.831743052724166, 6.804787503788654, 6.4772503134243955, 6.4772503134243955, 6.4772503134243955, 6.4772503134243955, 6.4772503134243955, 6.4772503134243955, 6.4772503134243955, 6.164845013507113, 5.7781721966833395, 5.656538009304045, 5.273469542574427, 5.109287405962799, 5.089310037016489, 4.903593147520897, 4.903593147520897, 4.9035142474561715, 4.9035142474561715, 4.9035142474561715, 7.574837604701032, 25.0307190960006, 9.995687277814259, 7.985087470515708, 7.985087470515708, 40.35502481136187, 85.62239292627176], "Category": ["Default", "Default", "Default", "Default", "Default", "Default", "Default", "Default", "Default", "Default", "Default", "Default", "Default", "Default", "Default", "Default", "Default", "Default", "Default", "Default", "Default", "Default", "Default", "Default", "Default", "Default", "Default", "Default", "Default", "Default", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic1", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic2", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic3", "Topic4", "Topic4", "Topic4", "Topic4", "Topic4", "Topic4", "Topic4", "Topic4", "Topic4", "Topic4", "Topic4", "Topic4", "Topic4", "Topic4", "Topic4", "Topic4", "Topic4", "Topic4", "Topic4", "Topic4", "Topic4", "Topic4", "Topic4", "Topic4", "Topic4", "Topic4", "Topic4", "Topic4", "Topic4", "Topic4", "Topic4", "Topic4", "Topic4", "Topic4", "Topic4", "Topic4", "Topic4", "Topic4", "Topic4", "Topic4", "Topic4", "Topic4", "Topic5", "Topic5", "Topic5", "Topic5", "Topic5", "Topic5", "Topic5", "Topic5", "Topic5", "Topic5", "Topic5", "Topic5", "Topic5", "Topic5", "Topic5", "Topic5", "Topic5", "Topic5", "Topic5", "Topic5", "Topic5", "Topic5", "Topic5", "Topic5", "Topic5", "Topic5", "Topic5", "Topic5", "Topic5", "Topic5", "Topic5", "Topic5", "Topic5", "Topic5", "Topic5", "Topic5", "Topic5"], "logprob": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -3.7133, -4.3835, -4.9142, -5.0626, -5.1023, -5.1148, -5.1959, -5.1913, -5.3164, -5.4107, -5.463, -5.5733, -5.5831, -5.7155, -5.7286, -5.7981, -5.8499, -5.897, -5.896, -5.8805, -5.9899, -6.0165, -6.0484, -6.0502, -6.0585, -6.0677, -6.087, -6.0937, -6.1161, -6.1475, -4.7132, -5.2403, -4.6092, -4.3742, -5.3787, -5.6757, -3.966, -3.5227, -3.9596, -4.9392, -4.6951, -5.1136, -5.3539, -4.6022, -4.8567, -5.5781, -5.6949, -4.4423, -4.5391, -4.7217, -4.7122, -4.9462, -5.0159, -5.0952, -5.1013, -5.1242, -5.227, -5.5583, -5.5667, -5.5852, -5.6328, -5.573, -5.6269, -5.6733, -5.728, -5.7311, -5.7319, -5.5996, -5.7764, -5.7428, -5.7697, -5.8383, -5.8745, -5.9056, -5.924, -5.9516, -5.9516, -5.8045, -5.9202, -5.4473, -5.7139, -5.6944, -5.454, -5.4923, -4.4486, -5.1079, -5.0922, -4.851, -5.2169, -5.4641, -5.2913, -5.3303, -5.6887, -4.3479, -4.7566, -5.1802, -5.223, -5.27, -5.3975, -5.4168, -5.4724, -5.5117, -5.5365, -5.603, -5.574, -5.6344, -5.7377, -5.761, -5.805, -5.853, -5.8498, -5.8843, -5.7653, -5.8833, -5.8605, -5.933, -5.9766, -5.9872, -5.8184, -5.9205, -5.9984, -6.0301, -6.0301, -5.4678, -4.6105, -4.8716, -4.3772, -4.5398, -5.0012, -5.3577, -4.547, -5.216, -5.4229, -5.6526, -5.5569, -4.6486, -4.9849, -4.4816, -4.7544, -5.6051, -5.5275, -5.5715, -4.863, -4.8247, -4.8585, -4.9069, -4.8997, -5.1019, -5.1308, -5.1766, -5.2267, -5.2691, -5.613, -5.6257, -5.6282, -5.3648, -5.682, -5.6941, -5.7392, -5.7465, -5.762, -5.7517, -5.7366, -5.8608, -5.8163, -5.9005, -5.953, -5.925, -5.9899, -5.9735, -6.0096, -5.9926, -4.6143, -5.915, -5.4334, -4.9189, -5.7806, -4.5649, -5.3541, -4.9283, -5.5526, -5.5761, -5.6982, -5.7337, -4.5357, -4.6981, -4.7882, -4.8479, -5.2185, -5.2734, -5.3162, -5.3888, -5.3453, -5.4078, -5.4078, -5.4146, -5.4661, -5.4661, -5.4661, -5.4661, -5.4661, -5.4661, -5.4661, -5.5209, -5.5928, -5.6172, -5.6986, -5.7311, -5.7402, -5.7786, -5.7786, -5.7789, -5.7789, -5.7789, -5.3742, -4.2993, -5.2312, -5.467, -5.467, -5.1635, -5.031], "loglift": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.1748, 1.1718, 1.1611, 1.1572, 1.1562, 1.156, 1.1532, 1.1525, 1.148, 1.1456, 1.1435, 1.139, 1.1371, 1.1315, 1.1307, 1.1276, 1.1244, 1.1215, 1.1201, 1.1195, 1.1135, 1.1126, 1.1108, 1.1102, 1.1087, 1.1076, 1.1068, 1.1049, 1.104, 1.1035, 1.0689, 1.0537, 0.9782, 0.9383, 1.0367, 1.0574, 0.824, 0.7517, 0.7893, 0.89, 0.8007, 0.8625, 0.9147, 0.533, 0.5238, 0.5694, 0.8489, 1.5518, 1.5488, 1.5443, 1.544, 1.5366, 1.5334, 1.53, 1.5294, 1.5287, 1.5247, 1.5039, 1.5026, 1.5007, 1.4998, 1.4987, 1.4986, 1.4958, 1.4931, 1.4924, 1.4905, 1.4895, 1.4895, 1.4891, 1.485, 1.4833, 1.4812, 1.4752, 1.4749, 1.4743, 1.4743, 1.4737, 1.4733, 1.4347, 1.4137, 1.3231, 1.1119, 1.0917, -0.1742, 0.4691, 0.4036, -0.061, 0.5365, 0.9488, 0.0212, -0.195, 0.5377, 1.6509, 1.6382, 1.6182, 1.6175, 1.6157, 1.6094, 1.6038, 1.6027, 1.5995, 1.5988, 1.5949, 1.5949, 1.5901, 1.5838, 1.5815, 1.5743, 1.5723, 1.572, 1.5706, 1.5694, 1.5676, 1.5647, 1.5619, 1.5611, 1.5599, 1.559, 1.5571, 1.5538, 1.5519, 1.5519, 1.5453, 1.4803, 1.4837, 1.4472, 1.2961, 1.3556, 1.3648, 0.9951, 1.2242, 1.327, 1.4399, 1.35, 0.4866, 0.5921, -0.2072, -0.0055, 1.2895, 0.9285, 0.2576, 1.7534, 1.7531, 1.752, 1.7513, 1.7513, 1.7426, 1.7408, 1.7378, 1.7336, 1.7306, 1.7051, 1.7035, 1.7027, 1.702, 1.7003, 1.6968, 1.6939, 1.6927, 1.6901, 1.6885, 1.6881, 1.678, 1.6776, 1.6772, 1.6715, 1.671, 1.6681, 1.667, 1.6655, 1.6634, 1.6219, 1.6478, 1.5396, 1.2976, 1.5915, 0.8156, 1.1019, -0.1794, -0.0105, 0.0009, 0.1261, 0.7065, 1.9623, 1.9512, 1.949, 1.9478, 1.9253, 1.9188, 1.9183, 1.9119, 1.9105, 1.9105, 1.9105, 1.9077, 1.9055, 1.9055, 1.9055, 1.9055, 1.9055, 1.9055, 1.9055, 1.9002, 1.893, 1.8898, 1.8786, 1.8777, 1.8725, 1.8713, 1.8713, 1.8711, 1.8711, 1.8711, 1.8409, 1.7205, 1.7066, 1.6953, 1.6953, 0.3786, -0.2411]}, "token.table": {"Topic": [4, 5, 1, 1, 2, 3, 4, 5, 5, 4, 5, 2, 1, 1, 5, 5, 4, 5, 3, 1, 4, 3, 4, 4, 5, 2, 3, 4, 4, 2, 5, 3, 1, 3, 4, 5, 2, 2, 3, 1, 3, 5, 5, 4, 1, 3, 4, 3, 2, 2, 1, 5, 3, 2, 3, 5, 3, 4, 1, 5, 2, 2, 3, 1, 4, 1, 1, 3, 3, 2, 4, 2, 3, 4, 1, 4, 2, 1, 1, 2, 3, 4, 2, 3, 4, 1, 3, 5, 4, 2, 5, 1, 2, 3, 1, 2, 5, 5, 2, 1, 2, 3, 2, 5, 4, 4, 5, 3, 1, 3, 4, 5, 1, 2, 4, 1, 3, 3, 4, 3, 4, 1, 3, 5, 1, 2, 3, 1, 4, 1, 4, 5, 1, 3, 3, 1, 5, 2, 3, 1, 2, 3, 2, 5, 4, 5, 1, 1, 4, 3, 1, 2, 4, 4, 2, 2, 3, 1, 3, 4, 2, 1, 3, 2, 5, 1, 2, 2, 1, 3, 5, 4, 3, 5, 2, 3, 2, 2, 4, 4, 3, 4, 3, 5, 2, 4, 5, 5, 5, 4, 1, 2, 3, 1, 2, 3, 2, 5, 3, 1, 1, 4, 5, 2, 4, 1, 5, 2, 2, 3, 3, 2, 4, 5, 5, 2, 3, 5, 4, 5, 4, 1, 1, 1, 4, 2, 2, 3, 4, 4, 3, 1, 4, 5, 1, 2, 1, 2, 3, 3, 3, 4, 1, 4, 2, 1, 3, 1, 3, 4, 2, 1, 3, 1, 2, 4, 1, 2, 3, 5, 2, 3, 1, 2, 4, 3, 1, 3, 5, 3, 2], "Freq": [0.8365406830709776, 0.9625582122822514, 0.8749506794717341, 0.21424889259818064, 0.3672838158825954, 0.15303492328441476, 0.15303492328441476, 0.1224279386275318, 0.8782531710713992, 0.9763376923529019, 0.8157414862361431, 0.9656541992657075, 0.9791748835603674, 0.9445579743062192, 0.9548038561127334, 0.8157414862361431, 0.7723464150382906, 0.1544692830076581, 0.9335216272400734, 0.8900362627676867, 0.11867150170235821, 0.7259797641171388, 0.24199325470571295, 0.8209076036324167, 0.8157414862361431, 0.9319372710784678, 0.6082880787286665, 0.3649728472371999, 0.8223905828446388, 0.2397054586002157, 0.7590672855673497, 0.838943718758308, 0.9884402024723363, 0.2072612567908215, 0.7254143987678752, 0.9263189948927445, 0.8825980672730873, 0.9520572799339957, 0.952727157445237, 0.9339018641984566, 0.9573619330696895, 0.9835634808239514, 0.9823517798855972, 0.813981558107072, 0.6725593694332741, 0.19055848800609432, 0.1345118738866548, 0.8732101476956364, 0.972301216572276, 0.9566727899239102, 0.9338579350973993, 0.9666703226409494, 0.9649121156331287, 0.7584397459120701, 0.21669707026059146, 0.974596727940561, 0.49438350786121305, 0.49438350786121305, 0.13201603152249605, 0.7920961891349764, 0.951469035314823, 0.19400687670172642, 0.6790240684560425, 0.8738592196139792, 0.8080544704374003, 0.9287637805212658, 0.9657487480194437, 0.9200025739995705, 0.8582417315303367, 0.6207364266817578, 0.3448535703787543, 0.9129162750949271, 0.8997323446801648, 0.8724076813066836, 0.8933987685355415, 0.10510573747476959, 0.946857046261858, 0.9760558744642769, 0.1539452623230954, 0.3335480683667067, 0.3335480683667067, 0.1539452623230954, 0.9779737579026085, 0.7886185432096424, 0.1971546358024106, 0.9712846445849925, 0.8381366925380638, 0.16762733850761277, 0.9346459470297537, 0.9498179517401559, 0.9422195919637426, 0.9091031244329973, 0.1167876815156867, 0.8175137706098069, 0.7007512631849142, 0.1985461912357257, 0.10511268947773714, 0.9263189948927445, 0.9349063803022495, 0.44207784608777523, 0.3438383247349363, 0.1473592820292584, 0.846640949780761, 0.12094870711153728, 0.9578770486277907, 0.25046688685438184, 0.7514006605631456, 0.8144654065693498, 0.12390030791387992, 0.49560123165551967, 0.1734604310794319, 0.1982404926622079, 0.2959387262227788, 0.5326897072010018, 0.17756323573366725, 0.9579493790628049, 0.932806486875453, 0.9774331926268973, 0.9430391300644843, 0.9779549346566859, 0.9660798339860226, 0.7593681039960396, 0.23111203165096858, 0.9263189948927445, 0.7421415344436794, 0.202402236666458, 0.06746741222215268, 0.8809526791926101, 0.9834071488871415, 0.7685085794346983, 0.20493562118258624, 0.8782531710713992, 0.29918357798371215, 0.6980950152953282, 0.880993713967026, 0.9564362279783136, 0.8817321623429714, 0.17156470557225365, 0.8149323514682049, 0.9136234728328735, 0.9518935848498452, 0.9519074877939754, 0.9734632740917, 0.9786100492535897, 0.82068861707072, 0.8653255441002591, 0.9390748413418296, 0.3890835586323431, 0.5836253379485147, 0.9181517049895209, 0.04960266361090718, 0.09920532722181435, 0.843245281385422, 0.910623297771401, 0.9781222370518863, 0.9836436280968407, 0.8824064681353526, 0.5059371115208579, 0.10540356490017873, 0.3794528336406434, 0.9296932801470428, 0.896800308681882, 0.081527300789262, 0.9308897257623039, 0.8157283607475214, 0.9920510141722392, 0.9397138408901776, 0.9614867546718908, 0.8037554888932472, 0.1555655784954672, 0.0259275964159112, 0.9773292608887407, 0.9076941950353528, 0.9732604772470452, 0.2238417200807212, 0.7274855902623439, 0.9311171067177199, 0.9064308854994485, 0.8266831286810346, 0.9362874709859108, 0.8928040998858574, 0.912408958934626, 0.9114860706111902, 0.9031780227199353, 0.9724650856029445, 0.20008629165891, 0.700302020806185, 0.9263189948927445, 0.9263189948927445, 0.8780749832188696, 0.5447325888843809, 0.13618314722109523, 0.3177606768492222, 0.9582126348073464, 0.2874527399175176, 0.670723059807541, 0.8437084239593076, 0.7859611560125985, 0.9246710555963054, 0.9690854765441621, 0.9347870719008714, 0.7952686497218904, 0.8839328917751191, 0.8515352664088021, 0.094615029600978, 0.9249040786517575, 0.8157283607475214, 0.881156405985209, 0.6320992111137916, 0.3511662283965509, 0.952727157445237, 0.9779737579026085, 0.9485937390030138, 0.8628964866721472, 0.9263189948927445, 0.10786955799726688, 0.8629564639781351, 0.9263189948927445, 0.25046688685438184, 0.7514006605631456, 0.911352315509949, 0.8881196172142533, 0.9737947472776625, 0.9440582013769989, 0.8877792212612139, 0.9151288520260406, 0.9614832928145235, 0.8356808435640372, 0.8893756045173279, 0.8259362633947367, 0.9739754033518049, 0.9756284545780796, 0.9375472691393552, 0.9481423870249712, 0.6860534971040337, 0.3075412228397393, 0.5278639172894244, 0.1649574741529451, 0.2969234534753012, 0.9751311704680556, 0.9497612894613782, 0.936386517861435, 0.9637609945136618, 0.8366330480428105, 0.9136214726691774, 0.9582298401893742, 0.9084256982336069, 0.9759296981990959, 0.9317167358284592, 0.9772498272797974, 0.9281881354297555, 0.8819354780452242, 0.09449308693341688, 0.9046893922972845, 0.9116689300647601, 0.9443579519335896, 0.6486211782138885, 0.17436053177792704, 0.1534372679645758, 0.027897685084468327, 0.24873383127355045, 0.7462014938206514, 0.7877731540582987, 0.21663761736603215, 0.9208540523662468, 0.9881710642003063, 0.7266334897376179, 0.22946320728556355, 0.038243867880927256, 0.9781859337887011, 0.9710139840685816], "Term": ["accessory", "afternoon", "also", "amp", "amp", "amp", "amp", "amp", "angeles", "another", "artwork", "away", "back", "bad", "beach", "beachlife", "beautiful", "beautiful", "believe", "best", "best", "better", "better", "big", "blackmayavoodoo", "bos", "business", "business", "businessowner", "california", "california", "career", "catsoftwitter", "check", "check", "cloudoffice", "co", "coffee", "commercial", "commute", "company", "corporate", "covid", "damn", "day", "day", "day", "decided", "definitely", "desk", "dog", "done", "dream", "email", "email", "employee", "entrepreneur", "entrepreneur", "environment", "environment", "even", "every", "every", "expert", "face", "favorite", "feel", "finance", "find", "first", "first", "florida", "follow", "food", "friday", "friday", "full", "gas", "get", "get", "get", "get", "giveaway", "go", "go", "going", "good", "good", "google", "got", "group", "health", "help", "help", "home", "home", "home", "homesales", "hope", "hour", "hour", "hour", "house", "house", "hybrid", "icon", "icon", "interview", "job", "job", "job", "job", "know", "know", "know", "laptop", "laptoplifestyle", "larkspur", "let", "life", "light", "like", "like", "listed", "little", "little", "little", "live", "long", "look", "look", "los", "love", "love", "lucky", "lunch", "lunchtime", "make", "make", "many", "market", "may", "meeting", "meme", "might", "millennial", "mom", "monday", "monday", "money", "morning", "morning", "morning", "motivation", "much", "need", "never", "new", "new", "new", "news", "next", "next", "night", "nowspinning", "office", "oh", "old", "one", "one", "one", "open", "pandemic", "park", "people", "people", "person", "phone", "place", "please", "pool", "poolside", "profit", "ready", "real", "realestate", "realestate", "realestateagent", "realtorlife", "reason", "remote", "remote", "remote", "return", "right", "right", "run", "running", "saturday", "save", "say", "screen", "seattle", "see", "see", "selfcare", "seward", "shop", "since", "since", "slicer", "smart", "software", "sold", "soldgetting", "someone", "someone", "souza", "souzagroup", "souzagroup", "spring", "staff", "stay", "still", "sunday", "sure", "team", "tech", "technology", "texas", "thankful", "thing", "think", "thinking", "time", "time", "today", "today", "today", "travel", "trying", "tuesday", "two", "use", "video", "view", "virginia", "want", "watch", "way", "wednesday", "week", "week", "weekend", "win", "womeninbusiness", "work", "work", "work", "work", "worker", "worker", "working", "working", "world", "would", "year", "year", "year", "yes", "zoom"]}, "R": 30, "lambda.step": 0.01, "plot.opts": {"xlab": "PC1", "ylab": "PC2"}, "topic.order": [4, 2, 1, 3, 5]};

function LDAvis_load_lib(url, callback){
  var s = document.createElement('script');
  s.src = url;
  s.async = true;
  s.onreadystatechange = s.onload = callback;
  s.onerror = function(){console.warn("failed to load library " + url);};
  document.getElementsByTagName("head")[0].appendChild(s);
}

if(typeof(LDAvis) !== "undefined"){
   // already loaded: just create the visualization
   !function(LDAvis){
       new LDAvis("#" + "ldavis_el15491403284190108166636547180", ldavis_el15491403284190108166636547180_data);
   }(LDAvis);
}else if(typeof define === "function" && define.amd){
   // require.js is available: use it to load d3/LDAvis
   require.config({paths: {d3: "https://d3js.org/d3.v5"}});
   require(["d3"], function(d3){
      window.d3 = d3;
      LDAvis_load_lib("https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js", function(){
        new LDAvis("#" + "ldavis_el15491403284190108166636547180", ldavis_el15491403284190108166636547180_data);
      });
    });
}else{
    // require.js not available: dynamically load d3 & LDAvis
    LDAvis_load_lib("https://d3js.org/d3.v5.js", function(){
         LDAvis_load_lib("https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js", function(){
                 new LDAvis("#" + "ldavis_el15491403284190108166636547180", ldavis_el15491403284190108166636547180_data);
            })
         });
}
</script>
</div>
</div>
<div class="cell" data-execution_count="73">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a>df_second_peak.sort_values(by <span class="op">=</span> [<span class="st">'likes'</span>])[:<span class="dv">20</span>][<span class="st">'lematize_text'</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="73">
<pre><code>27366    covering base today lol get mind boost discoun...
27405    ultra moisturizing body lotion also available ...
27404    true truth thursdaythoughts thursdaymorning do...
27403          old use hashtag stay healthy m shannonbream
27402    house two space could used two large executive...
30068    wish said still live amongst non believer one ...
27396    sunday shopping walmart shopping today food fo...
27394    job posting online job get paid chat customer ...
27393    sweet home office setup hanging kickbike lot l...
27391    bjsrestaurants go hour waterconservation never...
27387    return work present shift dress code corporati...
27381    good life best office assistant dogdad goldend...
27378    work home day lunch cast iron grilled chicken ...
27377    always realize need coffee right meeting start...
27373    love work good morning friday thankful another...
27371    need freaking drinkit one hell week unfortunat...
27369    today beautiful look let go entrepreneur joinm...
27367    check startup q dl free q app amp answer mkt r...
27365    vfx photo ready foundation entrepreneur joinmy...
27364    roll jungle boy know might end jungleboys ston...
Name: lematize_text, dtype: object</code></pre>
</div>
</div>
<div class="cell" data-scrolled="true" data-execution_count="39">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="co">#bi_gram</span></span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_gram(text):</span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> [<span class="st">' '</span>.join(x) <span class="cf">for</span> x <span class="kw">in</span> text]</span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk.util <span class="im">import</span> ngrams</span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'bi_gram'</span>] <span class="op">=</span> df[<span class="st">'lematize_text'</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: (<span class="bu">list</span>(ngrams(x.split(), <span class="dv">2</span>))))</span>
<span id="cb41-6"><a href="#cb41-6" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'bi_gram'</span>] <span class="op">=</span> df[<span class="st">'bi_gram'</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: get_gram(x))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-execution_count="40">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> collections <span class="im">import</span> Counter</span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a>list1 <span class="op">=</span> []</span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> bi <span class="kw">in</span> df[<span class="st">'bi_gram'</span>]:</span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a>    list1.extend(bi) </span>
<span id="cb42-5"><a href="#cb42-5" aria-hidden="true" tabindex="-1"></a>counts <span class="op">=</span> Counter(list1)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-execution_count="41">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="co">#top 20 bi_gram</span></span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a>counts.most_common()[:<span class="dv">20</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="41">
<pre><code>[('working home', 1487),
 ('work home', 1234),
 ('home office', 541),
 ('womeninbusiness womenintech', 520),
 ('new york', 379),
 ('womenintech workingmom', 359),
 ('remote work', 320),
 ('work remotely', 271),
 ('co worker', 255),
 ('look like', 237),
 ('social medium', 204),
 ('good morning', 201),
 ('conference call', 197),
 ('ability work', 195),
 ('zoom meeting', 193),
 ('feel like', 182),
 ('zoom u', 176),
 ('covid coronavirus', 176),
 ('financialprofessional supersinghs', 171),
 ('los angeles', 168)]</code></pre>
</div>
</div>
<div class="cell" data-execution_count="55">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Tri_gram</span></span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'Tri_gram'</span>] <span class="op">=</span> df[<span class="st">'lematize_text'</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: (<span class="bu">list</span>(ngrams(x.split(), <span class="dv">3</span>))))</span>
<span id="cb45-3"><a href="#cb45-3" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'Tri_gram'</span>] <span class="op">=</span> df[<span class="st">'Tri_gram'</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: get_gram(x))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-execution_count="56">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a>list2 <span class="op">=</span> []</span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> bi <span class="kw">in</span> df[<span class="st">'Tri_gram'</span>]:</span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a>    list2.extend(bi) </span>
<span id="cb46-4"><a href="#cb46-4" aria-hidden="true" tabindex="-1"></a>counts1 <span class="op">=</span> Counter(list2)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-execution_count="57">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="co">#top 20 Tri_gram</span></span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a>counts1.most_common()[:<span class="dv">20</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="57">
<pre><code>[('womeninbusiness womenintech workingmom', 355),
 ('ability work remotely', 184),
 ('consider locating keweenaw', 131),
 ('los angeles california', 130),
 ('shawn fortress solitude', 128),
 ('work remotely consider', 120),
 ('remotelearning remotejobs remoteworklife', 106),
 ('workingmom womeninbusiness womenintech', 106),
 ('remotejobs remoteworklife remoteemployees', 100),
 ('supersinghs shawn fortress', 100),
 ('remotely consider locating', 99),
 ('collaboration remotelearning remotejobs', 96),
 ('supersinghs kew garden', 84),
 ('financialprofessional supersinghs kew', 82),
 ('financialprofessional supersinghs shawn', 79),
 ('entrepreneur bos prosperity', 73),
 ('new york new', 72),
 ('york new york', 72),
 ('realestate homesales cloudoffice', 70),
 ('homesales cloudoffice workfromanywhere', 70)]</code></pre>
</div>
</div>
<div class="cell" data-execution_count="14">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> vaderSentiment.vaderSentiment <span class="im">import</span> SentimentIntensityAnalyzer</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-execution_count="35">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb50"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a>sid_obj <span class="op">=</span> SentimentIntensityAnalyzer()</span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'scores'</span>] <span class="op">=</span> df[<span class="st">'clean_text'</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: sid_obj.polarity_scores(x))</span>
<span id="cb50-3"><a href="#cb50-3" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'compound_score'</span>] <span class="op">=</span> df[<span class="st">'scores'</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: x[<span class="st">'compound'</span>])</span>
<span id="cb50-4"><a href="#cb50-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> condition(x):</span>
<span id="cb50-5"><a href="#cb50-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> x<span class="op">&gt;</span><span class="dv">0</span>:</span>
<span id="cb50-6"><a href="#cb50-6" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="st">"Positive"</span></span>
<span id="cb50-7"><a href="#cb50-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> x<span class="op">==</span><span class="dv">0</span>:</span>
<span id="cb50-8"><a href="#cb50-8" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="st">"Neutral"</span></span>
<span id="cb50-9"><a href="#cb50-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb50-10"><a href="#cb50-10" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="st">'Negative'</span></span>
<span id="cb50-11"><a href="#cb50-11" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'sentiment'</span>] <span class="op">=</span> df[<span class="st">'compound_score'</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: condition(x))</span>
<span id="cb50-12"><a href="#cb50-12" aria-hidden="true" tabindex="-1"></a>df.head() </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="35">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>author_id</th>
      <th>username</th>
      <th>author_followers</th>
      <th>author_tweets</th>
      <th>author_description</th>
      <th>author_location</th>
      <th>text</th>
      <th>created_at</th>
      <th>geo_id</th>
      <th>retweets</th>
      <th>...</th>
      <th>clean_text</th>
      <th>no_stopwords_text</th>
      <th>no_remotework_text</th>
      <th>lematize_text</th>
      <th>date</th>
      <th>month</th>
      <th>tweet</th>
      <th>scores</th>
      <th>compound_score</th>
      <th>sentiment</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2729932651</td>
      <td>TwelveRivers12</td>
      <td>367</td>
      <td>1862</td>
      <td>We strive to raise the bar of what it means to...</td>
      <td>Austin, TX</td>
      <td>#WFH but make it fashion (Twelve Rivers fashio...</td>
      <td>2020-12-19 20:00:14+00:00</td>
      <td>c3f37afa9efcf94b</td>
      <td>1</td>
      <td>...</td>
      <td>wfh but make it fashion twelve rivers fashion ...</td>
      <td>wfh make fashion twelve rivers fashion office ...</td>
      <td>make fashion twelve rivers fashion office big ...</td>
      <td>make fashion twelve river fashion office big g...</td>
      <td>2020-12-19</td>
      <td>12</td>
      <td>1</td>
      <td>{'neg': 0.0, 'neu': 0.834, 'pos': 0.166, 'comp...</td>
      <td>0.8674</td>
      <td>Positive</td>
    </tr>
    <tr>
      <th>1</th>
      <td>483173029</td>
      <td>CarrieHOlerich</td>
      <td>2138</td>
      <td>88698</td>
      <td>Driven, passionate #Communications graduate.🎓📚...</td>
      <td>Nebraska, USA</td>
      <td>Late night evening #wfh vibes finish my evenin...</td>
      <td>2020-12-19 07:12:54+00:00</td>
      <td>0fc2e8f588955000</td>
      <td>0</td>
      <td>...</td>
      <td>late night evening wfh vibes finish my evening...</td>
      <td>late night evening wfh vibes finish evening wf...</td>
      <td>late night evening vibes finish evening wfhlife</td>
      <td>late night evening vibe finish evening wfhlife</td>
      <td>2020-12-19</td>
      <td>12</td>
      <td>1</td>
      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>
      <td>0.0000</td>
      <td>Neutral</td>
    </tr>
    <tr>
      <th>2</th>
      <td>389908361</td>
      <td>JuanC611</td>
      <td>214</td>
      <td>12248</td>
      <td>I'm a #BCB, craft beer drinkin #Kaskade listen...</td>
      <td>Oxnard, CA</td>
      <td>Step 2, in progress...\n#wfh #wfhlife @ Riverp...</td>
      <td>2020-12-19 02:56:54+00:00</td>
      <td>a3c0ae863771d69e</td>
      <td>0</td>
      <td>...</td>
      <td>step in progress wfh wfhlife riverpark</td>
      <td>step progress wfh wfhlife riverpark</td>
      <td>step progress wfhlife riverpark</td>
      <td>step progress wfhlife riverpark</td>
      <td>2020-12-19</td>
      <td>12</td>
      <td>1</td>
      <td>{'neg': 0.0, 'neu': 0.641, 'pos': 0.359, 'comp...</td>
      <td>0.4215</td>
      <td>Positive</td>
    </tr>
    <tr>
      <th>3</th>
      <td>737763400118198277</td>
      <td>MissionTXperts</td>
      <td>828</td>
      <td>1618</td>
      <td>Follow us on IG! @missiontxperts #FamousForExp...</td>
      <td>Mission, TX</td>
      <td>Congratulations on your graduation!!! Welcome ...</td>
      <td>2020-12-18 22:35:35+00:00</td>
      <td>77633125ba089dcb</td>
      <td>1</td>
      <td>...</td>
      <td>congratulations on your graduation welcome to ...</td>
      <td>congratulations graduation welcome missiontxpe...</td>
      <td>congratulations graduation welcome missiontxpe...</td>
      <td>congratulation graduation welcome missiontxper...</td>
      <td>2020-12-18</td>
      <td>12</td>
      <td>1</td>
      <td>{'neg': 0.0, 'neu': 0.566, 'pos': 0.434, 'comp...</td>
      <td>0.7845</td>
      <td>Positive</td>
    </tr>
    <tr>
      <th>4</th>
      <td>522212036</td>
      <td>FitnessFoundry</td>
      <td>2693</td>
      <td>14002</td>
      <td>Award Winning Personal Trainer| EMT-B 🚑 NSCA-R...</td>
      <td>Boston and Malden, MA</td>
      <td>Part 2 #HomeWorkout \n\n#OldSchool Jumping Jac...</td>
      <td>2020-12-18 19:07:33+00:00</td>
      <td>75f5a403163f6f95</td>
      <td>1</td>
      <td>...</td>
      <td>part homeworkout oldschool jumping jack variat...</td>
      <td>part homeworkout oldschool jumping jack variat...</td>
      <td>part homeworkout oldschool jumping jack variat...</td>
      <td>part homeworkout oldschool jumping jack variat...</td>
      <td>2020-12-18</td>
      <td>12</td>
      <td>1</td>
      <td>{'neg': 0.0, 'neu': 0.81, 'pos': 0.19, 'compou...</td>
      <td>0.7003</td>
      <td>Positive</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 25 columns</p>
</div>
</div>
</div>
<div class="cell" data-execution_count="36">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'sentiment'</span>].value_counts()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="36">
<pre><code>Positive    18285
Neutral      9413
Negative     4267
Name: sentiment, dtype: int64</code></pre>
</div>
</div>
<div class="cell" data-execution_count="38">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb53"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a><span class="co">#generate positive sentiment word cloud</span></span>
<span id="cb53-2"><a href="#cb53-2" aria-hidden="true" tabindex="-1"></a>df_positive <span class="op">=</span> df[df[<span class="st">'sentiment'</span>] <span class="op">==</span> <span class="st">'Positive'</span>]</span>
<span id="cb53-3"><a href="#cb53-3" aria-hidden="true" tabindex="-1"></a>tweets <span class="op">=</span> <span class="st">''</span></span>
<span id="cb53-4"><a href="#cb53-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> tweet <span class="kw">in</span> df_positive[<span class="st">'lematize_text'</span>].values:</span>
<span id="cb53-5"><a href="#cb53-5" aria-hidden="true" tabindex="-1"></a>    tweets <span class="op">+=</span> <span class="st">''</span>.join(tweet)<span class="op">+</span><span class="st">' '</span></span>
<span id="cb53-6"><a href="#cb53-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> wordcloud <span class="im">import</span> WordCloud</span>
<span id="cb53-7"><a href="#cb53-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb53-8"><a href="#cb53-8" aria-hidden="true" tabindex="-1"></a>wordcloud <span class="op">=</span> WordCloud(width <span class="op">=</span> <span class="dv">800</span>, height <span class="op">=</span> <span class="dv">800</span>,</span>
<span id="cb53-9"><a href="#cb53-9" aria-hidden="true" tabindex="-1"></a>                background_color <span class="op">=</span><span class="st">'white'</span>,</span>
<span id="cb53-10"><a href="#cb53-10" aria-hidden="true" tabindex="-1"></a>                min_font_size <span class="op">=</span> <span class="dv">10</span>).generate(tweets)</span>
<span id="cb53-11"><a href="#cb53-11" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb53-12"><a href="#cb53-12" aria-hidden="true" tabindex="-1"></a><span class="co"># plot the WordCloud image                      </span></span>
<span id="cb53-13"><a href="#cb53-13" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize <span class="op">=</span> (<span class="dv">8</span>, <span class="dv">8</span>), facecolor <span class="op">=</span> <span class="va">None</span>)</span>
<span id="cb53-14"><a href="#cb53-14" aria-hidden="true" tabindex="-1"></a>plt.imshow(wordcloud)</span>
<span id="cb53-15"><a href="#cb53-15" aria-hidden="true" tabindex="-1"></a>plt.axis(<span class="st">"off"</span>)</span>
<span id="cb53-16"><a href="#cb53-16" aria-hidden="true" tabindex="-1"></a>plt.tight_layout(pad <span class="op">=</span> <span class="dv">0</span>)</span>
<span id="cb53-17"><a href="#cb53-17" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb53-18"><a href="#cb53-18" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="Yan_Shi_blogpost3_files/figure-html/cell-31-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-execution_count="39">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb54"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a><span class="co">#generate negative sentiment word cloud</span></span>
<span id="cb54-2"><a href="#cb54-2" aria-hidden="true" tabindex="-1"></a>df_negative <span class="op">=</span> df[df[<span class="st">'sentiment'</span>] <span class="op">==</span> <span class="st">'Negative'</span>]</span>
<span id="cb54-3"><a href="#cb54-3" aria-hidden="true" tabindex="-1"></a>tweets <span class="op">=</span> <span class="st">''</span></span>
<span id="cb54-4"><a href="#cb54-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> tweet <span class="kw">in</span> df_negative[<span class="st">'lematize_text'</span>].values:</span>
<span id="cb54-5"><a href="#cb54-5" aria-hidden="true" tabindex="-1"></a>    tweets <span class="op">+=</span> <span class="st">''</span>.join(tweet)<span class="op">+</span><span class="st">' '</span></span>
<span id="cb54-6"><a href="#cb54-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> wordcloud <span class="im">import</span> WordCloud</span>
<span id="cb54-7"><a href="#cb54-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb54-8"><a href="#cb54-8" aria-hidden="true" tabindex="-1"></a>wordcloud <span class="op">=</span> WordCloud(width <span class="op">=</span> <span class="dv">800</span>, height <span class="op">=</span> <span class="dv">800</span>,</span>
<span id="cb54-9"><a href="#cb54-9" aria-hidden="true" tabindex="-1"></a>                background_color <span class="op">=</span><span class="st">'white'</span>,</span>
<span id="cb54-10"><a href="#cb54-10" aria-hidden="true" tabindex="-1"></a>                min_font_size <span class="op">=</span> <span class="dv">10</span>).generate(tweets)</span>
<span id="cb54-11"><a href="#cb54-11" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb54-12"><a href="#cb54-12" aria-hidden="true" tabindex="-1"></a><span class="co"># plot the WordCloud image                      </span></span>
<span id="cb54-13"><a href="#cb54-13" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize <span class="op">=</span> (<span class="dv">8</span>, <span class="dv">8</span>), facecolor <span class="op">=</span> <span class="va">None</span>)</span>
<span id="cb54-14"><a href="#cb54-14" aria-hidden="true" tabindex="-1"></a>plt.imshow(wordcloud)</span>
<span id="cb54-15"><a href="#cb54-15" aria-hidden="true" tabindex="-1"></a>plt.axis(<span class="st">"off"</span>)</span>
<span id="cb54-16"><a href="#cb54-16" aria-hidden="true" tabindex="-1"></a>plt.tight_layout(pad <span class="op">=</span> <span class="dv">0</span>)</span>
<span id="cb54-17"><a href="#cb54-17" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb54-18"><a href="#cb54-18" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="Yan_Shi_blogpost3_files/figure-html/cell-32-output-1.png" class="img-fluid"></p>
</div>
</div>



</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  let localAlternateSentinel = 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<script src="https://giscus.app/client.js" data-repo="DACSS/Text_as_Data_Fall_2022" data-repo-id="R_kgDOH5675w" data-category="Announcements" data-category-id="" data-mapping="title" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="top" data-theme="light" data-lang="en" crossorigin="anonymous" async="">
</script>
</div> <!-- /content -->



</body></html>