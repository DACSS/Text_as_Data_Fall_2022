{
  "hash": "202bfd7d7bb11d3b6bd38d93bf006979",
  "result": {
    "markdown": "---\ntitle: \"Blog Post Six: Working with Time Series\"\nauthor: \"Molly Hackbarth\"\ndescription: \"Working with the data\"\ndate: \"12/9/2022\"\nformat:\n  html:\n    toc: true\n    code-fold: true\n    code-copy: true\n    code-tools: true\ncategories:\n  - blog posts\n  - hw6\n  - Molly Hackbarth\n---\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(qwraps2)\nknitr::opts_chunk$set(cache = TRUE)\n#qwraps2::lazyload_cache_dir(path = \"sixth_post_cache/html5\")\n```\n:::\n\n::: {.cell hash='BlogPost6_MollyHackbarth_cache/html/libraries_89c0916431441c6b42de794f8cd90ee3'}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'tidyverse' was built under R version 4.1.2\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.3.6      ✔ purrr   0.3.5 \n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.2.1      ✔ stringr 1.4.1 \n✔ readr   2.1.3      ✔ forcats 0.5.2 \n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'ggplot2' was built under R version 4.1.2\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'tibble' was built under R version 4.1.2\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'tidyr' was built under R version 4.1.2\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'purrr' was built under R version 4.1.2\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'dplyr' was built under R version 4.1.2\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'stringr' was built under R version 4.1.2\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'forcats' was built under R version 4.1.2\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n```\n:::\n\n```{.r .cell-code}\nlibrary(cld3)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'cld3' was built under R version 4.1.2\n```\n:::\n\n```{.r .cell-code}\nlibrary(dplyr)\nlibrary(here)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nhere() starts at /Users/mollyhackbarth/Desktop/Desktop/Graduate School/DACSS/Github Projects/Text_as_Data_Fall_2022\n```\n:::\n\n```{.r .cell-code}\nlibrary(devtools)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'devtools' was built under R version 4.1.2\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: usethis\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'usethis' was built under R version 4.1.2\n```\n:::\n\n```{.r .cell-code}\nlibrary(tidytext)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'tidytext' was built under R version 4.1.2\n```\n:::\n\n```{.r .cell-code}\nlibrary(quanteda)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'quanteda' was built under R version 4.1.2\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nPackage version: 3.2.3\nUnicode version: 14.0\nICU version: 70.1\nParallel computing: 4 of 4 threads used.\nSee https://quanteda.io for tutorials and examples.\n```\n:::\n\n```{.r .cell-code}\nlibrary(quanteda.textstats)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'quanteda.textstats' was built under R version 4.1.2\n```\n:::\n\n```{.r .cell-code}\nlibrary(quanteda.textmodels)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'quanteda.textmodels' was built under R version 4.1.2\n```\n:::\n\n```{.r .cell-code}\nlibrary(quanteda.textplots)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'quanteda.textplots' was built under R version 4.1.2\n```\n:::\n\n```{.r .cell-code}\nlibrary(quanteda.dictionaries)\nlibrary(quanteda.sentiment)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'quanteda.sentiment'\n\nThe following object is masked from 'package:quanteda':\n\n    data_dictionary_LSD2015\n```\n:::\n\n```{.r .cell-code}\nlibrary(patchwork)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'patchwork' was built under R version 4.1.2\n```\n:::\n\n```{.r .cell-code}\nlibrary(stm)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nstm v1.3.6 successfully loaded. See ?stm for help. \n Papers, resources, and other materials at structuraltopicmodel.com\n```\n:::\n\n```{.r .cell-code}\nlibrary(tm)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: NLP\n\nAttaching package: 'NLP'\n\nThe following objects are masked from 'package:quanteda':\n\n    meta, meta<-\n\nThe following object is masked from 'package:ggplot2':\n\n    annotate\n\n\nAttaching package: 'tm'\n\nThe following object is masked from 'package:quanteda':\n\n    stopwords\n```\n:::\n\n```{.r .cell-code}\n## new package \nlibrary(sentimentr)\nknitr::opts_chunk$set(echo = TRUE)\n```\n:::\n\n::: {.cell hash='BlogPost6_MollyHackbarth_cache/html/load data_622b3086f1ed0ba69e8615c381eac2a1'}\n\n```{.r .cell-code}\n#load(\"blogpost6.RData\")\n```\n:::\n\n\n# Research Question\n\n**My current research question:** How do Reddit and Twitter users sentiment differentiate about the show *Love is Blind Japan* over time?\n\nThis blog post will be focused on completing the code that I want to use for my Final Poster. Anything that is new will be in the title as **New!**\n\n# Reading in the Data\n\n\n::: {.cell hash='BlogPost6_MollyHackbarth_cache/html/reading data_59d15f1dfad1fadda8f956e37ce886b6'}\n\n```{.r .cell-code}\n#write csv has been commented out due to it continously trying to save an \"updated version\" in Git. \n\nreddit_data <- read.csv(here::here(\"posts\", \"_data\", \"loveisblindjapan.csv\"))\n\ntwitter1 <- read.csv(here::here(\"posts\", \"_data\", \"tweets.csv\"))\n\ntwitter2 <- read.csv(here::here(\"posts\", \"_data\", \"tweets#.csv\"))\n\nreddit <- subset(reddit_data, select = c(\"body\", \"created_utc\")) \n\nreddit$created_utc <- as.Date.POSIXct(reddit$created_utc)\n\nreddit <- reddit %>% \n  select(text = body, \n            date = created_utc)\n# remove deleted or removed comments by moderators of the subreddit (ones that only contain [deleted] or [removed])\nreddit <- reddit %>% \n  filter(!text == '[deleted]') %>% \n  filter(!text == '[removed]')\n\n#remove counting column\ntwitter1 <- twitter1 %>% select(!c(X, User))\ntwitter2 <- twitter2 %>% select(!c(X, User))\n\ntwitter <- merge(twitter1, twitter2, by=c('Tweet','Tweet', 'Date', 'Date'),all=T, ignore_case =T)\n#write.csv(twitter, here::here(\"posts\", \"_data\", \"twitter.csv\") , all(T) )\n\nnames(twitter) <- tolower(names(twitter))\ntwitter <- twitter %>% \n  rename_at('tweet', ~ 'text', \n            'Date' ~ 'date')\ntwitter$date <- as.Date(strftime(twitter$date, format=\"%Y-%m-%d\"))\n\n# remove duplicate tweets\ntwitter <- twitter %>% distinct(text, date, .keep_all = TRUE)\n\n#check for duplicate tweets\ntwitter %in% unique(twitter[ duplicated(twitter)]) \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] FALSE FALSE\n```\n:::\n:::\n\n::: {.cell hash='BlogPost6_MollyHackbarth_cache/html/lemmentizing the data_dab354833ac57a860c03177839beffb3'}\n\n```{.r .cell-code}\n# Twiter Lemmitized\ntwitter_corpus <- subset(twitter, detect_language(twitter) == \"en\")\ntwitter_corpus <- corpus(twitter_corpus)\ntwitter_corpus <- twitter_corpus[!is.na(twitter_corpus)]\ntwittersummary <- summary(twitter_corpus)\ntwitter_corpus <- trimws(gsub(\"[[:digit:]]{1,4}-[[:digit:]]{1,4}-[[:digit:]]{1,4}\", \"\", twitter_corpus))\n\nmystopwords <- c(\"love is blind japan\", \"#loveisbindjapan\", \"#LoveIsBlindJapan\",\"Love Is Blind Japan\",\"Love is Blind Japan\", \"Love Is Blind: Japan\", \"#loveisblind\", \"ラブイズブラインドjapan\", \"#ラブイズブラインドjapan\", \"loveisblind\", \"#loveisblind2\", \"blind:japan\", \"blind\", \"show\")\n\ntwitter_corpus_tokens <- tokens(twitter_corpus, \n    remove_punct = T,\n    remove_numbers = T,\n    remove_symbols = T,\n    remove_url = T) %>% \n  tokens_tolower() %>% \n  tokens_remove(pattern = phrase(mystopwords), valuetype = 'fixed') %>% \n  tokens_select(pattern = stopwords(\"en\"), selection = \"remove\")\n\ntwitter_lemmitized <- tokens_replace(twitter_corpus_tokens, \n                             pattern = lexicon::hash_lemmas$token, \n                             replacement = lexicon::hash_lemmas$lemma)\n\n# Reddit Lemmitized\n\nreddit_corpus <- subset(reddit, detect_language(reddit) == \"en\")\nreddit_corpus <- corpus(reddit_corpus)\nreddit_corpus <- reddit_corpus[!is.na(reddit_corpus)]\nredditsummary <- summary(reddit_corpus)\n\nreddit_corpus <- trimws(gsub(\"[[:digit:]]{1,4}-[[:digit:]]{1,4}-[[:digit:]]{1,4}\", \"\", reddit_corpus))\n\nreddit_corpus_tokens <- tokens(reddit_corpus, \n    remove_punct = T,\n    remove_numbers = T, \n    remove_symbols = T,\n    remove_url = T) %>% \n  tokens_tolower() %>% \n  tokens_select(pattern = stopwords(\"en\"), selection = \"remove\")\n\nreddit_lemmitized <- tokens_replace(reddit_corpus_tokens, \n                             pattern = lexicon::hash_lemmas$token, \n                             replacement = lexicon::hash_lemmas$lemma)\n```\n:::\n\n::: {.cell hash='BlogPost6_MollyHackbarth_cache/html/creating nrc dictionary_d7b48e2587d1240e3dfaef4b1fe899d7'}\n\n```{.r .cell-code}\n#Twitter NRC\n\ntwitterDfm_nrc <- dfm(tokens(twitter_lemmitized,\n                              remove_punct = TRUE),\n                       tolower = TRUE) %>%\n                    dfm_lookup(data_dictionary_NRC)\n\ntdf_nrc <- convert(twitterDfm_nrc, to = \"data.frame\")\ntdf_nrc$polarity <- (tdf_nrc$positive - tdf_nrc$negative)/(tdf_nrc$positive + tdf_nrc$negative)\ntdf_nrc$polarity[which((tdf_nrc$positive + tdf_nrc$negative) == 0)] <- 0\n\ntwitter_corpus_dfm <- twitter_lemmitized %>% \n  dfm() %>% \n  dfm_remove(stopwords('english')) %>% \n  dfm_trim(min_termfreq = 30, verbose = FALSE)\n\n# Reddit NRC\n\nredditDfm_nrc <- dfm(tokens(reddit_lemmitized,\n                              remove_punct = TRUE),\n                       tolower = TRUE) %>%\n                    dfm_lookup(data_dictionary_NRC)\n\nrdf_nrc <- convert(redditDfm_nrc, to = \"data.frame\")\nrdf_nrc$polarity <- (rdf_nrc$positive - rdf_nrc$negative)/(rdf_nrc$positive + rdf_nrc$negative)\nrdf_nrc$polarity[which((rdf_nrc$positive + rdf_nrc$negative) == 0)] <- 0\n\nreddit_corpus_dfm <- reddit_lemmitized %>% \n  dfm() %>% \n  dfm_remove(stopwords('english')) %>% \n  dfm_trim(min_termfreq = 30, verbose = FALSE)\n```\n:::\n\n\n# Sentiment by Dates\n\n\n::: {.cell hash='BlogPost6_MollyHackbarth_cache/html/emotions by percent_b83a812d60e885095188f8f0bd5fdbaa'}\n\n```{.r .cell-code}\ntdf_nrc <- convert(twitterDfm_nrc, to = \"data.frame\")\ntdf_nrc$date <- twitterDfm_nrc@docvars$date\ntdf_nrc$polarity <- (tdf_nrc$positive - tdf_nrc$negative)/(tdf_nrc$positive + tdf_nrc$negative)\ntdf_nrc$polarity[which((tdf_nrc$positive + tdf_nrc$negative) == 0)] <- 0\n\nrdf_nrc <- convert(redditDfm_nrc, to = \"data.frame\")\nrdf_nrc$date <- redditDfm_nrc@docvars$date\nrdf_nrc$polarity <- (rdf_nrc$positive - rdf_nrc$negative)/(rdf_nrc$positive + rdf_nrc$negative)\nrdf_nrc$polarity[which((rdf_nrc$positive + rdf_nrc$negative) == 0)] <- 0\n\nreddit_emotions <- rdf_nrc %>% \n  group_by(date) %>% \n summarise(polarity = mean(polarity),\n           anger = sum(anger),\n           anticipation = sum(anticipation), \n           disgust = sum(disgust),\n           fear = sum(fear),\n           joy = sum(joy),\n           negative = sum(negative),\n           positive = sum(positive),\n           sadness = sum(sadness),\n           surprise = sum(surprise),\n           trust = sum(trust)) %>% \n    rowwise() %>%\n  mutate(word_count = sum(c_across(anger:trust), na.rm = TRUE)) %>% \n   mutate(anger_percent = round(anger / sum(word_count), 3) * 100,\n          anticipation_percent = round(anticipation / sum(word_count), 3) * 100,\n          disgust_percent = round(disgust/ sum(word_count), 3) * 100,\n          fear_percent = round(fear / sum(word_count), 3) * 100,\n          joy_percent = round(joy / sum(word_count), 3) * 100,\n          negative_percent = round(negative / sum(word_count), 3) * 100,\n          positive_percent = round(positive / sum(word_count), 3) * 100,\n          sadness_percent = round(sadness / sum(word_count), 3) * 100,\n          surprise_percent = round(surprise / sum(word_count), 3) * 100,\n          trust_percent = round(trust / sum(word_count), 3) * 100)\n\ntwitter_emotions <- tdf_nrc %>% \n  group_by(date) %>% \n summarise(polarity = mean(polarity),\n           anger = sum(anger),\n           anticipation = sum(anticipation), \n           disgust = sum(disgust),\n           fear = sum(fear),\n           joy = sum(joy),\n           negative = sum(negative),\n           positive = sum(positive),\n           sadness = sum(sadness),\n           surprise = sum(surprise),\n           trust = sum(trust)) %>% \n  rowwise() %>%\n  mutate(word_count = sum(c_across(anger:trust), na.rm = TRUE)) %>% \n   mutate(anger_percent = round(anger / sum(word_count), 3)* 100,\n          anticipation_percent = round(anticipation / sum(word_count), 3) * 100,\n          disgust_percent = round(disgust/ sum(word_count), 3) * 100,\n          fear_percent = round(fear / sum(word_count), 3) * 100,\n          joy_percent = round(joy / sum(word_count), 3) * 100,\n          negative_percent = round(negative / sum(word_count), 3) * 100,\n          positive_percent = round(positive / sum(word_count), 3) * 100,\n          sadness_percent = round(sadness / sum(word_count), 3) * 100,\n          surprise_percent = round(surprise / sum(word_count), 3) * 100,\n          trust_percent = round(trust / sum(word_count), 3) * 100)\n```\n:::\n\n::: {.cell hash='BlogPost6_MollyHackbarth_cache/html/filter count_ae8b66c8629de47296178a6fb539d860'}\n\n```{.r .cell-code}\ntwitter_emotions <- twitter_emotions %>% \n  filter(word_count > 100)\n\nreddit_emotions <- reddit_emotions %>% \n  filter(word_count > 100)\n\nanger <- ggplot() +\ngeom_smooth(data = reddit_emotions, aes(x = date, y = anger_percent, color=\"Reddit\")) + geom_smooth(data = twitter_emotions, aes(x = date, y = anger_percent, color = \"Twitter\")) +\n    scale_color_manual(name='Social Medias',\n                     breaks=c('Reddit', 'Twitter'),\n                     values=c('Reddit'='red', 'Twitter'='blue')) +\n  labs(title=\"Twitter vs Reddit anger percentage by date\")\n\nanticipation <- ggplot() +\ngeom_smooth(data = reddit_emotions, aes(x = date, y = anticipation_percent, color=\"Reddit\")) + geom_smooth(data = twitter_emotions, aes(x = date, y = anticipation_percent, color = \"Twitter\")) +\n    scale_color_manual(name='Social Medias',\n                     breaks=c('Reddit', 'Twitter'),\n                     values=c('Reddit'='red', 'Twitter'='blue')) +\n  labs(title=\"Twitter vs Reddit anticipation percentage by date\")\n\ndisgust <- ggplot() +\ngeom_smooth(data = reddit_emotions, aes(x = date, y = disgust_percent, color=\"Reddit\")) + geom_smooth(data = twitter_emotions, aes(x = date, y = disgust_percent, color = \"Twitter\")) +\n    scale_color_manual(name='Social Medias',\n                     breaks=c('Reddit', 'Twitter'),\n                     values=c('Reddit'='red', 'Twitter'='blue')) +\n  labs(title=\"Twitter vs Reddit disgust percentage by date\")\n\nfear <- ggplot() +\ngeom_smooth(data = reddit_emotions, aes(x = date, y = fear_percent, color=\"Reddit\")) + geom_smooth(data = twitter_emotions, aes(x = date, y = fear_percent, color = \"Twitter\")) +\n    scale_color_manual(name='Social Medias',\n                     breaks=c('Reddit', 'Twitter'),\n                     values=c('Reddit'='red', 'Twitter'='blue')) +\n  labs(title=\"Twitter vs Reddit fear percentage by date\")\n\njoy <- ggplot() +\ngeom_smooth(data = reddit_emotions, aes(x = date, y = joy_percent, color=\"Reddit\")) + geom_smooth(data = twitter_emotions, aes(x = date, y = joy_percent, color = \"Twitter\")) +\n    scale_color_manual(name='Social Medias',\n                     breaks=c('Reddit', 'Twitter'),\n                     values=c('Reddit'='red', 'Twitter'='blue')) +\n  labs(title=\"Twitter vs Reddit joy percentage by date\")\n\nsadness <- ggplot() +\ngeom_smooth(data = reddit_emotions, aes(x = date, y = sadness_percent, color=\"Reddit\")) + geom_smooth(data = twitter_emotions, aes(x = date, y = sadness_percent, color = \"Twitter\")) +\n    scale_color_manual(name='Social Medias',\n                     breaks=c('Reddit', 'Twitter'),\n                     values=c('Reddit'='red', 'Twitter'='blue')) +\n  labs(title=\"Twitter vs Reddit sadness percentage by date\")\n\nsurprise <- ggplot() +\ngeom_smooth(data = reddit_emotions, aes(x = date, y = surprise_percent, color=\"Reddit\")) + geom_smooth(data = twitter_emotions, aes(x = date, y = surprise_percent, color = \"Twitter\")) +\n    scale_color_manual(name='Social Medias',\n                     breaks=c('Reddit', 'Twitter'),\n                     values=c('Reddit'='red', 'Twitter'='blue')) +\n  labs(title=\"Twitter vs Reddit surprise percentage by date\")\n\ntrust <- ggplot() +\ngeom_smooth(data = reddit_emotions, aes(x = date, y = trust_percent, color=\"Reddit\")) + geom_smooth(data = twitter_emotions, aes(x = date, y = trust_percent, color = \"Twitter\")) +\n    scale_color_manual(name='Social Medias',\n                     breaks=c('Reddit', 'Twitter'),\n                     values=c('Reddit'='red', 'Twitter'='blue')) +\n  labs(title=\"Twitter vs Reddit trust percentage by date\")\n\n\nnegative <- ggplot() +\ngeom_smooth(data = reddit_emotions, aes(x = date, y = negative_percent, color=\"Reddit\")) + geom_smooth(data = twitter_emotions, aes(x = date, y = negative_percent, color = \"Twitter\")) +\n    scale_color_manual(name='Social Medias',\n                     breaks=c('Reddit', 'Twitter'),\n                     values=c('Reddit'='red', 'Twitter'='blue')) +\n  labs(title=\"Twitter vs Reddit negativeness percentage by date\")\n\npositive <- ggplot() +\ngeom_smooth(data = reddit_emotions, aes(x = date, y = positive_percent, color=\"Reddit\")) + geom_smooth(data = twitter_emotions, aes(x = date, y = positive_percent, color = \"Twitter\")) +\n    scale_color_manual(name='Social Medias',\n                     breaks=c('Reddit', 'Twitter'),\n                     values=c('Reddit'='red', 'Twitter'='blue')) +\n  labs(title=\"Twitter vs Reddit positveness percentage by date\")\n\nanger / disgust \n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`geom_smooth()` using method = 'loess' and formula 'y ~ x'\n`geom_smooth()` using method = 'loess' and formula 'y ~ x'\n`geom_smooth()` using method = 'loess' and formula 'y ~ x'\n`geom_smooth()` using method = 'loess' and formula 'y ~ x'\n```\n:::\n\n::: {.cell-output-display}\n![](BlogPost6_MollyHackbarth_files/figure-html/filter count-1.png){width=672}\n:::\n\n```{.r .cell-code}\nfear / sadness \n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`geom_smooth()` using method = 'loess' and formula 'y ~ x'\n`geom_smooth()` using method = 'loess' and formula 'y ~ x'\n`geom_smooth()` using method = 'loess' and formula 'y ~ x'\n`geom_smooth()` using method = 'loess' and formula 'y ~ x'\n```\n:::\n\n::: {.cell-output-display}\n![](BlogPost6_MollyHackbarth_files/figure-html/filter count-2.png){width=672}\n:::\n\n```{.r .cell-code}\nanticipation / joy \n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`geom_smooth()` using method = 'loess' and formula 'y ~ x'\n`geom_smooth()` using method = 'loess' and formula 'y ~ x'\n`geom_smooth()` using method = 'loess' and formula 'y ~ x'\n`geom_smooth()` using method = 'loess' and formula 'y ~ x'\n```\n:::\n\n::: {.cell-output-display}\n![](BlogPost6_MollyHackbarth_files/figure-html/filter count-3.png){width=672}\n:::\n\n```{.r .cell-code}\nsurprise / trust\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`geom_smooth()` using method = 'loess' and formula 'y ~ x'\n`geom_smooth()` using method = 'loess' and formula 'y ~ x'\n`geom_smooth()` using method = 'loess' and formula 'y ~ x'\n`geom_smooth()` using method = 'loess' and formula 'y ~ x'\n```\n:::\n\n::: {.cell-output-display}\n![](BlogPost6_MollyHackbarth_files/figure-html/filter count-4.png){width=672}\n:::\n\n```{.r .cell-code}\npositive/negative\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`geom_smooth()` using method = 'loess' and formula 'y ~ x'\n`geom_smooth()` using method = 'loess' and formula 'y ~ x'\n`geom_smooth()` using method = 'loess' and formula 'y ~ x'\n`geom_smooth()` using method = 'loess' and formula 'y ~ x'\n```\n:::\n\n::: {.cell-output-display}\n![](BlogPost6_MollyHackbarth_files/figure-html/filter count-5.png){width=672}\n:::\n\n```{.r .cell-code}\ntwitter_reddit_sentiment <- ggplot() +\ngeom_smooth(data = reddit_emotions, aes(x = date, y = polarity, color=\"Reddit\")) + geom_smooth(data = twitter_emotions, aes(x = date, y = polarity, color = \"Twitter\")) + \nscale_color_manual(name='Social Medias',\n                  breaks=c('Reddit', 'Twitter'),\n                  values=c('Reddit'='red', 'Twitter'='blue')) +\n  labs(title=\"Twitter vs Reddit Average Dictionary Sentiment\")\n\ntwitter_reddit_sentiment\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`geom_smooth()` using method = 'loess' and formula 'y ~ x'\n`geom_smooth()` using method = 'loess' and formula 'y ~ x'\n```\n:::\n\n::: {.cell-output-display}\n![](BlogPost6_MollyHackbarth_files/figure-html/filter count-6.png){width=672}\n:::\n:::\n\n\nSince we have it in a line graph, lets go ahead and try to do a comparison in a bar chart for all emotions together.\n\n## Graphs New!\n\n\n::: {.cell hash='BlogPost6_MollyHackbarth_cache/html/bar chart graph_df29931c569c8a22f153e2e1ef2793dc'}\n\n```{.r .cell-code}\ntwitter_emotions_pivot <- twitter_emotions %>% \n  pivot_longer(c(anger, disgust, fear, sadness, anticipation, joy, surprise, trust), names_to = \"words\")\n\nt_emotions <- ggplot() + \n  geom_bar(data = twitter_emotions_pivot, aes(x = words, weight = value, fill = words)) + ggtitle(\"Twitter sentiments\")\n\nreddit_emotions_pivot <- reddit_emotions %>% \n  pivot_longer(c(anger, disgust, fear, sadness, anticipation, joy, surprise, trust), names_to = \"words\")\n\nr_emotions <- ggplot() + \n  geom_bar(data = reddit_emotions_pivot, aes(x = words, weight = value, fill = words)) + ggtitle(\"Reddit sentiments\")\n\nt_emotions \n```\n\n::: {.cell-output-display}\n![](BlogPost6_MollyHackbarth_files/figure-html/bar chart graph-1.png){width=672}\n:::\n\n```{.r .cell-code}\nr_emotions\n```\n\n::: {.cell-output-display}\n![](BlogPost6_MollyHackbarth_files/figure-html/bar chart graph-2.png){width=672}\n:::\n\n```{.r .cell-code}\ntwitter_emotions_pivot_2 <- twitter_emotions %>% \n  pivot_longer(c(positive, negative), names_to = \"words\")\n\nt_np <- ggplot() + \n  geom_bar(data = twitter_emotions_pivot_2, aes(x = words, weight = value, fill = words)) + ggtitle(\"Twitter sentiments\")\n\nreddit_emotions_pivot_2 <- reddit_emotions %>% \n  pivot_longer(c(positive, negative), names_to = \"words\")\n\nr_np <- ggplot() + \n  geom_bar(data = reddit_emotions_pivot_2, aes(x = words, weight = value, fill = words)) + ggtitle(\"Reddit sentiments\")\n\nt_np\n```\n\n::: {.cell-output-display}\n![](BlogPost6_MollyHackbarth_files/figure-html/bar chart graph-3.png){width=672}\n:::\n\n```{.r .cell-code}\nr_np\n```\n\n::: {.cell-output-display}\n![](BlogPost6_MollyHackbarth_files/figure-html/bar chart graph-4.png){width=672}\n:::\n:::\n\n\nOverall we're able to see that for Twitter the top three sentiments are: anticipation, joy and trust. For Reddit the top three sentiments are: trust, anticipation, and joy. This is interesting as it seems Reddit and Twitter share similar feelings about the show from a pure word count standpoint.\n\nAdditionally we can see there is a much higher word count for positive words for Reddit and Twitter.\n\n## Sentiment New!\n\nI also want to try another way of doing sentiment analysis. This is a packaged called sentimentR\n\n\n::: {.cell hash='BlogPost6_MollyHackbarth_cache/html/twitter sentiment r_9b7f7caf5e00079228e0cafe6f98c3d5'}\n\n```{.r .cell-code}\n# create named array of equal lengths\ntwitter_sen <- sapply(twitter_lemmitized, '[', seq(max(lengths(twitter_lemmitized))))\n\n\ntout <- twitter_sen %>%\n   as_tibble()  %>%\n   pivot_longer(cols = everything(), names_to = \"text\", values_to = \"tokens\") %>% \n  arrange(text) %>% \n  group_by(text) %>% \nsummarise(tokens = paste(tokens, collapse = \" \"))\n\ntout$date <- tdf_nrc$date\n\ntout <- tout %>% filter(!is.na(tokens)) \n\ntout$tokens <- gsub('NA', '', tout$tokens)\n\ntwitter_sent <- tout %>% \n  get_sentences() %>% \n  sentiment() %>% \n  mutate(polarity_level = ifelse(sentiment < 0.2, \"Negative\",\n                                 ifelse(sentiment > 0.2, \"Positive\",\"Neutral\")))  %>% \n  filter(word_count > 10)\n          \n\ntwitter_sent$tokens %>% \n  get_sentences(by = NULL) %>% \n  sentiment_by() %>% #View()\n  highlight() %>% \n  view()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nSaved in /var/folders/65/1r_9cvw92l52plzl3g17621c0000gn/T//RtmpqlWW4k/polarity.html\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nOpening /var/folders/65/1r_9cvw92l52plzl3g17621c0000gn/T//RtmpqlWW4k/polarity.html ...\n```\n:::\n\n```{.r .cell-code}\ntwitter_sent$tokens %>% \n  get_sentences() %>% \n  sentiment_by(by = NULL) %>% #View()\n  ggplot() + geom_density(aes(ave_sentiment))\n```\n\n::: {.cell-output-display}\n![](BlogPost6_MollyHackbarth_files/figure-html/twitter sentiment r-1.png){width=672}\n:::\n:::\n\n::: {.cell hash='BlogPost6_MollyHackbarth_cache/html/new sentinment reddit r_8c038b8e2df29249c5ec06257428c1e0'}\n\n```{.r .cell-code}\n# create named array of equal lengths\n\nreddit_lemmitized$date <- reddit_lemmitized$date\n\nreddit_sen <- sapply(reddit_lemmitized, '[', seq(max(lengths(reddit_lemmitized))))\n\nrout <- reddit_sen %>%\n   as_tibble()  %>%\n   pivot_longer(cols = everything(), names_to = \"text\", values_to = \"tokens\") %>%\n   arrange(text) %>% \n  group_by(text) %>% \nsummarise(tokens = paste(tokens, collapse = \" \"))\n\nrout$date <- rdf_nrc$date\n\nrout <- rout %>% filter(!is.na(tokens))  # remove NA values of each text\n\nrout$tokens <- gsub('NA', '', rout$tokens)\n \nreddit_sent <- rout %>% \n  get_sentences() %>% \n  sentiment() %>% \n  mutate(polarity_level = ifelse(sentiment < 0.2, \"Negative\",\n                                 ifelse(sentiment > 0.2, \"Positive\",\"Neutral\"))) %>% \n filter(word_count > 10)\n          \nreddit_sent$tokens %>% \n  get_sentences(by = NULL) %>% \n  sentiment_by() %>% #View()\n  highlight() \n```\n\n::: {.cell-output .cell-output-stderr}\n```\nSaved in /var/folders/65/1r_9cvw92l52plzl3g17621c0000gn/T//RtmpqlWW4k/polarity.html\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nOpening /var/folders/65/1r_9cvw92l52plzl3g17621c0000gn/T//RtmpqlWW4k/polarity.html ...\n```\n:::\n\n```{.r .cell-code}\nreddit_sent$tokens %>% \n  get_sentences() %>% \n  sentiment_by() %>% #View()\n  ggplot() + geom_density(aes(ave_sentiment))\n```\n\n::: {.cell-output-display}\n![](BlogPost6_MollyHackbarth_files/figure-html/new sentinment reddit r-1.png){width=672}\n:::\n:::\n\n\nHere we're able to see what the tokens cleaned up into sentences look like to sentimentr. I had tried it originally with the full database (no changing of the words at all) and it was interesting to see the sentence_id actually count the amount of sentences! What I like about this one is it shows you the positive, negative, and neutral by highlighting it and popping up. It allows you to read the sentences to see if you agree with them or not.\n\nInterestingly the overall sentiment according to this package is a bit positive but also fairly neutral by the density.\n\nUnfortunately for word count in a sentence I couldn't really filter out too many due to Twitter having a character limit. To deal with this I made a filter of at least 10 words.\n\nBelow you will find the non-edited data.\n\n\n::: {.cell hash='BlogPost6_MollyHackbarth_cache/html/reddit full_444114f1f79b9d087cbadbe9a0ecf460'}\n\n```{.r .cell-code}\nreddit_full <- reddit %>% \n  get_sentences() %>% \n  sentiment() %>% \n  mutate(polarity_level = ifelse(sentiment < 0.2, \"Negative\",\n                                 ifelse(sentiment > 0.2, \"Positive\",\"Neutral\"))) %>% \n  filter(word_count > 10)\n          \nreddit_full$text %>% \n  get_sentences(by = NULL) %>% \n  sentiment_by() %>% #View()\n  highlight() \n```\n\n::: {.cell-output .cell-output-stderr}\n```\nSaved in /var/folders/65/1r_9cvw92l52plzl3g17621c0000gn/T//RtmpqlWW4k/polarity.html\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nOpening /var/folders/65/1r_9cvw92l52plzl3g17621c0000gn/T//RtmpqlWW4k/polarity.html ...\n```\n:::\n\n```{.r .cell-code}\nreddit_full$text %>% \n  get_sentences() %>% \n  sentiment_by() %>% #View()\n  ggplot() + geom_density(aes(ave_sentiment))\n```\n\n::: {.cell-output-display}\n![](BlogPost6_MollyHackbarth_files/figure-html/reddit full-1.png){width=672}\n:::\n:::\n\n::: {.cell hash='BlogPost6_MollyHackbarth_cache/html/twitter full_02bd5dfa15dab06709d45987f00c6da6'}\n\n```{.r .cell-code}\ntwitter_full <- twitter %>% \n  get_sentences() %>% \n  sentiment() %>% \n  mutate(polarity_level = ifelse(sentiment < 0.2, \"Negative\",\n                                 ifelse(sentiment > 0.2, \"Positive\",\"Neutral\")))  %>% \n  filter(word_count > 10)\n          \n\ntwitter_full$text %>% \n  get_sentences(by = NULL) %>% \n  sentiment_by() %>% #View()\n  highlight() %>% \n  view()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nSaved in /var/folders/65/1r_9cvw92l52plzl3g17621c0000gn/T//RtmpqlWW4k/polarity.html\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nOpening /var/folders/65/1r_9cvw92l52plzl3g17621c0000gn/T//RtmpqlWW4k/polarity.html ...\n```\n:::\n\n```{.r .cell-code}\ntwitter_full$text %>% \n  get_sentences() %>% \n  sentiment_by(by = NULL) %>% #View()\n  ggplot() + geom_density(aes(ave_sentiment))\n```\n\n::: {.cell-output-display}\n![](BlogPost6_MollyHackbarth_files/figure-html/twitter full-1.png){width=672}\n:::\n:::\n\n::: {.cell hash='BlogPost6_MollyHackbarth_cache/html/comparision_fadbbd2c446de036b532e5a83650fa00'}\n\n```{.r .cell-code}\ntest <- twitter_full %>% \n  group_by(date) %>% \n  summarise(sentiment = mean(sentiment),\n         word_count = sum(word_count)) \n\ntest2 <- reddit_full %>% \n  group_by(date) %>% \n  summarise(sentiment = mean(sentiment),\n         word_count = sum(word_count)) \n\ntest3 <- twitter_sent %>% \n  group_by(date) %>% \n  summarise(sentiment = mean(sentiment),\n         word_count = sum(word_count)) \n\ntest4 <- reddit_sent %>% \n  group_by(date) %>% \n  summarise(sentiment = mean(sentiment),\n         word_count = sum(word_count)) \n\n         ggplot() +\ngeom_smooth(data = test, aes(x = date, y = sentiment, color=\"Twitter\")) + geom_smooth(data = test2, aes(x = date, y = sentiment, color = \"Reddit\")) +\n    scale_color_manual(name='Social Medias',\n                     breaks=c('Reddit', 'Twitter'),\n                     values=c('Reddit'='#EEA2AD', 'Twitter'='cadetblue1')) +\n  labs(title=\"Twitter vs Reddit average Sentiment of Uncleaned Data\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`geom_smooth()` using method = 'loess' and formula 'y ~ x'\n`geom_smooth()` using method = 'loess' and formula 'y ~ x'\n```\n:::\n\n::: {.cell-output-display}\n![](BlogPost6_MollyHackbarth_files/figure-html/comparision-1.png){width=672}\n:::\n\n```{.r .cell-code}\n         ggplot() +\ngeom_smooth(data = test3, aes(x = date, y = sentiment, color=\"Twitter\")) + geom_smooth(data = test4, aes(x = date, y = sentiment, color = \"Reddit\")) +\n    scale_color_manual(name='Social Medias',\n                     breaks=c('Reddit', 'Twitter'),\n                     values=c('Reddit'='red', 'Twitter'='blue')) +\n  labs(title=\"Twitter vs Reddit average Sentiment of Tokenized Data\")         \n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`geom_smooth()` using method = 'loess' and formula 'y ~ x'\n`geom_smooth()` using method = 'loess' and formula 'y ~ x'\n```\n:::\n\n::: {.cell-output-display}\n![](BlogPost6_MollyHackbarth_files/figure-html/comparision-2.png){width=672}\n:::\n\n```{.r .cell-code}\n ggplot() + geom_smooth(data = test4, aes(x = date, y = sentiment, color = \"Reddit Tokenized\")) + geom_smooth(data = test3, aes(x = date, y = sentiment, color = \"Twitter Tokenized\")) + geom_smooth(data = test2, aes(x = date, y = sentiment, color = \"Reddit Uncleaned Data\")) + geom_smooth(data = test, aes(x = date, y = sentiment, color = \"Twitter Uncleaned Data\")) + \nscale_color_manual(name='Social Medias',\n                  breaks=c('Reddit Tokenized', 'Twitter Tokenized', 'Reddit Uncleaned Data', 'Twitter Uncleaned Data'),\n                  values=c('Reddit Tokenized'='Red', 'Twitter Tokenized'='blue', 'Reddit Uncleaned Data' = '#EEA2AD', 'Twitter Uncleaned Data' = 'cadetblue1')) +\n  labs(title=\"Twitter vs Reddit Average Sentiment\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`geom_smooth()` using method = 'loess' and formula 'y ~ x'\n`geom_smooth()` using method = 'loess' and formula 'y ~ x'\n`geom_smooth()` using method = 'loess' and formula 'y ~ x'\n`geom_smooth()` using method = 'loess' and formula 'y ~ x'\n```\n:::\n\n::: {.cell-output-display}\n![](BlogPost6_MollyHackbarth_files/figure-html/comparision-3.png){width=672}\n:::\n\n```{.r .cell-code}\n ggplot() + geom_density(data = test4, aes(sentiment, color = \"Reddit Tokenized\")) + geom_density(data = test3, aes(sentiment, color = \"Twitter Tokenized\")) + geom_density(data = test2, aes(sentiment, color = \"Reddit Uncleaned Data\")) + geom_density(data = test, aes(sentiment, color = \"Twitter Uncleaned Data\")) + \nscale_color_manual(name='Social Medias',\n                  breaks=c('Reddit Tokenized', 'Twitter Tokenized', 'Reddit Uncleaned Data', 'Twitter Uncleaned Data'),\n                  values=c('Reddit Tokenized'='Red', 'Twitter Tokenized'='blue', 'Reddit Uncleaned Data' = '#EEA2AD', 'Twitter Uncleaned Data' = 'cadetblue1')) +\n  labs(title=\"Twitter vs Reddit Average Sentiment\")\n```\n\n::: {.cell-output-display}\n![](BlogPost6_MollyHackbarth_files/figure-html/comparision-4.png){width=672}\n:::\n:::\n\n\n# Word Cloud\n\n\n::: {.cell hash='BlogPost6_MollyHackbarth_cache/html/unnamed-chunk-1_3b1600c5b382950ff923927011d650f3'}\n\n```{.r .cell-code}\ntextplot_wordcloud(twitter_corpus_dfm, max_words=200, color=\"blue\")\n```\n\n::: {.cell-output-display}\n![](BlogPost6_MollyHackbarth_files/figure-html/unnamed-chunk-1-1.png){width=672}\n:::\n\n```{.r .cell-code}\ntextplot_wordcloud(reddit_corpus_dfm, max_words=200, color=\"red\")\n```\n\n::: {.cell-output-display}\n![](BlogPost6_MollyHackbarth_files/figure-html/unnamed-chunk-1-2.png){width=672}\n:::\n:::\n\n\n# STM New!\n\nBelow I will have the STM for both reddit and twitter. This time I have added two prevalance items, polarity and dates.\n\n\n::: {.cell hash='BlogPost6_MollyHackbarth_cache/html/stm reddit_e43aa656ada515f1a4bc431be5d8f8ec'}\n\n```{.r .cell-code}\nk <- 25\nrModel <- dfm(reddit_lemmitized)\n\ndocvars(reddit_lemmitized) <- rModel\n\nrModel$polarity <- rdf_nrc$polarity\n\nrModel <- stm(rModel,\n                K = k,\n              prevalence = ~ polarity + date,\n               max.em.its = 1000,\n               seed = 1234,\n               init.type = \"Spectral\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in dfm2stm(x, docvars, omit_empty = TRUE): Dropped empty document(s):\ntext240, text459, text800, text1726, text2722, text2723, text3049, text3388,\ntext3790, text4268, text4653, text4658, text4886, text5437, text5520, text9213,\ntext9500\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nBeginning Spectral Initialization \n\t Calculating the gram matrix...\n\t Using only 10000 most frequent terms during initialization...\n\t Finding anchor words...\n \t.........................\n\t Recovering initialization...\n \t...................................................................................................\nInitialization complete.\n....................................................................................................\nCompleted E-Step (7 seconds). \nCompleted M-Step. \nCompleting Iteration 1 (approx. per word bound = -7.297) \n....................................................................................................\nCompleted E-Step (5 seconds). \nCompleted M-Step. \nCompleting Iteration 2 (approx. per word bound = -7.135, relative change = 2.227e-02) \n....................................................................................................\nCompleted E-Step (5 seconds). \nCompleted M-Step. \nCompleting Iteration 3 (approx. per word bound = -7.056, relative change = 1.100e-02) \n....................................................................................................\nCompleted E-Step (4 seconds). \nCompleted M-Step. \nCompleting Iteration 4 (approx. per word bound = -7.013, relative change = 6.165e-03) \n....................................................................................................\nCompleted E-Step (4 seconds). \nCompleted M-Step. \nCompleting Iteration 5 (approx. per word bound = -6.983, relative change = 4.178e-03) \nTopic 1: can, know, translation, just, feel \n Topic 2: big, woman, man, japan, issue \n Topic 3: show, think, love, see, reality \n Topic 4: version, us, one, love, lib \n Topic 5: mori, minami, say, watch, show \n Topic 6: wed, like, ring, style, get \n Topic 7: japan, like, thing, see, will \n Topic 8: make, look, feel, couple, show \n Topic 9: think, want, take, tell, episode \n Topic 10: point, good, way, like, thing \n Topic 11: ryotaro, motomi, thank, relationship, say \n Topic 12: friend, love, feel, wataru, see \n Topic 13: look, good, think, like, someone \n Topic 14: like, think, people, also, make \n Topic 15: girl, good, shuntaro, still, say \n Topic 16: go, say, just, need, know \n Topic 17: say, hair, ask, just, look \n Topic 18: english, thing, speak, like, make \n Topic 19: japanese, also, want, japan, good \n Topic 20: happy, just, lol, couple, get \n Topic 21: mean, say, yes, get, dream \n Topic 22: like, get, marry, miss, want \n Topic 23: think, like, work, business, make \n Topic 24: people, just, like, time, show \n Topic 25: like, just, really, good, feel \n....................................................................................................\nCompleted E-Step (4 seconds). \nCompleted M-Step. \nCompleting Iteration 6 (approx. per word bound = -6.962, relative change = 3.009e-03) \n....................................................................................................\nCompleted E-Step (4 seconds). \nCompleted M-Step. \nCompleting Iteration 7 (approx. per word bound = -6.947, relative change = 2.183e-03) \n....................................................................................................\nCompleted E-Step (4 seconds). \nCompleted M-Step. \nCompleting Iteration 8 (approx. per word bound = -6.936, relative change = 1.634e-03) \n....................................................................................................\nCompleted E-Step (4 seconds). \nCompleted M-Step. \nCompleting Iteration 9 (approx. per word bound = -6.927, relative change = 1.257e-03) \n....................................................................................................\nCompleted E-Step (4 seconds). \nCompleted M-Step. \nCompleting Iteration 10 (approx. per word bound = -6.920, relative change = 9.765e-04) \nTopic 1: can, translation, know, say, word \n Topic 2: woman, man, big, japan, guy \n Topic 3: show, reality, think, tv, see \n Topic 4: us, version, watch, love, lib \n Topic 5: mori, minami, want, say, like \n Topic 6: wed, style, ring, wear, dress \n Topic 7: japan, physical, people, common, thing \n Topic 8: make, feel, get, couple, like \n Topic 9: think, tell, want, like, take \n Topic 10: point, way, thing, good, weird \n Topic 11: thank, ryotaro, motomi, relationship, together \n Topic 12: wataru, friend, midori, love, see \n Topic 13: look, good, think, find, like \n Topic 14: like, think, ayano, seem, people \n Topic 15: girl, pretty, cast, still, young \n Topic 16: go, say, just, know, will \n Topic 17: hair, ask, question, priya, say \n Topic 18: speak, english, thing, sound, like \n Topic 19: japanese, also, japan, live, culture \n Topic 20: couple, lol, happy, post, just \n Topic 21: mean, yes, say, dream, family \n Topic 22: marry, get, like, house, miss \n Topic 23: work, think, business, like, mizuki \n Topic 24: people, just, time, take, even \n Topic 25: just, like, really, good, can \n....................................................................................................\nCompleted E-Step (4 seconds). \nCompleted M-Step. \nCompleting Iteration 11 (approx. per word bound = -6.915, relative change = 7.573e-04) \n....................................................................................................\nCompleted E-Step (4 seconds). \nCompleted M-Step. \nCompleting Iteration 12 (approx. per word bound = -6.911, relative change = 5.842e-04) \n....................................................................................................\nCompleted E-Step (4 seconds). \nCompleted M-Step. \nCompleting Iteration 13 (approx. per word bound = -6.908, relative change = 4.670e-04) \n....................................................................................................\nCompleted E-Step (4 seconds). \nCompleted M-Step. \nCompleting Iteration 14 (approx. per word bound = -6.905, relative change = 3.923e-04) \n....................................................................................................\nCompleted E-Step (4 seconds). \nCompleted M-Step. \nCompleting Iteration 15 (approx. per word bound = -6.903, relative change = 3.454e-04) \nTopic 1: word, say, translation, can, use \n Topic 2: woman, man, big, old, guy \n Topic 3: show, reality, tv, think, see \n Topic 4: us, watch, love, version, lib \n Topic 5: mori, minami, want, say, like \n Topic 6: wed, style, ring, wear, dress \n Topic 7: japan, people, physical, attraction, common \n Topic 8: make, feel, get, cute, age \n Topic 9: think, tell, want, just, like \n Topic 10: point, gt, weird, way, thing \n Topic 11: thank, ryotaro, motomi, relationship, hope \n Topic 12: wataru, midori, friend, love, misaki \n Topic 13: good, look, think, find, like \n Topic 14: like, think, seem, ayano, shuntaro \n Topic 15: girl, pretty, cast, call, young \n Topic 16: go, say, just, know, will \n Topic 17: ask, hair, question, priya, just \n Topic 18: speak, english, thing, talk, like \n Topic 19: japanese, japan, culture, live, also \n Topic 20: couple, lol, episode, happy, post \n Topic 21: yes, mean, say, family, dream \n Topic 22: get, marry, house, know, like \n Topic 23: work, think, business, mizuki, like \n Topic 24: people, time, just, take, even \n Topic 25: just, can, really, feel, like \n....................................................................................................\nCompleted E-Step (4 seconds). \nCompleted M-Step. \nCompleting Iteration 16 (approx. per word bound = -6.901, relative change = 2.972e-04) \n....................................................................................................\nCompleted E-Step (4 seconds). \nCompleted M-Step. \nCompleting Iteration 17 (approx. per word bound = -6.899, relative change = 2.391e-04) \n....................................................................................................\nCompleted E-Step (4 seconds). \nCompleted M-Step. \nCompleting Iteration 18 (approx. per word bound = -6.898, relative change = 2.098e-04) \n....................................................................................................\nCompleted E-Step (4 seconds). \nCompleted M-Step. \nCompleting Iteration 19 (approx. per word bound = -6.896, relative change = 1.995e-04) \n....................................................................................................\nCompleted E-Step (4 seconds). \nCompleted M-Step. \nCompleting Iteration 20 (approx. per word bound = -6.895, relative change = 1.801e-04) \nTopic 1: word, say, use, translation, can \n Topic 2: woman, man, big, old, guy \n Topic 3: show, reality, tv, edit, see \n Topic 4: us, watch, love, version, lib \n Topic 5: mori, minami, want, say, change \n Topic 6: wed, style, ring, wear, dress \n Topic 7: people, japan, physical, attraction, common \n Topic 8: make, feel, get, cute, age \n Topic 9: think, tell, just, want, try \n Topic 10: gt, point, weird, comment, thing \n Topic 11: thank, ryotaro, motomi, hope, relationship \n Topic 12: midori, wataru, friend, misaki, love \n Topic 13: good, look, think, find, like \n Topic 14: like, seem, think, ayano, shuntaro \n Topic 15: girl, pretty, voice, call, forget \n Topic 16: go, say, just, know, will \n Topic 17: ask, hair, question, priya, answer \n Topic 18: speak, talk, english, thing, like \n Topic 19: japanese, culture, japan, live, also \n Topic 20: couple, lol, episode, happy, together \n Topic 21: yes, mean, say, family, dream \n Topic 22: get, marry, know, house, still \n Topic 23: business, think, mizuki, work, marriage \n Topic 24: people, time, just, take, see \n Topic 25: can, just, feel, really, thing \n....................................................................................................\nCompleted E-Step (4 seconds). \nCompleted M-Step. \nCompleting Iteration 21 (approx. per word bound = -6.894, relative change = 1.607e-04) \n....................................................................................................\nCompleted E-Step (4 seconds). \nCompleted M-Step. \nCompleting Iteration 22 (approx. per word bound = -6.893, relative change = 1.459e-04) \n....................................................................................................\nCompleted E-Step (4 seconds). \nCompleted M-Step. \nCompleting Iteration 23 (approx. per word bound = -6.892, relative change = 1.262e-04) \n....................................................................................................\nCompleted E-Step (4 seconds). \nCompleted M-Step. \nCompleting Iteration 24 (approx. per word bound = -6.891, relative change = 1.139e-04) \n....................................................................................................\nCompleted E-Step (4 seconds). \nCompleted M-Step. \nCompleting Iteration 25 (approx. per word bound = -6.890, relative change = 1.076e-04) \nTopic 1: word, say, use, translation, can \n Topic 2: woman, man, old, big, year \n Topic 3: show, reality, tv, edit, see \n Topic 4: watch, us, love, version, lib \n Topic 5: mori, minami, want, say, change \n Topic 6: wed, style, ring, wear, dress \n Topic 7: people, japan, physical, attraction, common \n Topic 8: make, feel, much, age, cute \n Topic 9: tell, think, just, try, want \n Topic 10: gt, point, comment, weird, scene \n Topic 11: thank, ryotaro, motomi, hope, love \n Topic 12: midori, wataru, friend, misaki, kaoru \n Topic 13: good, look, think, find, guy \n Topic 14: like, seem, think, feel, ayano \n Topic 15: girl, voice, pretty, call, remember \n Topic 16: go, say, just, know, end \n Topic 17: ask, hair, question, priya, answer \n Topic 18: speak, talk, english, thing, sound \n Topic 19: japanese, culture, japan, live, also \n Topic 20: couple, lol, episode, together, happy \n Topic 21: yes, mean, say, family, give \n Topic 22: get, marry, know, maybe, house \n Topic 23: business, mizuki, think, plan, money \n Topic 24: people, time, just, take, see \n Topic 25: can, partner, able, work, thing \n....................................................................................................\nCompleted E-Step (4 seconds). \nCompleted M-Step. \nCompleting Iteration 26 (approx. per word bound = -6.890, relative change = 9.674e-05) \n....................................................................................................\nCompleted E-Step (4 seconds). \nCompleted M-Step. \nCompleting Iteration 27 (approx. per word bound = -6.889, relative change = 8.652e-05) \n....................................................................................................\nCompleted E-Step (4 seconds). \nCompleted M-Step. \nCompleting Iteration 28 (approx. per word bound = -6.889, relative change = 8.545e-05) \n....................................................................................................\nCompleted E-Step (4 seconds). \nCompleted M-Step. \nCompleting Iteration 29 (approx. per word bound = -6.888, relative change = 7.817e-05) \n....................................................................................................\nCompleted E-Step (4 seconds). \nCompleted M-Step. \nCompleting Iteration 30 (approx. per word bound = -6.887, relative change = 7.407e-05) \nTopic 1: use, say, word, translation, can \n Topic 2: woman, man, old, big, year \n Topic 3: show, reality, tv, edit, also \n Topic 4: watch, us, love, version, lib \n Topic 5: mori, want, minami, say, career \n Topic 6: wed, style, ring, wear, dress \n Topic 7: people, japan, physical, attraction, common \n Topic 8: make, much, age, pod, feel \n Topic 9: tell, think, try, just, something \n Topic 10: gt, point, comment, weird, scene \n Topic 11: thank, hope, ryotaro, motomi, love \n Topic 12: midori, wataru, friend, misaki, kaoru \n Topic 13: good, think, look, find, agree \n Topic 14: like, seem, feel, think, ayano \n Topic 15: girl, voice, remember, call, forget \n Topic 16: go, say, just, know, end \n Topic 17: ask, hair, question, priya, answer \n Topic 18: talk, speak, english, sound, thing \n Topic 19: japanese, culture, japan, live, also \n Topic 20: couple, lol, episode, together, happy \n Topic 21: yes, mean, say, family, give \n Topic 22: get, marry, know, maybe, right \n Topic 23: business, mizuki, think, lie, plan \n Topic 24: people, time, just, take, see \n Topic 25: can, partner, able, work, thing \n....................................................................................................\nCompleted E-Step (4 seconds). \nCompleted M-Step. \nCompleting Iteration 31 (approx. per word bound = -6.887, relative change = 7.638e-05) \n....................................................................................................\nCompleted E-Step (4 seconds). \nCompleted M-Step. \nCompleting Iteration 32 (approx. per word bound = -6.886, relative change = 9.379e-05) \n....................................................................................................\nCompleted E-Step (4 seconds). \nCompleted M-Step. \nCompleting Iteration 33 (approx. per word bound = -6.886, relative change = 8.288e-05) \n....................................................................................................\nCompleted E-Step (5 seconds). \nCompleted M-Step. \nCompleting Iteration 34 (approx. per word bound = -6.885, relative change = 6.460e-05) \n....................................................................................................\nCompleted E-Step (6 seconds). \nCompleted M-Step. \nCompleting Iteration 35 (approx. per word bound = -6.885, relative change = 5.316e-05) \nTopic 1: use, say, word, translation, can \n Topic 2: woman, man, old, big, year \n Topic 3: show, reality, edit, tv, also \n Topic 4: watch, us, love, version, lib \n Topic 5: mori, want, minami, say, career \n Topic 6: wed, style, ring, wear, dress \n Topic 7: japan, people, physical, attraction, common \n Topic 8: make, much, age, pod, see \n Topic 9: tell, think, try, just, something \n Topic 10: gt, comment, point, weird, scene \n Topic 11: thank, hope, ryotaro, motomi, love \n Topic 12: midori, wataru, friend, kaoru, misaki \n Topic 13: good, think, look, find, agree \n Topic 14: like, seem, feel, really, think \n Topic 15: girl, remember, voice, call, forget \n Topic 16: go, say, just, know, end \n Topic 17: ask, hair, question, priya, answer \n Topic 18: talk, speak, english, sound, thing \n Topic 19: japanese, culture, japan, live, also \n Topic 20: couple, lol, episode, together, happy \n Topic 21: yes, mean, say, family, give \n Topic 22: get, marry, know, maybe, right \n Topic 23: business, mizuki, lie, think, plan \n Topic 24: people, time, just, take, see \n Topic 25: can, partner, able, relationship, work \n....................................................................................................\nCompleted E-Step (10 seconds). \nCompleted M-Step. \nCompleting Iteration 36 (approx. per word bound = -6.885, relative change = 4.923e-05) \n....................................................................................................\nCompleted E-Step (6 seconds). \nCompleted M-Step. \nCompleting Iteration 37 (approx. per word bound = -6.884, relative change = 4.968e-05) \n....................................................................................................\nCompleted E-Step (5 seconds). \nCompleted M-Step. \nCompleting Iteration 38 (approx. per word bound = -6.884, relative change = 5.363e-05) \n....................................................................................................\nCompleted E-Step (11 seconds). \nCompleted M-Step. \nCompleting Iteration 39 (approx. per word bound = -6.884, relative change = 5.038e-05) \n....................................................................................................\nCompleted E-Step (13 seconds). \nCompleted M-Step. \nCompleting Iteration 40 (approx. per word bound = -6.883, relative change = 4.642e-05) \nTopic 1: use, say, word, translation, can \n Topic 2: woman, man, old, year, big \n Topic 3: show, reality, edit, tv, also \n Topic 4: watch, us, love, version, lib \n Topic 5: want, mori, minami, say, career \n Topic 6: wed, style, ring, wear, dress \n Topic 7: japan, people, physical, attraction, common \n Topic 8: make, much, age, pod, see \n Topic 9: tell, think, try, just, something \n Topic 10: gt, comment, point, weird, scene \n Topic 11: hope, thank, love, ryotaro, motomi \n Topic 12: midori, wataru, friend, kaoru, misaki \n Topic 13: good, think, look, find, agree \n Topic 14: like, feel, seem, really, ayano \n Topic 15: girl, remember, voice, forget, call \n Topic 16: go, say, just, know, end \n Topic 17: ask, hair, question, priya, answer \n Topic 18: talk, speak, english, sound, thing \n Topic 19: japanese, culture, japan, live, asian \n Topic 20: couple, lol, episode, together, happy \n Topic 21: yes, mean, say, family, give \n Topic 22: get, marry, know, maybe, right \n Topic 23: business, mizuki, lie, think, plan \n Topic 24: people, time, just, see, take \n Topic 25: can, partner, relationship, work, thing \n....................................................................................................\nCompleted E-Step (13 seconds). \nCompleted M-Step. \nCompleting Iteration 41 (approx. per word bound = -6.883, relative change = 4.319e-05) \n....................................................................................................\nCompleted E-Step (6 seconds). \nCompleted M-Step. \nCompleting Iteration 42 (approx. per word bound = -6.883, relative change = 4.417e-05) \n....................................................................................................\nCompleted E-Step (5 seconds). \nCompleted M-Step. \nCompleting Iteration 43 (approx. per word bound = -6.882, relative change = 4.848e-05) \n....................................................................................................\nCompleted E-Step (5 seconds). \nCompleted M-Step. \nCompleting Iteration 44 (approx. per word bound = -6.882, relative change = 4.685e-05) \n....................................................................................................\nCompleted E-Step (4 seconds). \nCompleted M-Step. \nCompleting Iteration 45 (approx. per word bound = -6.882, relative change = 4.193e-05) \nTopic 1: use, say, word, translation, understand \n Topic 2: woman, man, old, year, young \n Topic 3: show, reality, edit, tv, also \n Topic 4: watch, us, love, version, lib \n Topic 5: want, mori, minami, say, dream \n Topic 6: wed, style, ring, wear, dress \n Topic 7: japan, physical, people, attraction, common \n Topic 8: make, much, pod, age, see \n Topic 9: tell, think, try, just, something \n Topic 10: gt, comment, point, weird, scene \n Topic 11: love, hope, thank, ryotaro, motomi \n Topic 12: midori, wataru, friend, kaoru, misaki \n Topic 13: think, good, look, find, agree \n Topic 14: like, feel, seem, really, ayano \n Topic 15: girl, remember, voice, forget, notice \n Topic 16: go, say, just, know, end \n Topic 17: ask, hair, question, answer, mention \n Topic 18: talk, speak, english, sound, thing \n Topic 19: japanese, culture, japan, live, asian \n Topic 20: couple, lol, episode, together, see \n Topic 21: yes, mean, say, family, give \n Topic 22: get, marry, know, maybe, right \n Topic 23: business, mizuki, lie, priya, think \n Topic 24: people, time, see, take, just \n Topic 25: relationship, can, partner, work, thing \n....................................................................................................\nCompleted E-Step (5 seconds). \nCompleted M-Step. \nCompleting Iteration 46 (approx. per word bound = -6.881, relative change = 4.013e-05) \n....................................................................................................\nCompleted E-Step (7 seconds). \nCompleted M-Step. \nCompleting Iteration 47 (approx. per word bound = -6.881, relative change = 4.279e-05) \n....................................................................................................\nCompleted E-Step (7 seconds). \nCompleted M-Step. \nCompleting Iteration 48 (approx. per word bound = -6.881, relative change = 4.420e-05) \n....................................................................................................\nCompleted E-Step (5 seconds). \nCompleted M-Step. \nCompleting Iteration 49 (approx. per word bound = -6.880, relative change = 4.704e-05) \n....................................................................................................\nCompleted E-Step (7 seconds). \nCompleted M-Step. \nCompleting Iteration 50 (approx. per word bound = -6.880, relative change = 4.813e-05) \nTopic 1: use, say, word, translation, understand \n Topic 2: woman, man, old, year, young \n Topic 3: show, reality, edit, tv, also \n Topic 4: watch, us, love, version, lib \n Topic 5: want, mori, minami, say, dream \n Topic 6: wed, style, ring, wear, dress \n Topic 7: japan, physical, people, attraction, common \n Topic 8: make, much, pod, age, big \n Topic 9: tell, think, try, just, something \n Topic 10: comment, gt, point, weird, bite \n Topic 11: love, hope, thank, ryotaro, motomi \n Topic 12: midori, wataru, friend, kaoru, misaki \n Topic 13: think, good, look, find, agree \n Topic 14: like, feel, seem, really, ayano \n Topic 15: girl, remember, voice, notice, forget \n Topic 16: say, go, just, know, want \n Topic 17: ask, hair, question, answer, mention \n Topic 18: talk, speak, english, sound, thing \n Topic 19: japanese, japan, culture, live, asian \n Topic 20: couple, lol, episode, together, one \n Topic 21: yes, mean, say, give, family \n Topic 22: get, marry, know, maybe, right \n Topic 23: priya, mizuki, business, lie, think \n Topic 24: people, time, see, take, just \n Topic 25: relationship, can, partner, will, work \n....................................................................................................\nCompleted E-Step (4 seconds). \nCompleted M-Step. \nCompleting Iteration 51 (approx. per word bound = -6.880, relative change = 4.593e-05) \n....................................................................................................\nCompleted E-Step (7 seconds). \nCompleted M-Step. \nCompleting Iteration 52 (approx. per word bound = -6.880, relative change = 4.070e-05) \n....................................................................................................\nCompleted E-Step (10 seconds). \nCompleted M-Step. \nCompleting Iteration 53 (approx. per word bound = -6.879, relative change = 3.717e-05) \n....................................................................................................\nCompleted E-Step (16 seconds). \nCompleted M-Step. \nCompleting Iteration 54 (approx. per word bound = -6.879, relative change = 3.928e-05) \n....................................................................................................\nCompleted E-Step (13 seconds). \nCompleted M-Step. \nCompleting Iteration 55 (approx. per word bound = -6.879, relative change = 3.801e-05) \nTopic 1: use, say, word, translation, understand \n Topic 2: woman, man, old, year, young \n Topic 3: show, reality, edit, tv, also \n Topic 4: watch, us, love, version, lib \n Topic 5: want, mori, minami, say, dream \n Topic 6: wed, style, ring, wear, dress \n Topic 7: japan, physical, people, attraction, common \n Topic 8: make, much, pod, age, big \n Topic 9: tell, think, try, just, bad \n Topic 10: comment, gt, point, weird, bite \n Topic 11: love, hope, thank, ryotaro, motomi \n Topic 12: midori, wataru, friend, kaoru, great \n Topic 13: think, good, look, find, agree \n Topic 14: like, feel, seem, really, ayano \n Topic 15: girl, remember, voice, notice, forget \n Topic 16: say, go, just, know, want \n Topic 17: ask, hair, question, mention, answer \n Topic 18: talk, speak, english, sound, thing \n Topic 19: japanese, japan, culture, live, asian \n Topic 20: couple, lol, episode, together, one \n Topic 21: yes, mean, say, give, little \n Topic 22: get, marry, know, maybe, right \n Topic 23: priya, mizuki, business, lie, think \n Topic 24: people, time, see, take, just \n Topic 25: relationship, can, partner, will, work \n....................................................................................................\nCompleted E-Step (18 seconds). \nCompleted M-Step. \nCompleting Iteration 56 (approx. per word bound = -6.879, relative change = 3.092e-05) \n....................................................................................................\nCompleted E-Step (5 seconds). \nCompleted M-Step. \nCompleting Iteration 57 (approx. per word bound = -6.878, relative change = 2.789e-05) \n....................................................................................................\nCompleted E-Step (9 seconds). \nCompleted M-Step. \nCompleting Iteration 58 (approx. per word bound = -6.878, relative change = 2.460e-05) \n....................................................................................................\nCompleted E-Step (10 seconds). \nCompleted M-Step. \nCompleting Iteration 59 (approx. per word bound = -6.878, relative change = 2.197e-05) \n....................................................................................................\nCompleted E-Step (6 seconds). \nCompleted M-Step. \nCompleting Iteration 60 (approx. per word bound = -6.878, relative change = 2.242e-05) \nTopic 1: use, say, word, translation, understand \n Topic 2: woman, man, old, year, young \n Topic 3: show, reality, edit, tv, also \n Topic 4: watch, us, love, version, lib \n Topic 5: want, mori, minami, say, dream \n Topic 6: wed, style, ring, wear, dress \n Topic 7: japan, physical, people, attraction, common \n Topic 8: make, much, pod, age, big \n Topic 9: tell, think, try, just, bad \n Topic 10: comment, gt, point, weird, bite \n Topic 11: love, hope, thank, ryotaro, motomi \n Topic 12: midori, wataru, friend, great, kaoru \n Topic 13: think, good, look, find, agree \n Topic 14: like, feel, seem, really, ayano \n Topic 15: girl, remember, voice, notice, forget \n Topic 16: say, go, just, know, want \n Topic 17: ask, hair, question, mention, answer \n Topic 18: talk, speak, english, sound, make \n Topic 19: japanese, japan, culture, live, american \n Topic 20: couple, lol, together, episode, one \n Topic 21: yes, mean, give, sure, little \n Topic 22: get, marry, know, maybe, right \n Topic 23: priya, mizuki, business, lie, plan \n Topic 24: people, time, see, take, just \n Topic 25: relationship, can, partner, will, work \n....................................................................................................\nCompleted E-Step (6 seconds). \nCompleted M-Step. \nCompleting Iteration 61 (approx. per word bound = -6.878, relative change = 2.310e-05) \n....................................................................................................\nCompleted E-Step (5 seconds). \nCompleted M-Step. \nCompleting Iteration 62 (approx. per word bound = -6.878, relative change = 2.329e-05) \n....................................................................................................\nCompleted E-Step (4 seconds). \nCompleted M-Step. \nCompleting Iteration 63 (approx. per word bound = -6.877, relative change = 2.562e-05) \n....................................................................................................\nCompleted E-Step (4 seconds). \nCompleted M-Step. \nCompleting Iteration 64 (approx. per word bound = -6.877, relative change = 2.490e-05) \n....................................................................................................\nCompleted E-Step (4 seconds). \nCompleted M-Step. \nCompleting Iteration 65 (approx. per word bound = -6.877, relative change = 2.071e-05) \nTopic 1: use, say, word, understand, read \n Topic 2: woman, man, old, year, young \n Topic 3: show, reality, edit, tv, also \n Topic 4: watch, us, love, version, lib \n Topic 5: want, mori, minami, say, dream \n Topic 6: wed, style, ring, wear, dress \n Topic 7: japan, physical, people, attraction, common \n Topic 8: make, much, pod, big, age \n Topic 9: tell, think, try, bad, just \n Topic 10: comment, gt, point, weird, bite \n Topic 11: love, hope, thank, ryotaro, motomi \n Topic 12: midori, wataru, friend, great, kaoru \n Topic 13: think, good, look, find, agree \n Topic 14: like, feel, seem, really, ayano \n Topic 15: girl, remember, voice, notice, forget \n Topic 16: say, go, just, want, know \n Topic 17: ask, hair, question, mention, answer \n Topic 18: talk, speak, english, sound, make \n Topic 19: japanese, japan, culture, live, american \n Topic 20: couple, lol, together, episode, one \n Topic 21: yes, mean, sure, give, may \n Topic 22: get, know, marry, maybe, right \n Topic 23: priya, mizuki, business, lie, plan \n Topic 24: people, time, see, take, just \n Topic 25: relationship, can, partner, will, feeling \n....................................................................................................\nCompleted E-Step (4 seconds). \nCompleted M-Step. \nCompleting Iteration 66 (approx. per word bound = -6.877, relative change = 1.894e-05) \n....................................................................................................\nCompleted E-Step (4 seconds). \nCompleted M-Step. \nCompleting Iteration 67 (approx. per word bound = -6.877, relative change = 1.919e-05) \n....................................................................................................\nCompleted E-Step (4 seconds). \nCompleted M-Step. \nCompleting Iteration 68 (approx. per word bound = -6.877, relative change = 1.919e-05) \n....................................................................................................\nCompleted E-Step (5 seconds). \nCompleted M-Step. \nCompleting Iteration 69 (approx. per word bound = -6.877, relative change = 1.731e-05) \n....................................................................................................\nCompleted E-Step (4 seconds). \nCompleted M-Step. \nCompleting Iteration 70 (approx. per word bound = -6.876, relative change = 1.608e-05) \nTopic 1: use, say, word, understand, read \n Topic 2: woman, man, old, year, young \n Topic 3: show, reality, edit, tv, also \n Topic 4: watch, us, love, version, lib \n Topic 5: mori, want, minami, say, dream \n Topic 6: wed, style, ring, wear, dress \n Topic 7: japan, physical, attraction, people, common \n Topic 8: make, much, pod, big, age \n Topic 9: tell, think, try, bad, just \n Topic 10: comment, gt, point, weird, bite \n Topic 11: love, hope, thank, ryotaro, motomi \n Topic 12: midori, wataru, friend, great, kaoru \n Topic 13: think, good, look, find, agree \n Topic 14: like, feel, really, seem, ayano \n Topic 15: girl, remember, voice, notice, forget \n Topic 16: say, go, just, want, know \n Topic 17: ask, hair, question, mention, answer \n Topic 18: talk, speak, english, sound, make \n Topic 19: japanese, japan, culture, live, american \n Topic 20: couple, lol, together, episode, one \n Topic 21: yes, mean, sure, may, give \n Topic 22: get, know, marry, maybe, right \n Topic 23: priya, mizuki, business, lie, plan \n Topic 24: people, time, see, take, lot \n Topic 25: relationship, can, will, partner, feeling \n....................................................................................................\nCompleted E-Step (4 seconds). \nCompleted M-Step. \nCompleting Iteration 71 (approx. per word bound = -6.876, relative change = 1.704e-05) \n....................................................................................................\nCompleted E-Step (4 seconds). \nCompleted M-Step. \nCompleting Iteration 72 (approx. per word bound = -6.876, relative change = 1.729e-05) \n....................................................................................................\nCompleted E-Step (4 seconds). \nCompleted M-Step. \nCompleting Iteration 73 (approx. per word bound = -6.876, relative change = 1.586e-05) \n....................................................................................................\nCompleted E-Step (4 seconds). \nCompleted M-Step. \nCompleting Iteration 74 (approx. per word bound = -6.876, relative change = 1.436e-05) \n....................................................................................................\nCompleted E-Step (4 seconds). \nCompleted M-Step. \nCompleting Iteration 75 (approx. per word bound = -6.876, relative change = 1.447e-05) \nTopic 1: use, say, word, understand, read \n Topic 2: woman, man, old, year, young \n Topic 3: show, reality, edit, tv, also \n Topic 4: watch, us, love, version, lib \n Topic 5: mori, want, minami, say, dream \n Topic 6: wed, style, ring, wear, dress \n Topic 7: japan, physical, attraction, people, common \n Topic 8: make, much, pod, big, age \n Topic 9: tell, think, try, bad, just \n Topic 10: comment, gt, point, bite, weird \n Topic 11: love, hope, thank, ryotaro, motomi \n Topic 12: midori, wataru, friend, great, kaoru \n Topic 13: think, good, look, find, agree \n Topic 14: like, feel, really, seem, ayano \n Topic 15: girl, remember, voice, notice, forget \n Topic 16: say, go, just, want, know \n Topic 17: ask, hair, question, answer, mention \n Topic 18: talk, speak, english, sound, make \n Topic 19: japanese, japan, culture, live, american \n Topic 20: couple, lol, together, episode, one \n Topic 21: yes, mean, may, sure, give \n Topic 22: get, know, marry, maybe, right \n Topic 23: priya, mizuki, business, lie, plan \n Topic 24: people, time, see, take, lot \n Topic 25: relationship, can, will, partner, feeling \n....................................................................................................\nCompleted E-Step (4 seconds). \nCompleted M-Step. \nCompleting Iteration 76 (approx. per word bound = -6.876, relative change = 1.632e-05) \n....................................................................................................\nCompleted E-Step (4 seconds). \nCompleted M-Step. \nCompleting Iteration 77 (approx. per word bound = -6.876, relative change = 1.840e-05) \n....................................................................................................\nCompleted E-Step (4 seconds). \nCompleted M-Step. \nCompleting Iteration 78 (approx. per word bound = -6.876, relative change = 2.061e-05) \n....................................................................................................\nCompleted E-Step (4 seconds). \nCompleted M-Step. \nCompleting Iteration 79 (approx. per word bound = -6.875, relative change = 1.795e-05) \n....................................................................................................\nCompleted E-Step (4 seconds). \nCompleted M-Step. \nCompleting Iteration 80 (approx. per word bound = -6.875, relative change = 2.038e-05) \nTopic 1: use, say, word, understand, read \n Topic 2: woman, man, old, year, young \n Topic 3: show, reality, edit, tv, also \n Topic 4: watch, us, love, version, lib \n Topic 5: mori, want, minami, say, dream \n Topic 6: wed, style, ring, wear, dress \n Topic 7: japan, physical, attraction, people, common \n Topic 8: make, much, pod, big, age \n Topic 9: tell, think, bad, try, just \n Topic 10: comment, gt, point, bite, weird \n Topic 11: love, hope, thank, ryotaro, motomi \n Topic 12: midori, wataru, friend, great, kaoru \n Topic 13: think, good, look, find, guy \n Topic 14: like, feel, really, seem, ayano \n Topic 15: girl, remember, voice, notice, forget \n Topic 16: say, just, go, want, even \n Topic 17: ask, hair, question, answer, mention \n Topic 18: talk, speak, english, sound, make \n Topic 19: japanese, japan, culture, live, american \n Topic 20: couple, lol, together, episode, one \n Topic 21: yes, mean, may, sure, give \n Topic 22: get, know, marry, maybe, right \n Topic 23: priya, mizuki, business, lie, plan \n Topic 24: people, time, see, take, lot \n Topic 25: relationship, can, will, partner, feeling \n....................................................................................................\nCompleted E-Step (4 seconds). \nCompleted M-Step. \nCompleting Iteration 81 (approx. per word bound = -6.875, relative change = 2.230e-05) \n....................................................................................................\nCompleted E-Step (10 seconds). \nCompleted M-Step. \nCompleting Iteration 82 (approx. per word bound = -6.875, relative change = 2.111e-05) \n....................................................................................................\nCompleted E-Step (29 seconds). \nCompleted M-Step. \nCompleting Iteration 83 (approx. per word bound = -6.875, relative change = 2.280e-05) \n....................................................................................................\nCompleted E-Step (8 seconds). \nCompleted M-Step. \nCompleting Iteration 84 (approx. per word bound = -6.875, relative change = 2.405e-05) \n....................................................................................................\nCompleted E-Step (7 seconds). \nCompleted M-Step. \nCompleting Iteration 85 (approx. per word bound = -6.874, relative change = 2.405e-05) \nTopic 1: use, say, word, understand, read \n Topic 2: woman, man, old, year, young \n Topic 3: show, reality, edit, tv, also \n Topic 4: watch, us, love, version, lib \n Topic 5: mori, want, minami, say, dream \n Topic 6: wed, style, ring, wear, dress \n Topic 7: japan, physical, attraction, people, common \n Topic 8: make, much, pod, big, age \n Topic 9: tell, think, bad, try, just \n Topic 10: comment, gt, point, bite, weird \n Topic 11: love, hope, thank, ryotaro, motomi \n Topic 12: midori, wataru, friend, great, kaoru \n Topic 13: think, good, look, find, guy \n Topic 14: like, feel, really, seem, ayano \n Topic 15: girl, remember, voice, notice, forget \n Topic 16: say, just, go, want, even \n Topic 17: ask, hair, question, answer, mention \n Topic 18: talk, speak, english, sound, make \n Topic 19: japanese, japan, culture, live, american \n Topic 20: couple, together, lol, episode, one \n Topic 21: yes, may, mean, sure, give \n Topic 22: get, know, marry, maybe, right \n Topic 23: priya, mizuki, business, lie, plan \n Topic 24: people, time, see, take, lot \n Topic 25: relationship, can, will, partner, someone \n....................................................................................................\nCompleted E-Step (7 seconds). \nCompleted M-Step. \nCompleting Iteration 86 (approx. per word bound = -6.874, relative change = 2.284e-05) \n....................................................................................................\nCompleted E-Step (7 seconds). \nCompleted M-Step. \nCompleting Iteration 87 (approx. per word bound = -6.874, relative change = 2.163e-05) \n....................................................................................................\nCompleted E-Step (6 seconds). \nCompleted M-Step. \nCompleting Iteration 88 (approx. per word bound = -6.874, relative change = 2.014e-05) \n....................................................................................................\nCompleted E-Step (7 seconds). \nCompleted M-Step. \nCompleting Iteration 89 (approx. per word bound = -6.874, relative change = 2.097e-05) \n....................................................................................................\nCompleted E-Step (6 seconds). \nCompleted M-Step. \nCompleting Iteration 90 (approx. per word bound = -6.874, relative change = 1.991e-05) \nTopic 1: use, say, word, understand, read \n Topic 2: woman, man, old, year, young \n Topic 3: show, reality, edit, tv, also \n Topic 4: watch, us, love, version, lib \n Topic 5: mori, want, minami, say, dream \n Topic 6: wed, style, ring, wear, dress \n Topic 7: japan, physical, attraction, people, common \n Topic 8: make, much, pod, big, work \n Topic 9: tell, think, bad, try, need \n Topic 10: gt, comment, point, bite, weird \n Topic 11: love, hope, ryotaro, motomi, thank \n Topic 12: midori, wataru, friend, great, kaoru \n Topic 13: think, good, look, find, guy \n Topic 14: like, feel, really, seem, ayano \n Topic 15: girl, remember, voice, notice, forget \n Topic 16: say, just, go, want, even \n Topic 17: ask, hair, question, answer, mention \n Topic 18: talk, speak, english, sound, make \n Topic 19: japanese, japan, culture, live, american \n Topic 20: couple, together, lol, episode, one \n Topic 21: yes, may, mean, sure, give \n Topic 22: get, know, marry, maybe, right \n Topic 23: priya, mizuki, business, lie, plan \n Topic 24: people, time, see, take, lot \n Topic 25: relationship, can, will, partner, someone \n....................................................................................................\nCompleted E-Step (7 seconds). \nCompleted M-Step. \nCompleting Iteration 91 (approx. per word bound = -6.874, relative change = 2.133e-05) \n....................................................................................................\nCompleted E-Step (6 seconds). \nCompleted M-Step. \nCompleting Iteration 92 (approx. per word bound = -6.873, relative change = 2.237e-05) \n....................................................................................................\nCompleted E-Step (7 seconds). \nCompleted M-Step. \nCompleting Iteration 93 (approx. per word bound = -6.873, relative change = 2.511e-05) \n....................................................................................................\nCompleted E-Step (11 seconds). \nCompleted M-Step. \nCompleting Iteration 94 (approx. per word bound = -6.873, relative change = 3.206e-05) \n....................................................................................................\nCompleted E-Step (4 seconds). \nCompleted M-Step. \nCompleting Iteration 95 (approx. per word bound = -6.873, relative change = 3.355e-05) \nTopic 1: use, say, word, understand, read \n Topic 2: woman, man, old, year, young \n Topic 3: show, reality, edit, tv, also \n Topic 4: watch, us, love, version, lib \n Topic 5: mori, want, minami, say, dream \n Topic 6: wed, style, ring, wear, dress \n Topic 7: japan, physical, attraction, people, common \n Topic 8: make, much, pod, big, work \n Topic 9: tell, think, bad, try, need \n Topic 10: gt, comment, point, post, bite \n Topic 11: love, hope, ryotaro, motomi, thank \n Topic 12: midori, wataru, great, friend, kaoru \n Topic 13: think, good, look, find, guy \n Topic 14: like, feel, really, seem, ayano \n Topic 15: girl, remember, voice, notice, forget \n Topic 16: say, just, go, want, even \n Topic 17: ask, hair, question, answer, mention \n Topic 18: talk, speak, english, sound, make \n Topic 19: japanese, japan, culture, live, american \n Topic 20: couple, together, one, episode, lol \n Topic 21: yes, may, mean, sure, give \n Topic 22: get, know, marry, maybe, right \n Topic 23: priya, mizuki, business, lie, plan \n Topic 24: people, time, see, take, lot \n Topic 25: relationship, will, can, partner, someone \n....................................................................................................\nCompleted E-Step (4 seconds). \nCompleted M-Step. \nCompleting Iteration 96 (approx. per word bound = -6.873, relative change = 1.777e-05) \n....................................................................................................\nCompleted E-Step (4 seconds). \nCompleted M-Step. \nCompleting Iteration 97 (approx. per word bound = -6.873, relative change = 1.389e-05) \n....................................................................................................\nCompleted E-Step (4 seconds). \nCompleted M-Step. \nCompleting Iteration 98 (approx. per word bound = -6.873, relative change = 1.392e-05) \n....................................................................................................\nCompleted E-Step (5 seconds). \nCompleted M-Step. \nCompleting Iteration 99 (approx. per word bound = -6.872, relative change = 1.578e-05) \n....................................................................................................\nCompleted E-Step (6 seconds). \nCompleted M-Step. \nCompleting Iteration 100 (approx. per word bound = -6.872, relative change = 1.844e-05) \nTopic 1: use, say, word, understand, read \n Topic 2: woman, man, old, year, young \n Topic 3: show, reality, edit, tv, also \n Topic 4: watch, us, love, version, lib \n Topic 5: mori, want, minami, say, dream \n Topic 6: wed, style, ring, wear, dress \n Topic 7: japan, physical, attraction, people, common \n Topic 8: make, much, pod, big, work \n Topic 9: think, tell, bad, try, need \n Topic 10: gt, comment, post, point, weird \n Topic 11: love, hope, ryotaro, motomi, thank \n Topic 12: midori, wataru, great, friend, kaoru \n Topic 13: think, good, look, find, guy \n Topic 14: like, feel, really, seem, ayano \n Topic 15: girl, remember, voice, notice, forget \n Topic 16: say, just, go, want, even \n Topic 17: ask, hair, question, answer, mention \n Topic 18: talk, speak, english, sound, make \n Topic 19: japanese, japan, culture, live, american \n Topic 20: couple, together, one, episode, lol \n Topic 21: yes, may, mean, sure, give \n Topic 22: get, know, marry, maybe, still \n Topic 23: priya, mizuki, business, lie, plan \n Topic 24: people, time, see, take, lot \n Topic 25: relationship, will, can, partner, someone \n....................................................................................................\nCompleted E-Step (9 seconds). \nCompleted M-Step. \nCompleting Iteration 101 (approx. per word bound = -6.872, relative change = 1.959e-05) \n....................................................................................................\nCompleted E-Step (5 seconds). \nCompleted M-Step. \nCompleting Iteration 102 (approx. per word bound = -6.872, relative change = 2.200e-05) \n....................................................................................................\nCompleted E-Step (4 seconds). \nCompleted M-Step. \nCompleting Iteration 103 (approx. per word bound = -6.872, relative change = 2.013e-05) \n....................................................................................................\nCompleted E-Step (4 seconds). \nCompleted M-Step. \nCompleting Iteration 104 (approx. per word bound = -6.872, relative change = 1.682e-05) \n....................................................................................................\nCompleted E-Step (4 seconds). \nCompleted M-Step. \nCompleting Iteration 105 (approx. per word bound = -6.872, relative change = 1.440e-05) \nTopic 1: thank, use, say, word, understand \n Topic 2: woman, man, old, year, young \n Topic 3: show, reality, edit, tv, also \n Topic 4: watch, us, love, version, lib \n Topic 5: mori, want, minami, say, dream \n Topic 6: wed, style, ring, wear, dress \n Topic 7: japan, physical, attraction, people, common \n Topic 8: make, much, pod, big, work \n Topic 9: think, tell, bad, try, need \n Topic 10: gt, comment, post, point, weird \n Topic 11: love, hope, ryotaro, motomi, cute \n Topic 12: midori, wataru, great, friend, kaoru \n Topic 13: think, good, look, find, guy \n Topic 14: like, feel, really, seem, ayano \n Topic 15: girl, remember, voice, notice, forget \n Topic 16: say, just, go, want, even \n Topic 17: ask, hair, question, answer, mention \n Topic 18: talk, speak, english, sound, make \n Topic 19: japanese, japan, culture, live, american \n Topic 20: couple, one, together, episode, lol \n Topic 21: yes, may, mean, give, sure \n Topic 22: get, know, marry, maybe, still \n Topic 23: priya, mizuki, business, lie, plan \n Topic 24: people, time, see, take, lot \n Topic 25: relationship, will, can, partner, someone \n....................................................................................................\nCompleted E-Step (5 seconds). \nCompleted M-Step. \nCompleting Iteration 106 (approx. per word bound = -6.872, relative change = 1.328e-05) \n....................................................................................................\nCompleted E-Step (4 seconds). \nCompleted M-Step. \nCompleting Iteration 107 (approx. per word bound = -6.871, relative change = 1.176e-05) \n....................................................................................................\nCompleted E-Step (5 seconds). \nCompleted M-Step. \nCompleting Iteration 108 (approx. per word bound = -6.871, relative change = 1.083e-05) \n....................................................................................................\nCompleted E-Step (4 seconds). \nCompleted M-Step. \nCompleting Iteration 109 (approx. per word bound = -6.871, relative change = 1.046e-05) \n....................................................................................................\nCompleted E-Step (4 seconds). \nCompleted M-Step. \nCompleting Iteration 110 (approx. per word bound = -6.871, relative change = 1.207e-05) \nTopic 1: thank, use, say, word, understand \n Topic 2: woman, man, old, year, young \n Topic 3: show, reality, edit, tv, also \n Topic 4: watch, us, love, version, lib \n Topic 5: mori, want, minami, say, dream \n Topic 6: wed, style, ring, wear, dress \n Topic 7: japan, physical, attraction, people, common \n Topic 8: make, much, pod, big, work \n Topic 9: think, tell, bad, try, need \n Topic 10: gt, comment, post, point, weird \n Topic 11: love, hope, ryotaro, motomi, cute \n Topic 12: midori, wataru, great, friend, kaoru \n Topic 13: think, good, look, find, guy \n Topic 14: like, feel, really, seem, ayano \n Topic 15: girl, remember, voice, notice, forget \n Topic 16: say, just, go, want, even \n Topic 17: ask, hair, question, answer, mention \n Topic 18: talk, speak, english, sound, language \n Topic 19: japanese, japan, culture, live, american \n Topic 20: couple, one, together, episode, lol \n Topic 21: yes, may, mean, give, sure \n Topic 22: get, know, marry, maybe, still \n Topic 23: priya, mizuki, business, lie, plan \n Topic 24: people, time, see, take, lot \n Topic 25: relationship, will, can, partner, someone \n....................................................................................................\nCompleted E-Step (4 seconds). \nCompleted M-Step. \nCompleting Iteration 111 (approx. per word bound = -6.871, relative change = 1.898e-05) \n....................................................................................................\nCompleted E-Step (4 seconds). \nCompleted M-Step. \nCompleting Iteration 112 (approx. per word bound = -6.871, relative change = 1.651e-05) \n....................................................................................................\nCompleted E-Step (4 seconds). \nCompleted M-Step. \nModel Converged \n```\n:::\n\n```{.r .cell-code}\n#labelTopics(rModel)\nplot(rModel, type = \"summary\")\n```\n\n::: {.cell-output-display}\n![](BlogPost6_MollyHackbarth_files/figure-html/stm reddit-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# get the words\nrTopicNames <- labelTopics(rModel, n=4)$frex\n\n# set up an empty vector\nrTopicLabels <- rep(NA, k)\n\n# set up a loop to go through the topics and collapse the words to a single name\nfor (i in 1:k){\n  rTopicLabels[i] <- paste(rTopicNames[i,], collapse = \"_\")\n}\n\n# print the names\nrTopicLabels\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] \"translation_translate_subtitle_translator\"\n [2] \"man_woman_aska_old\"                       \n [3] \"tv_show_staff_reality\"                    \n [4] \"version_lib_season_brazil\"                \n [5] \"mori_minami_minami's_mori's\"              \n [6] \"ring_wear_ceremony_brand\"                 \n [7] \"private_intimacy_taboo_divorce\"           \n [8] \"nana_gap_vibe_proposal\"                   \n [9] \"nanako_self_bad_odacchi\"                  \n[10] \"delete_gt_photo_lt\"                       \n[11] \"adorable_blond_sweet_hope\"                \n[12] \"midori_wataru_misaki_lupin\"               \n[13] \"look_good_agree_find\"                     \n[14] \"ayano_shuntaro_feel_seem\"                 \n[15] \"insta_の_です_た\"                         \n[16] \"go_else_anything_whole\"                   \n[17] \"greasy_wet_answer_oil\"                    \n[18] \"sound_speak_speaker_english\"              \n[19] \"surgery_indian_asian_plastic\"             \n[20] \"couple_episode_wow_scene\"                 \n[21] \"yes_practice_may_sure\"                    \n[22] \"marry_get_totally_maybe\"                  \n[23] \"mizuki_lie_restaurant_owner\"              \n[24] \"screen_time_exactly_take\"                 \n[25] \"relationship_feeling_respect_able\"        \n```\n:::\n:::\n\n::: {.cell hash='BlogPost6_MollyHackbarth_cache/html/stm twitter_7454272fb3c04167ce55438963fc044a'}\n\n```{.r .cell-code}\nk <- 25\n### TWITTER\ntModel <- dfm(twitter_lemmitized)\n\ndocvars(twitter_lemmitized) <- tModel\n\ntModel$polarity <- tdf_nrc$polarity\n\ntModel <- stm(tModel,\n                K = k,\n              prevalence = ~ polarity + date,\n               max.em.its = 1000,\n               seed = 1234,\n               init.type = \"Spectral\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in dfm2stm(x, docvars, omit_empty = TRUE): Dropped empty document(s):\ntext2341, text3887, text3963, text4213, text4460, text4461, text4571, text4587,\ntext4608, text4621, text5803, text6822, text6833, text6835, text6842, text6862,\ntext6872, text6875, text6876, text6881, text7634\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nBeginning Spectral Initialization \n\t Calculating the gram matrix...\n\t Finding anchor words...\n \t.........................\n\t Recovering initialization...\n \t......................................................................................\nInitialization complete.\n....................................................................................................\nCompleted E-Step (5 seconds). \nCompleted M-Step. \nCompleting Iteration 1 (approx. per word bound = -7.363) \n....................................................................................................\nCompleted E-Step (3 seconds). \nCompleted M-Step. \nCompleting Iteration 2 (approx. per word bound = -7.070, relative change = 3.978e-02) \n....................................................................................................\nCompleted E-Step (3 seconds). \nCompleted M-Step. \nCompleting Iteration 3 (approx. per word bound = -6.940, relative change = 1.833e-02) \n....................................................................................................\nCompleted E-Step (4 seconds). \nCompleted M-Step. \nCompleting Iteration 4 (approx. per word bound = -6.885, relative change = 8.015e-03) \n....................................................................................................\nCompleted E-Step (3 seconds). \nCompleted M-Step. \nCompleting Iteration 5 (approx. per word bound = -6.852, relative change = 4.690e-03) \nTopic 1: watch, version, people, first, season \n Topic 2: just, know, want, already, season \n Topic 3: ryotaro, cry, motomi, pretty, look \n Topic 4: love, us, much, also, now \n Topic 5: like, feel, make, genuine, good \n Topic 6: couple, omg, heart, tv, first \n Topic 7: start, watch, beautiful, everything, good \n Topic 8: japan, brazil, wait, good, next \n Topic 9: guy, think, really, shuntaro, different \n Topic 10: wataru, end, like, ask, happy \n Topic 11: good, make, take, can, say \n Topic 12: finish, drama, japanese, feeling, people \n Topic 13: one, old, try, get, watch \n Topic 14: okay, pod, think, life, seem \n Topic 15: get, marry, say, gt, good \n Topic 16: see, cute, oh, odacchi, though \n Topic 17: episode, get, good, make, new \n Topic 18: sweet, need, still, midori, set \n Topic 19: japanese, watch, many, episode, sad \n Topic 20: watch, date, last, japan, kind \n Topic 21: tell, im, girl, together, yudai \n Topic 22: like, feel, priya, work, break \n Topic 23: way, watch, two, hear, hard \n Topic 24: man, woman, wholesome, really, say \n Topic 25: get, something, say, make, amp \n....................................................................................................\nCompleted E-Step (3 seconds). \nCompleted M-Step. \nCompleting Iteration 6 (approx. per word bound = -6.832, relative change = 3.036e-03) \n....................................................................................................\nCompleted E-Step (3 seconds). \nCompleted M-Step. \nCompleting Iteration 7 (approx. per word bound = -6.818, relative change = 2.018e-03) \n....................................................................................................\nCompleted E-Step (3 seconds). \nCompleted M-Step. \nCompleting Iteration 8 (approx. per word bound = -6.808, relative change = 1.457e-03) \n....................................................................................................\nCompleted E-Step (10 seconds). \nCompleted M-Step. \nCompleting Iteration 9 (approx. per word bound = -6.801, relative change = 1.063e-03) \n....................................................................................................\nCompleted E-Step (18 seconds). \nCompleted M-Step. \nCompleting Iteration 10 (approx. per word bound = -6.796, relative change = 7.563e-04) \nTopic 1: watch, version, season, people, first \n Topic 2: just, know, want, already, someone \n Topic 3: cry, ryotaro, motomi, pretty, damn \n Topic 4: love, us, now, much, also \n Topic 5: like, hair, genuine, hate, blonde \n Topic 6: couple, omg, heart, tv, every \n Topic 7: start, beautiful, everything, watch, else \n Topic 8: japan, brazil, wait, next, love \n Topic 9: think, guy, really, shuntaro, different \n Topic 10: end, wataru, happy, ask, look \n Topic 11: good, make, can, take, much \n Topic 12: finish, drama, people, nice, feeling \n Topic 13: one, old, try, fuck, dude \n Topic 14: pod, okay, life, lot, seem \n Topic 15: get, marry, gt, say, ever \n Topic 16: see, cute, odacchi, oh, nanako \n Topic 17: episode, get, new, time, late \n Topic 18: need, sweet, still, midori, set \n Topic 19: japanese, many, watch, episode, just \n Topic 20: date, show, last, reality, kind \n Topic 21: tell, im, together, girl, day \n Topic 22: like, feel, priya, work, really \n Topic 23: way, two, house, hear, watch \n Topic 24: man, woman, wholesome, say, really \n Topic 25: something, even, will, say, amp \n....................................................................................................\nCompleted E-Step (4 seconds). \nCompleted M-Step. \nCompleting Iteration 11 (approx. per word bound = -6.792, relative change = 5.151e-04) \n....................................................................................................\nCompleted E-Step (4 seconds). \nCompleted M-Step. \nCompleting Iteration 12 (approx. per word bound = -6.790, relative change = 3.679e-04) \n....................................................................................................\nCompleted E-Step (10 seconds). \nCompleted M-Step. \nCompleting Iteration 13 (approx. per word bound = -6.788, relative change = 2.685e-04) \n....................................................................................................\nCompleted E-Step (9 seconds). \nCompleted M-Step. \nCompleting Iteration 14 (approx. per word bound = -6.786, relative change = 2.050e-04) \n....................................................................................................\nCompleted E-Step (5 seconds). \nCompleted M-Step. \nCompleting Iteration 15 (approx. per word bound = -6.785, relative change = 1.676e-04) \nTopic 1: watch, version, season, first, people \n Topic 2: just, want, know, someone, already \n Topic 3: cry, ryotaro, motomi, pretty, damn \n Topic 4: love, us, now, much, also \n Topic 5: like, hair, genuine, hate, put \n Topic 6: couple, omg, every, heart, tv \n Topic 7: start, beautiful, everything, series, else \n Topic 8: japan, brazil, wait, next, love \n Topic 9: think, guy, really, different, shuntaro \n Topic 10: end, wataru, look, happy, ask \n Topic 11: good, make, can, take, much \n Topic 12: finish, drama, people, nice, feeling \n Topic 13: one, old, try, fuck, year \n Topic 14: pod, okay, life, lot, seem \n Topic 15: get, marry, gt, ever, literally \n Topic 16: see, cute, odacchi, nanako, oh \n Topic 17: episode, time, new, get, late \n Topic 18: need, sweet, still, meet, set \n Topic 19: japanese, many, watch, understand, mean \n Topic 20: date, show, reality, last, kind \n Topic 21: tell, together, girl, im, day \n Topic 22: like, feel, priya, work, really \n Topic 23: way, two, house, hear, hard \n Topic 24: man, woman, say, wholesome, really \n Topic 25: will, even, something, fall, actually \n....................................................................................................\nCompleted E-Step (3 seconds). \nCompleted M-Step. \nCompleting Iteration 16 (approx. per word bound = -6.784, relative change = 1.350e-04) \n....................................................................................................\nCompleted E-Step (3 seconds). \nCompleted M-Step. \nCompleting Iteration 17 (approx. per word bound = -6.784, relative change = 8.708e-05) \n....................................................................................................\nCompleted E-Step (4 seconds). \nCompleted M-Step. \nCompleting Iteration 18 (approx. per word bound = -6.783, relative change = 5.604e-05) \n....................................................................................................\nCompleted E-Step (11 seconds). \nCompleted M-Step. \nCompleting Iteration 19 (approx. per word bound = -6.783, relative change = 2.210e-05) \n....................................................................................................\nCompleted E-Step (9 seconds). \nCompleted M-Step. \nCompleting Iteration 20 (approx. per word bound = -6.783, relative change = 1.149e-05) \nTopic 1: watch, version, season, first, people \n Topic 2: just, want, know, someone, already \n Topic 3: cry, ryotaro, motomi, pretty, damn \n Topic 4: love, us, now, much, also \n Topic 5: like, hair, bad, genuine, hate \n Topic 6: couple, omg, every, heart, tv \n Topic 7: start, beautiful, everything, series, super \n Topic 8: japan, brazil, wait, love, next \n Topic 9: think, really, guy, different, shuntaro \n Topic 10: midori, end, wataru, look, happy \n Topic 11: good, make, can, take, go \n Topic 12: finish, drama, people, real, nice \n Topic 13: one, old, try, year, fuck \n Topic 14: pod, okay, lot, life, seem \n Topic 15: get, marry, gt, ever, literally \n Topic 16: see, cute, odacchi, nanako, oh \n Topic 17: episode, time, new, late, go \n Topic 18: need, meet, sweet, still, amp \n Topic 19: japanese, many, mean, understand, thing \n Topic 20: date, show, reality, last, kind \n Topic 21: tell, girl, together, im, gonna \n Topic 22: like, feel, priya, work, mori \n Topic 23: way, two, house, hear, never \n Topic 24: man, say, woman, wholesome, girl \n Topic 25: even, will, actually, something, fall \n....................................................................................................\nCompleted E-Step (11 seconds). \nCompleted M-Step. \nModel Converged \n```\n:::\n\n```{.r .cell-code}\nlabelTopics(tModel)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nTopic 1 Top Words:\n \t Highest Prob: watch, version, season, first, people, ep, please \n \t FREX: version, ep, season, first, watch, original, currently \n \t Lift: @blackberniebabe, @kercoby, @metraux_julia, @mrgordian, @ph1boyyy, @san_dogukan, @tuneflix1 \n \t Score: watch, version, season, first, people, ep, please \nTopic 2 Top Words:\n \t Highest Prob: just, want, know, someone, already, everyone, find \n \t FREX: know, want, already, someone, just, marriage, completely \n \t Lift: @jeeyonshim, @jiualn, @scootercasterny, @vitamin_ashley, #poetry, #selfcare, 24th \n \t Score: just, want, know, already, someone, marriage, find \nTopic 3 Top Words:\n \t Highest Prob: cry, ryotaro, motomi, pretty, damn, motomi's, parent \n \t FREX: motomi, ryotaro, cry, adorable, motomi's, ryotaro's, pretty \n \t Lift: 🙋🏻‍♀, @blike_dante, @brittanys, @catcohen, @chrissy__dee, @evankail, @jordanoloman \n \t Score: ryotaro, motomi, cry, pretty, motomi's, parent, damn \nTopic 4 Top Words:\n \t Highest Prob: love, us, now, much, also, lol, netflix \n \t FREX: us, lol, also, far, love, netflix, now \n \t Lift: @adarkknightt, @tygasjaw69, dramaaa, @emilyamick, @kari_paul, graduate, hashtags \n \t Score: love, us, much, now, also, netflix, lol \nTopic 5 Top Words:\n \t Highest Prob: like, hair, bad, genuine, hate, put, blonde \n \t FREX: blonde, hair, hurt, dye, genuine, highly, put \n \t Lift: @brightlyagain, @chelseacirruzzo, @dammy_eneli, @farrahfox_13, @joshinji, @mommycrat, @mrjerryoc \n \t Score: hair, like, genuine, bad, dye, blonde, hate \nTopic 6 Top Words:\n \t Highest Prob: couple, omg, every, heart, tv, root, tear \n \t FREX: omg, couple, heart, emotional, favorite, tear, 1x4 \n \t Lift: @dolamited, @doseofdiana__, @guru_stu, @heyyy_riri, @katethornley3, @oloni, @solohmx514 \n \t Score: couple, omg, every, heart, tv, root, tear \nTopic 7 Top Words:\n \t Highest Prob: start, beautiful, everything, series, super, else, week \n \t FREX: start, everything, else, movie, bowl, week, beautiful \n \t Lift: 🙏🏻, sia, warp, @alyricalsoul, @amxkiry, @andysignore, @bbteamnorth \n \t Score: start, beautiful, everything, week, else, super, family \nTopic 8 Top Words:\n \t Highest Prob: japan, brazil, wait, love, next, s2, listen \n \t FREX: brazil, lib, tomorrow, s2, game, wait, japan \n \t Lift: tn, eastern, hollister, iraq, politic, price, russian \n \t Score: japan, brazil, wait, next, love, s2, listen \nTopic 9 Top Words:\n \t Highest Prob: think, really, guy, different, shuntaro, ayano, whole \n \t FREX: shuntaro, guy, ayano, usa, minute, kenya, culture \n \t Lift: @bombedefleurs, @justingrayesq, @litto_fish, @ssshlyn, @uhnelly, #hissuitfitwasfirethou, 56y \n \t Score: guy, think, really, shuntaro, ayano, different, culture \nTopic 10 Top Words:\n \t Highest Prob: midori, end, wataru, look, happy, ask, great \n \t FREX: sorry, wataru, end, ask, question, check, happy \n \t Lift: @cherry_coloured, @criterion, @evabennett3, @inaribriana, @jessica19197346, @kathymcrae9, @kismytiara \n \t Score: wataru, end, midori, happy, ask, look, great \nTopic 11 Top Words:\n \t Highest Prob: good, make, can, take, go, much, hope \n \t FREX: take, connection, good, make, appreciate, sooo, can \n \t Lift: @ceoofmisaka, @danielleweisber, @eclecticmuses, @jorjorfrmdablk, @juleshortstuff, @mistressleora, @severlyawsome \n \t Score: good, make, take, can, much, hope, work \nTopic 12 Top Words:\n \t Highest Prob: finish, people, drama, real, nice, feeling, definitely \n \t FREX: finish, definitely, cameron, lauren, 👏🏾, favourite, switch \n \t Lift: -1, @autist333, @clvtno, @hewobear, @hey_tyraashleyy, @hierohero1, @jackiew01461728 \n \t Score: finish, drama, feeling, nice, definitely, people, country \nTopic 13 Top Words:\n \t Highest Prob: one, old, try, year, fuck, dude, english \n \t FREX: one, dude, misaki, hell, old, plan, kaoru \n \t Lift: @lisacrosbie, @meganvwalker, @nategearysports, @yaeltygiel, #2, #dothatatthewedding, #gg \n \t Score: one, old, try, year, dude, fuck, english \nTopic 14 Top Words:\n \t Highest Prob: pod, okay, lot, life, seem, think, mizuki \n \t FREX: okay, pod, lie, life, reveal, future, business \n \t Lift: -ryotaro's, @ayoolaaa, @bleunormann, @carmenbelcher_, @erinbrownwrites, @goldcaro, @loveashbelle \n \t Score: okay, pod, life, lot, lie, seem, mizuki \nTopic 15 Top Words:\n \t Highest Prob: get, marry, gt, ever, literally, age, thing \n \t FREX: gt, age, mom, marry, ever, tattoo, literally \n \t Lift: bengali, -adults, -continuing, -people, -secrets, @bdentrek, @charnecolleen \n \t Score: get, marry, gt, age, ever, literally, mom \nTopic 16 Top Words:\n \t Highest Prob: see, cute, odacchi, nanako, oh, though, shit \n \t FREX: nanako, cute, lmao, see, oh, though, letter \n \t Lift: @alexsheppard, @carameru_dani, @dianeeguerrero, @juicebinn, @katandcats17, @localpinkgurl, @malignedgod \n \t Score: see, cute, nanako, oh, odacchi, though, shit \nTopic 17 Top Words:\n \t Highest Prob: episode, time, new, late, go, proposal, believe \n \t FREX: final, personality, drop, late, job, proposal, release \n \t Lift: gunma, @baseballkenya1, @helgemsanchez, @itsamandared, @mattt7000, @netflixke, @pstinny \n \t Score: episode, new, time, drop, late, release, personality \nTopic 18 Top Words:\n \t Highest Prob: need, meet, sweet, amp, still, set, maybe \n \t FREX: bridge, design, sweet, room, cool, amaze, set \n \t Lift: captain, max, @ajenglish, @axel_hexed, @davechensky, @gretchemaben, @grxylie \n \t Score: need, sweet, set, meet, still, bridge, amp \nTopic 19 Top Words:\n \t Highest Prob: japanese, many, mean, understand, thing, sad, just \n \t FREX: #tvtime, s01, many, sad, u, understand, other \n \t Lift: e02, e03, e04, e05, e09, @_benjvmins_, @drmnewcomb \n \t Score: japanese, s01, #tvtime, many, sad, understand, u \nTopic 20 Top Words:\n \t Highest Prob: date, show, reality, last, kind, romantic, edition \n \t FREX: inferno, kind, participant, reality, romantic, single's, mother \n \t Lift: @___kennnyyy, @_alemiye, @agustdmentality, @allisonkfarrell, @androidauth, @arrowfilmsvideo, @callingu_home \n \t Score: date, show, reality, last, kind, romantic, inferno \nTopic 21 Top Words:\n \t Highest Prob: tell, girl, together, im, gonna, day, give \n \t FREX: yudai, im, tell, wed, nana, idk, rn \n \t Lift: drain, sofa, @0xtracy, @camiinthisthang, @issprice, @meredithb104, @miladymaker \n \t Score: im, tell, yudai, girl, together, wed, gonna \nTopic 22 Top Words:\n \t Highest Prob: like, feel, priya, mori, work, break, anyone \n \t FREX: break, priya, anyone, genuinely, feel, toxic, none \n \t Lift: @mnateshyamalan, @phynaz, @xandraellin, #loves, #moneytalks, #moneytwitter, arrive \n \t Score: like, feel, priya, break, work, mori, anyone \nTopic 23 Top Words:\n \t Highest Prob: way, two, house, hear, never, speak, hard \n \t FREX: terrace, hear, house, hard, way, journey, thoughtful \n \t Lift: @aitrife, @bruuvv, @exoticrozayred, @itswalela, @jeon_bts321, @katskratchh, @moonlitballad \n \t Score: way, house, hear, terrace, two, hard, america \nTopic 24 Top Words:\n \t Highest Prob: man, say, woman, wholesome, girl, choose, kitchen \n \t FREX: kitchen, wholesome, woman, man, ugly, woman's, belong \n \t Lift: @abroadinjapan, @dinamarei_, @sequoian, #anime, #flykah, #mafs, #misowitheverything \n \t Score: man, woman, wholesome, say, kitchen, ugly, woman's \nTopic 25 Top Words:\n \t Highest Prob: even, will, actually, something, talk, fall, wow \n \t FREX: something, will, even, fall, wow, another, actually \n \t Lift: @quisteen, lesgoooo, yayyyy, givinggggggggg, @thedudeapproves, @madeline_gobbo, @needlesonnews \n \t Score: even, will, something, actually, wow, fall, talk \n```\n:::\n\n```{.r .cell-code}\nplot(tModel, type = \"summary\")\n```\n\n::: {.cell-output-display}\n![](BlogPost6_MollyHackbarth_files/figure-html/stm twitter-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# get the words\ntTopicNames <- labelTopics(tModel, n=4)$frex\n\n# set up an empty vector\ntTopicLabels <- rep(NA, k)\n\n# set up a loop to go through the topics and collapse the words to a single name\nfor (i in 1:k){\n  tTopicLabels[i] <- paste(tTopicNames[i,], collapse = \"_\")\n}\n\n# print the names\ntTopicLabels\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] \"version_ep_season_first\"          \"know_want_already_someone\"       \n [3] \"motomi_ryotaro_cry_adorable\"      \"us_lol_also_far\"                 \n [5] \"blonde_hair_hurt_dye\"             \"omg_couple_heart_emotional\"      \n [7] \"start_everything_else_movie\"      \"brazil_lib_tomorrow_s2\"          \n [9] \"shuntaro_guy_ayano_usa\"           \"sorry_wataru_end_ask\"            \n[11] \"take_connection_good_make\"        \"finish_definitely_cameron_lauren\"\n[13] \"one_dude_misaki_hell\"             \"okay_pod_lie_life\"               \n[15] \"gt_age_mom_marry\"                 \"nanako_cute_lmao_see\"            \n[17] \"final_personality_drop_late\"      \"bridge_design_sweet_room\"        \n[19] \"#tvtime_s01_many_sad\"             \"inferno_kind_participant_reality\"\n[21] \"yudai_im_tell_wed\"                \"break_priya_anyone_genuinely\"    \n[23] \"terrace_hear_house_hard\"          \"kitchen_wholesome_woman_man\"     \n[25] \"something_will_even_fall\"        \n```\n:::\n:::\n\n\nHere I was able to see that even with two factors (polarity and dates) it seems that the topics stayed fairly similar.\n\n# Final Thoughts (TLDR)\n\n-   Throughout my various blog post I feel like I was able to craft multiple graphs that I want to use in my Final Project.\n\n-   It took a lot longer to figure out how to do sentiment by dates but it feels well worth it!\n\n-   I think looking back it might have been a better idea to combine the Twitter and Reddit data together and done an analysis on that. This may have caused less trouble in rendering the blog and let me explore a bit more in depth.\n\n\n::: {.cell hash='BlogPost6_MollyHackbarth_cache/html/save image_4cae125cea5834d9e7073b27a3c648ef'}\n\n```{.r .cell-code}\nsave.image(file = \"blogpost6.RData\")\n```\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}