{
  "hash": "4ce87d6628b9aa6300d80c5a8b3430cf",
  "result": {
    "markdown": "---\ntitle: \"Blog Post 3\"\nauthor: \"Mantek Singh Bhatia\"\ndesription: \"First Blog Post - Literature Review\"\ndate: \"10/25/2022\"\nformat:\n  html:\n    toc: true\n    code-fold: true\n    code-copy: true\n    code-tools: true\ncategories:\n  - Blog Post 3\n  - Mantek Singh Bhatia\n  - Self-Identity\n  - Online Gaming\n  - Avatars\n  - Characterization\n---\n\n\n\n## Research Objective\n\nMy research objective for this project is to understand how people characterize their avatars in games.  \n\n:::{.callout-important}\nHere I use the term Research Objective because I do not have a specific Research Question in mind right now. This project is merely exploratory for me. It may develop closer to the end of the project.\n:::\n\n\nCreating avatars in games gives people the freedom to be creative and cultivate an alternate identity. Now, this identity can be their \"ideal self\" or something that they just create for fun. To understand this process of creating identities I want to first examine the avatars people have already made. For this context I am thinking of scouring Reddit to find threads that talk about people describing the avatars/characters they have created while playing \"Dungeons and Dragons\". \n\n&nbsp;  \n&nbsp;  \n&nbsp;  \n\n## Data Collection  \n\nI was able to scrap data from multiple Reddit threads where users talk about their characters that they have created while playing a Dungeons and Dragons campaign.  \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# install.packages(\"rvest\")\n# install.packages(\"RedditExtractoR\")\n# install.packages(\"textclean\")\nlibrary(RedditExtractoR)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'RedditExtractoR' was built under R version 4.2.2\n```\n:::\n\n```{.r .cell-code}\nlibrary(rvest)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'rvest' was built under R version 4.2.2\n```\n:::\n\n```{.r .cell-code}\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.3.6      ✔ purrr   0.3.5 \n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.2.1      ✔ stringr 1.4.1 \n✔ readr   2.1.3      ✔ forcats 0.5.2 \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter()         masks stats::filter()\n✖ readr::guess_encoding() masks rvest::guess_encoding()\n✖ dplyr::lag()            masks stats::lag()\n```\n:::\n\n```{.r .cell-code}\nlibrary(quanteda)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nPackage version: 3.2.3\nUnicode version: 13.0\nICU version: 69.1\nParallel computing: 8 of 8 threads used.\nSee https://quanteda.io for tutorials and examples.\n```\n:::\n\n```{.r .cell-code}\nlibrary(quanteda.textplots)\nlibrary(textclean)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'textclean' was built under R version 4.2.2\n```\n:::\n\n```{.r .cell-code}\nurl <- c(\"https://www.reddit.com/r/DnD/comments/b1pk5c/tell_me_about_your_characters/\", \n         \"https://www.reddit.com/r/DnD/comments/33bv4f/best_dd_character_youve_made_or_seen/\",\n         \"https://www.reddit.com/r/DnD/comments/37cx49/your_first_ever_dd_character/\",\n         \"https://www.reddit.com/r/rpg/comments/2fk4op/best_dd_character_youve_ever_made/\",\n         \"https://www.reddit.com/r/DnD/comments/cgdwgl/share_your_dnd_character/\",\n         \"https://www.reddit.com/r/dndnext/comments/au8k0w/what_are_some_of_your_favourite_dd_character/\")\n\n\n\n# comments <- get_thread_content(url)\n# save.image(\"mantek_blogpost3.RData\")\nload(\"mantek_blogpost3.RData\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in readChar(con, 5L, useBytes = TRUE): cannot open compressed file\n'mantek_blogpost3.RData', probable reason 'No such file or directory'\n```\n:::\n\n::: {.cell-output .cell-output-error}\n```\nError in readChar(con, 5L, useBytes = TRUE): cannot open the connection\n```\n:::\n\n```{.r .cell-code}\n#preprocessing\nall_comments <- \n  comments$comments$comment %>% \n  str_replace_all(\"\\n\",\" \")           #data cleaning\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in stri_replace_all_regex(string, pattern, fix_replacement(replacement), : object 'comments' not found\n```\n:::\n\n```{.r .cell-code}\nall_comments <- replace_contraction(all_comments)     #opened all contractions, like didn't to did not\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in is.factor(x): object 'all_comments' not found\n```\n:::\n\n```{.r .cell-code}\ntail(all_comments, n = 10)    #Some of the comments\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in tail(all_comments, n = 10): object 'all_comments' not found\n```\n:::\n\n```{.r .cell-code}\nreddit_DnD_characters <- corpus(all_comments)\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in corpus(all_comments): object 'all_comments' not found\n```\n:::\n\n```{.r .cell-code}\nDnD_summary <- summary(reddit_DnD_characters, n = Inf)\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in summary(reddit_DnD_characters, n = Inf): object 'reddit_DnD_characters' not found\n```\n:::\n\n```{.r .cell-code}\nDnD_summary             #SUmmary of the corpus\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in eval(expr, envir, enclos): object 'DnD_summary' not found\n```\n:::\n\n```{.r .cell-code}\nDnD_tokens <- tokens(reddit_DnD_characters); DnD_tokens       #tokens before preprosessing\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in tokens(reddit_DnD_characters): object 'reddit_DnD_characters' not found\n```\n:::\n\n::: {.cell-output .cell-output-error}\n```\nError in eval(expr, envir, enclos): object 'DnD_tokens' not found\n```\n:::\n\n```{.r .cell-code}\n#Removed Punctuation\n#Removed symbols\n#Removed Numbers\n#Removed Stopwords\n\nDnD_tokens <- tokens(reddit_DnD_characters, remove_punct=TRUE, remove_symbols = TRUE,\n                     remove_numbers = TRUE) %>%\n  tokens_select(pattern=stopwords(\"en\"), selection=\"remove\"); DnD_tokens\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in tokens(reddit_DnD_characters, remove_punct = TRUE, remove_symbols = TRUE, : object 'reddit_DnD_characters' not found\n```\n:::\n\n::: {.cell-output .cell-output-error}\n```\nError in eval(expr, envir, enclos): object 'DnD_tokens' not found\n```\n:::\n\n```{.r .cell-code}\nDnD_dfm <- DnD_tokens %>% \n  dfm() %>%\n  dfm_trim(min_termfreq = 20, verbose = FALSE)\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in dfm(.): object 'DnD_tokens' not found\n```\n:::\n\n```{.r .cell-code}\nDnD_dfm         #The DFM\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in eval(expr, envir, enclos): object 'DnD_dfm' not found\n```\n:::\n\n```{.r .cell-code}\nall_features <- featnames(DnD_dfm); all_features\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in featnames(DnD_dfm): object 'DnD_dfm' not found\n```\n:::\n\n::: {.cell-output .cell-output-error}\n```\nError in eval(expr, envir, enclos): object 'all_features' not found\n```\n:::\n\n```{.r .cell-code}\ntopfeatures(DnD_dfm, 100)\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in topfeatures(DnD_dfm, 100): object 'DnD_dfm' not found\n```\n:::\n\n```{.r .cell-code}\ntextplot_wordcloud(DnD_dfm)      #Word Cloud of the existing tokens\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in textplot_wordcloud(DnD_dfm): object 'DnD_dfm' not found\n```\n:::\n\n```{.r .cell-code}\n#creating a Network plot\nDnD_fcm = fcm(DnD_dfm)\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in fcm(DnD_dfm): object 'DnD_dfm' not found\n```\n:::\n\n```{.r .cell-code}\n# pull the top features\nmyFeatures = names(topfeatures(DnD_fcm, 30))\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in topfeatures(DnD_fcm, 30): object 'DnD_fcm' not found\n```\n:::\n\n```{.r .cell-code}\n# retain only those top features as part of our matrix\nSmaller_fsm = fcm_select(DnD_fcm, pattern = myFeatures, selection = \"keep\")\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in fcm_select(DnD_fcm, pattern = myFeatures, selection = \"keep\"): object 'DnD_fcm' not found\n```\n:::\n\n```{.r .cell-code}\n# compute size weight for vertices in network\nsize = log(colSums(Smaller_fsm))\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in h(simpleError(msg, call)): error in evaluating the argument 'x' in selecting a method for function 'colSums': object 'Smaller_fsm' not found\n```\n:::\n\n```{.r .cell-code}\n# create plot\ntextplot_network(Smaller_fsm, vertex_size = size / max(size) * 3)\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in textplot_network(Smaller_fsm, vertex_size = size/max(size) * : object 'Smaller_fsm' not found\n```\n:::\n\n```{.r .cell-code}\n#kwic_time <- kwic(reddit_DnD_characters, pattern = phrase(\"time\")); head(kwic_time, n=10)\n\n#kwic_character <- kwic(reddit_DnD_characters, pattern = phrase(\"character\")); head(kwic_character, n=10)\n\n#kwic_party <- kwic(reddit_DnD_characters, pattern = phrase(\"party\")); head(kwic_party, n=10)\n```\n:::\n\n\nThis is a preview of what the data is like in the Reddit threads. Right now there are a lot of frequent words as features which do not give us a lot of information, however, there are a few features that talk about the type/class of characters players usually choose which can give us a lot of insights.  \n\n\n&nbsp;  \n&nbsp;  \n&nbsp;  \n\n## Next Steps  \n\n-   Find more threads to scrap more comments.  \n-   Clean/Preprocess the features obtained to extract more nuanced information from the threads.  \n-   Think about what other methods introduced in the Text-as-Data class can be applied to the data to find meaningful observations from the data.  \n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}