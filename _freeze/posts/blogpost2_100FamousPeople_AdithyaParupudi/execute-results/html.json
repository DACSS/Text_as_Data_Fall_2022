{
  "hash": "284ec6261b4a2ae85e15edbe86b22935",
  "result": {
    "markdown": "---\ntitle: \"Blog Post 2 - 100+ Famous People\"\nauthor: \"Adithya Parupudi\"\ndesription: \"Scraped biographies of 100+ famous people to perform text analysis\"\ndate: \"22/10/2022\"\nformat:\n  html:\n    toc: true\n    code-fold: true\n    code-copy: true\n    code-tools: true\ncategories:\n  - Adithya Parupudi\n  - blogpost2\n---\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-error}\n```\nError: package or namespace load failed for 'tidyverse' in loadNamespace(i, c(lib.loc, .libPaths()), versionCheck = vI[[i]]):\n namespace 'rlang' 1.0.4 is already loaded, but >= 1.0.6 is required\n```\n:::\n\n```{.r .cell-code}\nlibrary(rvest)\n```\n\n::: {.cell-output .cell-output-error}\n```\nError: package or namespace load failed for 'rvest' in loadNamespace(i, c(lib.loc, .libPaths()), versionCheck = vI[[i]]):\n namespace 'rlang' 1.0.4 is already loaded, but >= 1.0.6 is required\n```\n:::\n\n```{.r .cell-code}\nlibrary(stringr)\n```\n:::\n\n\nUsing the website \\<\\> to scrape daat of 126 famous people from all over the world. This website has the detailed information about their early life, academic achievements, and the impact created by them.\n\nI wanted to find out :\n\n1.  What is the most common profession? Which areas of work do most of them fall into?\n2.  Where are they from? Whats their education background?\n3.  Whats their cause of death?\n4.  Which time period did most of them existed?\n5.  Emotion behind their famous quotes\n\nReading the content of landing page, which has urls of all the famous people.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nall = read_html(\"https://www.biographyonline.net/people/famous-100.html\")\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in read_html(\"https://www.biographyonline.net/people/famous-100.html\"): could not find function \"read_html\"\n```\n:::\n:::\n\n\nI've created three variables to capture the celebrity names, individual page urls and their content. Each page contains various excerpts from their life such as \"Early Life\", \"Notable Achievements\", \"Famous Quotes\" and so on. I further created a dataset with each variable name as its column, to structure the data for further text processing, which is yet to be done.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npeople_names <- all %>% html_nodes(\"ol a\") %>% html_text()\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in html_text(.): could not find function \"html_text\"\n```\n:::\n\n```{.r .cell-code}\n# people_names\n\n#getting all the links\n\nlinks <- all %>% html_nodes(\"ol a\") %>% \n  html_attr(\"href\") %>% \n  str_replace(.,\"/women/ingrid-bergman.html\", \"../women/ingrid-bergman.html\") %>% \n  str_replace(.,\"https://www.biographyonline.net/\", \"../\") %>% \n  str_replace(.,\"../\", \"https://www.biographyonline.net/\")\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in html_attr(., \"href\"): could not find function \"html_attr\"\n```\n:::\n\n```{.r .cell-code}\nget_content = function(link){\n  data = read_html(link)\n  # data = read_html(\"https://www.biographyonline.net/nobelprize/economics/paul-krugman.html\")\n  content = data %>% html_nodes('.clearfix') %>% html_text() %>% paste(collapse = \"!!!\")\n  return(content)\n    \n}\n\ncontent = sapply(links, FUN = get_content, USE.NAMES = FALSE) \n```\n\n::: {.cell-output .cell-output-error}\n```\nError in lapply(X = X, FUN = FUN, ...): object 'links' not found\n```\n:::\n\n```{.r .cell-code}\ndataset = data.frame(people_names, links, content, stringsAsFactors = FALSE)\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in data.frame(people_names, links, content, stringsAsFactors = FALSE): object 'people_names' not found\n```\n:::\n:::\n\n\nArranging the data in alphabetical order.\n\n\n::: {.cell}\n\n```{.r .cell-code}\narrange(dataset, people_names)\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in arrange(dataset, people_names): could not find function \"arrange\"\n```\n:::\n:::\n\n\nNow that I've collected the dataset, I have to perform text pre-processing by removing some urls that came with scraped content. Also split the content into multiple rows for better readability and context clarity.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}