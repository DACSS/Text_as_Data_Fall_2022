{
  "hash": "bf2bb7f15075c9783bfda43bd2d3605a",
  "result": {
    "markdown": "---\ntitle: \"Tidying Tweets\"\nauthor: \"Kirsten Johnson\"\ndesription: \"Blog Post 2: Tidying Tweets\"\ndate: \"11/15/2022\"\nformat:\n  html:\n    toc: true\n    code-fold: true\n    code-copy: true\n    code-tools: true\ncategories:\n  - Blog post 2 \n  - Twitter\n  - Traffic Safety\n  - Sentiment Analysis\n---\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n\nknitr::opts_chunk$set(echo = TRUE)\n```\n:::\n\n\n### Using the Twitter API\n\nFor my final project, I plan on conducting an analysis of tweets mentioning MassDOT, as I work on social media for the agency as part of my job. With the MBTA GM stepping down in early November and the agency under scrutiny over the past few weeks due to public dissatisfaction with the public transit system in Massachusetts, I'm interested if a negative sentiment can be identified towards MassDOT. Though MBTA and MassDOT are two different agencies, they work in tandem and the work of both are often conflated with each other by the public.\n\nI decided to look at tweets in particular since MassDOT's primary social media precense is on Twitter. Using the Twitter API took much trial and error. After some time I was able to gathered tweets from the past 7 days that mention MassDOT on Twitter using the twarc2 package in Python. The goal is to capture the public's attitude towards the agency and traffic safety culture. I plan to gather 30 days of tweets over the next few weeks, but I will start tidying the data I have collected thus far. These tweets have been saved to a CSV file.\n\n### Tidy Tweets\n\nThe Twitter API limits searching for tweets up to seven days old. Assuming Twitter still exists (thanks Elon), I'll be gathering tweets using the API over the next few weeks in hopes to compile at least a month of data.\n\n## The tweets I've gathered thus far are for November 8th-15th, 2022. I'll start by creating a corpus with these tweets. Let's start by loading the necessary packages.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npackages <- c(\"cleanNLP\", \"devtools\", \"tidytext\", \"plyr\", \"tidyverse\", \"quanteda\")\n\ninstall.packages(setdiff(packages, rownames(installed.packages())))  \n\n\n# load libraries\nlibrary(cleanNLP)\nlibrary(tidytext)\nlibrary(tidyverse)\nlibrary(quanteda)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nPackage version: 3.2.3\nUnicode version: 13.0\nICU version: 69.1\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nParallel computing: 8 of 8 threads used.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nSee https://quanteda.io for tutorials and examples.\n```\n:::\n\n```{.r .cell-code}\nlibrary(plyr)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n------------------------------------------------------------------------------\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nYou have loaded plyr after dplyr - this is likely to cause problems.\nIf you need functions from both plyr and dplyr, please load plyr first, then dplyr:\nlibrary(plyr); library(dplyr)\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n------------------------------------------------------------------------------\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'plyr'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following objects are masked from 'package:dplyr':\n\n    arrange, count, desc, failwith, id, mutate, rename, summarise,\n    summarize\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:purrr':\n\n    compact\n```\n:::\n\n```{.r .cell-code}\nlibrary(dplyr)\nlibrary(devtools)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: usethis\n```\n:::\n\n```{.r .cell-code}\nlibrary(tidyverse)\n```\n:::\n\n\nNow I'll import the csv of tweets and preview the first 20 rows of data and summarize the data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Import csv of tweets containing the text \"MassDOT\nmassdot_tweets <- read.csv(\"../MassDOTtweets.csv\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in file(file, \"rt\"): cannot open file '../MassDOTtweets.csv': No such\nfile or directory\n```\n:::\n\n::: {.cell-output .cell-output-error}\n```\nError in file(file, \"rt\"): cannot open the connection\n```\n:::\n\n```{.r .cell-code}\nmassdot_tweets <- as_tibble(massdot_tweets)\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in as_tibble(massdot_tweets): object 'massdot_tweets' not found\n```\n:::\n\n```{.r .cell-code}\n# Preview first 20 rows\nhead(massdot_tweets, 20)\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in head(massdot_tweets, 20): object 'massdot_tweets' not found\n```\n:::\n\n```{.r .cell-code}\n# Summarize data\nsummary(massdot_tweets)\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in summary(massdot_tweets): object 'massdot_tweets' not found\n```\n:::\n:::\n\n\nOver the 7-day time period, 533 tweets mention MassDOT. The tweets data contains 78 columns, many of which are of no interest to me. While I may change my mind in the future, I am only interested in the tweet text, the tweet date, and the username that the tweet came from. I also don't want to include tweets that are from the @MassDOT or @MassDOTSafety handles, as I am only interested in tweets coming from outside of the agency. I'll filter those out.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Subset data to only include relevant fields\n#Filter out tweets from @MassDOT or @MassDOTSafety\nlibrary(dplyr)\nmassdot_tweets<- massdot_tweets %>% \n  select(author.username, created_at, text)%>%\n  filter(author.username != \"MassDOT\")%>%\n  filter(author.username != \"MassDOTSafety\")\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in select(., author.username, created_at, text): object 'massdot_tweets' not found\n```\n:::\n\n```{.r .cell-code}\nsummary(massdot_tweets)\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in summary(massdot_tweets): object 'massdot_tweets' not found\n```\n:::\n:::\n\n\nAfter filtering out tweets from MassDOT, I'm left with 500 tweets. Now I'll create a corpus.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create corpus of tweets\nmassdot_tweets_corpus <-corpus(massdot_tweets)\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in corpus(massdot_tweets): object 'massdot_tweets' not found\n```\n:::\n\n```{.r .cell-code}\nmassdot_tweets_summary <- summary(massdot_tweets_corpus)\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in summary(massdot_tweets_corpus): object 'massdot_tweets_corpus' not found\n```\n:::\n\n```{.r .cell-code}\nmassdot_tweets_summary\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in eval(expr, envir, enclos): object 'massdot_tweets_summary' not found\n```\n:::\n:::\n\n\nTwitter users often write tweets in more of a stream of consciousness format, meaning they don't use complete sentences. I'm skeptical about the reliability of the sentences field in the summary output. However, the word count is likely more accurate. I'm curious how many words on average are used in a tweet mentioning MassDOT.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n##Get mean number of words in a tweet\nmean((ntoken(massdot_tweets_corpus)))\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in ntoken(massdot_tweets_corpus): object 'massdot_tweets_corpus' not found\n```\n:::\n\n```{.r .cell-code}\n##Get median number of words in a tweet\nmedian((ntoken(massdot_tweets_corpus)))\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in ntoken(massdot_tweets_corpus): object 'massdot_tweets_corpus' not found\n```\n:::\n:::\n\n\nOn average, 29 tokens (words) are contained in a tweet mentioning MassDOT, and the median amount of tokens in the 500 tweet set is 24. Next I will tokenize these tweets and drop the puncuation. For now, I'll include the numbers\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Tokenize tweets\ntweets_tokens <- tokens(massdot_tweets_corpus,\n                        remove_punct = T)\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in tokens(massdot_tweets_corpus, remove_punct = T): object 'massdot_tweets_corpus' not found\n```\n:::\n\n```{.r .cell-code}\n(print(tweets_tokens))\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in h(simpleError(msg, call)): error in evaluating the argument 'x' in selecting a method for function 'print': object 'tweets_tokens' not found\n```\n:::\n:::\n\n\nNow I want to take a quick look at how \"MassDOT\" is used in these tweets, whether it be a tag or just mentioned in the text.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# check use of MassDOT in tweets\nkwic_massDOT<- kwic(tweets_tokens,\n                    pattern = c(\"massdot\"),\n                    window = 5)\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in kwic(tweets_tokens, pattern = c(\"massdot\"), window = 5): object 'tweets_tokens' not found\n```\n:::\n\n```{.r .cell-code}\nhead(kwic_massDOT, 50)\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in head(kwic_massDOT, 50): object 'kwic_massDOT' not found\n```\n:::\n:::\n\n\nI notice a lot of the tweet text is repeated in multiple records, likely indicating a retweet. I do wonder how those records should be handled.\n\nSince I ultimately am interested in understanding the sentiment of the tweets, I need to start investigating what words are used and the frequency of those words. I'll look at what adjectives are used most in my next blog post.\n\n### Questions and Next Steps\n\nAfter this initial exploration, I'm left with more questions than answers:\n\n1.  *Assuming I am able to gather tweets every 7 days, will 1000-2000 tweets be sufficient for a reliable analysis? Is my analysis too narrow?*\n\n2.  *Is there even a sentiment to be found?* In my experience of reviewing tweets mentioning MassDOT, many come from news or informational accounts. Can these be used in understanding public sentiment or should I pivot to topic modeling?\n\n3.  *Do retweets need to be removed?* Retweets will create duplicates of the tweet text, but does this still count as an individual tweet? I'm inclined to say yes, since a retweet is often the Twitter user agreeing with the tweet. I'll look through literature to understand if this is appropriate.\n\n------------------------------------------------------------------------\n",
    "supporting": [
      "KirstenJohnson_BlogPost2_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}