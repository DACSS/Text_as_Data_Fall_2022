{
  "hash": "948180bc60bb37ef595f08cce7bcca0d",
  "result": {
    "markdown": "---\ntitle: \"Blog 4 -Supervised Learning Part 1\"\nauthor: \"Rhowena Vespa\"\ndesription: \"Dictionary and Polarity scores\"\ndate: \"10/29/2022\"\nformat:\n  html:\n    toc: true\n    code-fold: true\n    code-copy: true\n    code-tools: true\ncategories:\n  - Blog 4\n  - Polarity1\n  - dictionary\n  - healthcare\n  - supervised learning\n  - ggplot2\n---\n\n::: {.cell}\n\n```{.r .cell-code}\nknitr::opts_chunk$set(echo = TRUE, warning = FALSE)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(readr)\nlibrary(dplyr)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'dplyr'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n```\n:::\n\n```{.r .cell-code}\nlibrary(quanteda)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nPackage version: 3.2.3\nUnicode version: 13.0\nICU version: 69.1\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nParallel computing: 8 of 8 threads used.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nSee https://quanteda.io for tutorials and examples.\n```\n:::\n\n```{.r .cell-code}\nlibrary(quanteda.textstats)\nlibrary(quanteda.textplots)\nlibrary(ggplot2)\nlibrary(DT)\nlibrary(tm)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: NLP\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'NLP'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:ggplot2':\n\n    annotate\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following objects are masked from 'package:quanteda':\n\n    meta, meta<-\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'tm'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:quanteda':\n\n    stopwords\n```\n:::\n\n```{.r .cell-code}\nlibrary(stringr)\nlibrary(tidytext)\nlibrary(plyr)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n------------------------------------------------------------------------------\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nYou have loaded plyr after dplyr - this is likely to cause problems.\nIf you need functions from both plyr and dplyr, please load plyr first, then dplyr:\nlibrary(plyr); library(dplyr)\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n------------------------------------------------------------------------------\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'plyr'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following objects are masked from 'package:dplyr':\n\n    arrange, count, desc, failwith, id, mutate, rename, summarise,\n    summarize\n```\n:::\n\n```{.r .cell-code}\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n── Attaching packages\n───────────────────────────────────────\ntidyverse 1.3.2 ──\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n✔ tibble  3.1.8     ✔ purrr   0.3.5\n✔ tidyr   1.2.1     ✔ forcats 0.5.2\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ NLP::annotate()   masks ggplot2::annotate()\n✖ plyr::arrange()   masks dplyr::arrange()\n✖ purrr::compact()  masks plyr::compact()\n✖ plyr::count()     masks dplyr::count()\n✖ plyr::failwith()  masks dplyr::failwith()\n✖ dplyr::filter()   masks stats::filter()\n✖ plyr::id()        masks dplyr::id()\n✖ dplyr::lag()      masks stats::lag()\n✖ plyr::mutate()    masks dplyr::mutate()\n✖ plyr::rename()    masks dplyr::rename()\n✖ plyr::summarise() masks dplyr::summarise()\n✖ plyr::summarize() masks dplyr::summarize()\n```\n:::\n\n```{.r .cell-code}\nlibrary(quanteda.textmodels)\nlibrary(devtools)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: usethis\n```\n:::\n\n```{.r .cell-code}\nlibrary(caret)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: lattice\n\nAttaching package: 'caret'\n\nThe following object is masked from 'package:purrr':\n\n    lift\n```\n:::\n\n```{.r .cell-code}\nlibrary(quanteda.dictionaries)\n#library(devtools)\n#devtools::install_github(\"kbenoit/quanteda.dictionaries\")\nlibrary(quanteda.dictionaries)\nlibrary(syuzhet) \n#remotes::install_github(\"quanteda/quanteda.sentiment\")\nlibrary(quanteda.sentiment)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'quanteda.sentiment'\n\nThe following object is masked from 'package:quanteda':\n\n    data_dictionary_LSD2015\n```\n:::\n:::\n\n\n\nThis 4th Blog starts work on supervised machine learning from week 7 and 8. Using tweet replies as corpus,\nsentiment scores, polarity scores are calculated and visualized.\n\nSupervised machine learning will continue on next blog post to build models for polarity classification\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Read in data\n\nIRA<- read_csv(\"IRA_med.csv\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nNew names:\nRows: 9497 Columns: 79\n── Column specification\n──────────────────────────────────────────────────────── Delimiter: \",\" chr\n(34): edit_history_tweet_ids, text, lang, source, reply_settings, entit... dbl\n(18): id, conversation_id, referenced_tweets.replied_to.id, referenced_... lgl\n(23): referenced_tweets.retweeted.id, edit_controls.is_edit_eligible, r... dttm\n(4): edit_controls.editable_until, created_at, author.created_at, __tw...\nℹ Use `spec()` to retrieve the full column specification for this data. ℹ\nSpecify the column types or set `show_col_types = FALSE` to quiet this message.\n• `` -> `...79`\n```\n:::\n\n```{.r .cell-code}\n#remove @twitter handles\nIRA$text <- gsub(\"@[[:alpha:]]*\",\"\", IRA$text) #remove Twitter handles\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nIRA_corpus <- corpus(IRA,text_field = \"text\")   \n```\n:::\n\n\n#tokenize and stemming\n\n::: {.cell}\n\n```{.r .cell-code}\nIRA_tokens <- tokens(IRA_corpus)\nIRA_tokens <- tokens_wordstem(IRA_tokens)\n```\n:::\n\n\n\n# USING LECTURE week8 --NRC sentiment\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# use liwcalike() to estimate sentiment using NRC dictionary\nIRAreviewSentiment_nrc <- liwcalike(IRA_corpus, data_dictionary_NRC)\n\nnames(IRAreviewSentiment_nrc)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] \"docname\"      \"Segment\"      \"WPS\"          \"WC\"           \"Sixltr\"      \n [6] \"Dic\"          \"anger\"        \"anticipation\" \"disgust\"      \"fear\"        \n[11] \"joy\"          \"negative\"     \"positive\"     \"sadness\"      \"surprise\"    \n[16] \"trust\"        \"AllPunc\"      \"Period\"       \"Comma\"        \"Colon\"       \n[21] \"SemiC\"        \"QMark\"        \"Exclam\"       \"Dash\"         \"Quote\"       \n[26] \"Apostro\"      \"Parenth\"      \"OtherP\"      \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(IRAreviewSentiment_nrc) +\n  geom_histogram(aes(x = positive)) +\n  theme_bw()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n```\n:::\n\n::: {.cell-output-display}\n![](Blog4_Vespa_IRA_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nIRA_corpus[which(IRAreviewSentiment_nrc$positive > 15)]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCorpus consisting of 376 documents and 78 docvars.\ntext19 :\n\"4president   The US gets zero benefit by supporting Ukraine....\"\n\ntext28 :\n\" we’re winning?\"\n\ntext78 :\n\" bold faced lie\"\n\ntext131 :\n\" Prove it\"\n\ntext138 :\n\" Bullshit clown\"\n\ntext139 :\n\" Nothing has been won you clown\"\n\n[ reached max_ndoc ... 370 more documents ]\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(IRAreviewSentiment_nrc) +\n  geom_histogram(aes(x = negative)) +\n  theme_bw()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n```\n:::\n\n::: {.cell-output-display}\n![](Blog4_Vespa_IRA_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nIRA_corpus[which(IRAreviewSentiment_nrc$negative > 15)]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCorpus consisting of 884 documents and 78 docvars.\ntext24 :\n\"  suck on that\"\n\ntext25 :\n\" press x to doubt\"\n\ntext26 :\n\"  Hasbara troll.. shutthefuckup hoe\"\n\ntext33 :\n\" Pharma didn't lose shit.\"\n\ntext78 :\n\" bold faced lie\"\n\ntext91 :\n\" And inflation still went up\"\n\n[ reached max_ndoc ... 878 more documents ]\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# create a full dfm for comparison\nIRA_Dfm <- tokens(IRA_corpus,\n                         remove_punct = TRUE,\n                         remove_symbols = TRUE,\n                         remove_numbers = TRUE,\n                         remove_url = TRUE,\n                         split_hyphens = FALSE,\n                         include_docvars = TRUE) %>%\n  tokens_tolower() %>%\n  dfm()\n\nhead(IRA_Dfm, 10)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nDocument-feature matrix of: 10 documents, 11,231 features (99.88% sparse) and 78 docvars.\n       features\ndocs    so when do i get to see those cheap prices\n  text1  0    0  0 0   0  0   0     0     0      0\n  text2  1    1  1 1   1  1   1     1     1      1\n  text3  0    0  0 1   0  0   0     0     0      0\n  text4  0    0  0 0   0  1   0     0     0      0\n  text5  0    0  0 0   1  1   0     0     0      0\n  text6  0    0  0 0   0  0   0     0     0      0\n[ reached max_ndoc ... 4 more documents, reached max_nfeat ... 11,221 more features ]\n```\n:::\n\n```{.r .cell-code}\ndim(IRA_Dfm)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1]  9497 11231\n```\n:::\n\n```{.r .cell-code}\n# convert corpus to dfm using the dictionary\nIRADfm_nrc <- tokens(IRA_corpus,\n                         remove_punct = TRUE,\n                         remove_symbols = TRUE,\n                         remove_numbers = TRUE,\n                         remove_url = TRUE,\n                         split_hyphens = FALSE,\n                         include_docvars = TRUE) %>%\n  tokens_tolower() %>%\n  dfm() %>%\n  dfm_lookup(data_dictionary_NRC)\n  \n  \ndim(IRADfm_nrc)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 9497   10\n```\n:::\n\n```{.r .cell-code}\nhead(IRADfm_nrc, 10)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nDocument-feature matrix of: 10 documents, 10 features (76.00% sparse) and 78 docvars.\n       features\ndocs    anger anticipation disgust fear joy negative positive sadness surprise\n  text1     0            0       0    0   0        0        0       0        0\n  text2     0            0       0    0   0        1        0       0        0\n  text3     2            1       0    1   1        2        1       1        0\n  text4     0            0       0    0   0        1        1       0        0\n  text5     0            0       0    0   0        0        1       0        0\n  text6     1            0       0    0   0        1        0       1        0\n       features\ndocs    trust\n  text1     0\n  text2     0\n  text3     1\n  text4     0\n  text5     0\n  text6     0\n[ reached max_ndoc ... 4 more documents ]\n```\n:::\n\n```{.r .cell-code}\nclass(IRADfm_nrc)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"dfm\"\nattr(,\"package\")\n[1] \"quanteda\"\n```\n:::\n:::\n\n\n# POLARITY\n\n::: {.cell}\n\n```{.r .cell-code}\nIRAdf_nrc <- convert(IRADfm_nrc, to = \"data.frame\")\nnames(IRAdf_nrc)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] \"doc_id\"       \"anger\"        \"anticipation\" \"disgust\"      \"fear\"        \n [6] \"joy\"          \"negative\"     \"positive\"     \"sadness\"      \"surprise\"    \n[11] \"trust\"       \n```\n:::\n\n```{.r .cell-code}\nIRAdf_nrc$polarity <- (IRAdf_nrc$positive - IRAdf_nrc$negative)/(IRAdf_nrc$positive + IRAdf_nrc$negative)\n\nIRAdf_nrc$polarity[(IRAdf_nrc$positive + IRAdf_nrc$negative) == 0] <- 0\n\nggplot(IRAdf_nrc) +\n  geom_histogram(aes(x=polarity)) +\n  theme_bw()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n```\n:::\n\n::: {.cell-output-display}\n![](Blog4_Vespa_IRA_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n\n\n# NEW DATAFRAME WITH TEXT AND POLARITY\n\n\n::: {.cell}\n\n```{.r .cell-code}\nIRAdf_nrc_CBIND <- as.data.frame(cbind(IRAdf_nrc, IRA_text_df))\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in data.frame(..., check.names = FALSE): object 'IRA_text_df' not found\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nIRAdf_nrc_CBIND <- as.character(IRAdf_nrc_CBIND)\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in eval(expr, envir, enclos): object 'IRAdf_nrc_CBIND' not found\n```\n:::\n\n```{.r .cell-code}\ntypeof(IRAdf_nrc_CBIND)\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in typeof(IRAdf_nrc_CBIND): object 'IRAdf_nrc_CBIND' not found\n```\n:::\n:::\n\n\n# NEW CORPUS with polarity scores\n\n\n::: {.cell}\n\n```{.r .cell-code}\nIRApolarity_corpus <- corpus(IRAdf_nrc_CBIND)\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in corpus(IRAdf_nrc_CBIND): object 'IRAdf_nrc_CBIND' not found\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nwriteLines(head(IRA_corpus[which(IRAdf_nrc$polarity == 1)]))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n What use to cost 2-3 dollars at grocery stores now cost 5-7 dollars and we get less product. Great job.\n How much of our money have you sent to Ukraine now joe?\n4president   The US gets zero benefit by supporting Ukraine.  Absolutely nothing!\n_di1200     Do you think the US will stand by when the Taliban use the “ARSENAL” left behind against an ally? \\n\\n5 years? \\n10 years?\\n\\nPeace forever lol\n we’re winning?\n570SEASONS  These are good provisions that will help people. Trump campaigned on a few of these too. https://t.co/KQmJRxKZYV\n```\n:::\n:::\n\n\n\n# APPLY DICTIONARY within context\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# tokenize corpus\nIRAtokens <- tokens(IRA_corpus, remove_punct = TRUE)\n# what are the context (target) words or phrases\nIRA_words <- c(\"inflation\",\"POTUS\", \"price*\",\"joe\", \"biden\", \"trump\",\"medicare\",\"drug\",\"cost\",\"america*\",\"won\",\"lost\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# retain only our tokens and their context\nIRAtokens_HC <- tokens_keep(IRAtokens, pattern = phrase(IRA_words), window = 40)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nIRAdata_dictionary_LSD2015_pos_neg <- data_dictionary_LSD2015[1:2]\n\nIRAtokens_HC_lsd <- tokens_lookup(IRAtokens_HC,\n                               dictionary = data_dictionary_LSD2015_pos_neg)\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in is(x, \"dictionary2\"): object 'data_dictionary_LSD2015_pos_neg' not found\n```\n:::\n:::\n\n\n# COnvert to dfm\n\n\n::: {.cell}\n\n```{.r .cell-code}\nIRAdfm_HC <- dfm(IRAtokens_HC_lsd)\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in dfm(IRAtokens_HC_lsd): object 'IRAtokens_HC_lsd' not found\n```\n:::\n\n```{.r .cell-code}\nhead(IRAdfm_HC, 10)\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in head(IRAdfm_HC, 10): object 'IRAdfm_HC' not found\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# convert to data frame\nIRAmat_HC <- convert(IRAdfm_HC, to = \"data.frame\")\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in convert(IRAdfm_HC, to = \"data.frame\"): object 'IRAdfm_HC' not found\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# drop if both features are 0\nIRAmat_HC <- IRAmat_HC[-which((IRAmat_HC$negative + IRAmat_HC$positive)==0),]\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in eval(expr, envir, enclos): object 'IRAmat_HC' not found\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# print a little summary info\npaste(\"We have \",nrow(IRAmat_HC),\" tweets replies that mention positive or negative words in the context of Inflation terms.\", sep=\"\")\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in nrow(IRAmat_HC): object 'IRAmat_HC' not found\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# create polarity scores\nIRAmat_HC$polarity <- (IRAmat_HC$positive - IRAmat_HC$negative)/(IRAmat_HC$positive + IRAmat_HC$negative)\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in eval(expr, envir, enclos): object 'IRAmat_HC' not found\n```\n:::\n\n```{.r .cell-code}\n# summary\nsummary(IRAmat_HC$polarity)\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in summary(IRAmat_HC$polarity): object 'IRAmat_HC' not found\n```\n:::\n\n```{.r .cell-code}\n# plot\nggplot(IRAmat_HC) + \n  geom_histogram(aes(x=polarity)) + \n  theme_bw()\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in ggplot(IRAmat_HC): object 'IRAmat_HC' not found\n```\n:::\n:::\n\n\n\n\n## REFERENCES\n\n        1. House, T., 2022. BY THE NUMBERS: The Inflation Reduction Act - The White House. [online] The White House. Available at: <https://www.whitehouse.gov/briefing-room/statements-releases/2022/08/15/by-the-numbers-the-inflation-reduction-act/> [Accessed 15 October 2022].\n        2. Biden, P. (2022, October 15). We pay more for our prescription drugs than any other nation in the world. it's outrageous. but now, instead of money going into the pockets of drug companies, it will go into your pockets in the form of lower drug prices. Twitter. Retrieved October 15, 2022, from https://twitter.com/POTUS/status/1581374573815431168 \n        3. Robinson, J. S. and D. (n.d.). Welcome to text mining with r: Text mining with R. Welcome to Text Mining with R | Text Mining with R. Retrieved October 15, 2022, from https://www.tidytextmining.com/ \n\n\n\n\n\n",
    "supporting": [
      "Blog4_Vespa_IRA_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}