{
  "hash": "a5582c6f5eff74ad6d08f2606bd4587a",
  "result": {
    "markdown": "---\ntitle: \"Blog Post 4\"\nauthor: \"Claire Battaglia\"\ndesription: \"Applying Dictionary Methods to Open-Text Survey Responses\"\ndate: \"10/30/2022\"\nformat:\n  html:\n    toc: true\n    code-fold: true\n    code-copy: true\n    code-tools: true\ncategories:\n  - Claire Battaglia\n  - text-as-data\n  - blog post 4\n  - open-text survey response\n  - dictionary methods\n---\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(plyr)\nlibrary(tidyverse)\nlibrary(tidytext)\nlibrary(quanteda)\nlibrary(devtools)\nlibrary(quanteda.dictionaries)\nlibrary(quanteda.sentiment)\n\nknitr::opts_chunk$set(echo = TRUE)\n```\n:::\n\n\nIn this post I'll be applying dictionary methods to my corpus. My corpus is the responses to the open-text survey question \"What changes would you like to see for Missoula’s food system?\" As I understand it, utilizing dictionary methods to analyze a corpus essentially entails measuring the frequency with which words in a given lexicon appear the corpus. I haven't found any pre-existing lexicons that are relevant to my corpus so I believe that I will ultimately need to create my own to really analyze this corpus using dictionary methods. For today, though, I will use existing dictionaries just to practice.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# load corpus from blog post 3\nload(\"change_corpus.RData\")\n\n# load dfm from blog post 3\nload(\"change_no_stop_dfm.RData\")\n```\n:::\n\n\nFirst I'll try the `liwcalike()` function from `quanteda.dictionaries`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# use liwcalike\nchange_sentimentNRC <- liwcalike(change_corpus, data_dictionary_NRC)\n\nnames(change_sentimentNRC)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] \"docname\"      \"Segment\"      \"WPS\"          \"WC\"           \"Sixltr\"      \n [6] \"Dic\"          \"anger\"        \"anticipation\" \"disgust\"      \"fear\"        \n[11] \"joy\"          \"negative\"     \"positive\"     \"sadness\"      \"surprise\"    \n[16] \"trust\"        \"AllPunc\"      \"Period\"       \"Comma\"        \"Colon\"       \n[21] \"SemiC\"        \"QMark\"        \"Exclam\"       \"Dash\"         \"Quote\"       \n[26] \"Apostro\"      \"Parenth\"      \"OtherP\"      \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# create plot for positive\nggplot(change_sentimentNRC) +\n  geom_histogram(aes(x = positive)) +\n  theme_bw()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n```\n:::\n\n::: {.cell-output-display}\n![](ClaireBattaglia_blogpost4_files/figure-html/plot positive and negative-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# create plot for negative\nggplot(change_sentimentNRC) +\n  geom_histogram(aes(x = negative)) +\n  theme_bw()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n```\n:::\n\n::: {.cell-output-display}\n![](ClaireBattaglia_blogpost4_files/figure-html/plot positive and negative-2.png){width=672}\n:::\n:::\n\n\nIf I'm understanding these plots correctly, the vast majority of responses have not been categorized as either positive or negative. This makes sense given the question \"What changes would you like to see for Missoula’s food system?\" While respondents may have (and quite likely *do* have) positive or negative feelings about the Missoula food system, the question doesn't specifically ask about those feelings.\n\n<aside> After comparing the measures to the actual text of the documents, some of the documents that are neither positive nor negative may actually be blank responses. </aside>\n\nNext I'll create a document feature matrix using a dictionary.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# create dfm with NRC dictionary\nchange_sentimentNRC_dfm <- tokens(change_corpus,\n                         remove_punct = TRUE,\n                         remove_symbols = TRUE,\n                         remove_numbers = TRUE,\n                         remove_url = TRUE,\n                         split_hyphens = FALSE,\n                         include_docvars = TRUE) %>%\n  tokens_tolower() %>%\n  dfm() %>%\n  dfm_lookup(data_dictionary_NRC)\n\n# preview\nhead(change_sentimentNRC_dfm, 10)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nDocument-feature matrix of: 10 documents, 10 features (57.00% sparse) and 0 docvars.\n       features\ndocs    anger anticipation disgust fear joy negative positive sadness surprise\n  text1     0            1       0    0   1        0        1       0        1\n  text2     0            0       0    0   0        0        0       0        0\n  text3     0            0       0    0   0        0        1       0        0\n  text4     2            3       1    2   4        4        7       1        2\n  text5     1            0       2    2   1        2        2       2        0\n  text6     0            0       0    0   0        0        0       0        0\n       features\ndocs    trust\n  text1     1\n  text2     0\n  text3     0\n  text4     3\n  text5     1\n  text6     0\n[ reached max_ndoc ... 4 more documents ]\n```\n:::\n:::\n\n\nNext I'll do the same thing but use a different dictionary.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# create dfm with Gen Inq dictionary\nchange_sentimentGenInq_dfm <- change_no_stop_dfm %>%\n  dfm_lookup(data_dictionary_geninqposneg)\n\n# preview\nhead(change_sentimentGenInq_dfm, 10)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nDocument-feature matrix of: 10 documents, 2 features (50.00% sparse) and 0 docvars.\n       features\ndocs    positive negative\n  text1        2        0\n  text2        0        0\n  text3        1        0\n  text4        7        2\n  text5        2        2\n  text6        0        0\n[ reached max_ndoc ... 4 more documents ]\n```\n:::\n:::\n\n\nAt least from these previews there seems to be reasonable agreement between the two dictionaries. I'm going to look at the actual documents to see if I can get a sense of what is being categorized as positive and negative.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# preview corpus\nhead(change_corpus, 10)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCorpus consisting of 10 documents.\ntext1 :\n\"More concentration on the basic good groups\"\n\ntext2 :\n\"\"\n\ntext3 :\n\"I'd like to see more storytelling around regenerative agricu...\"\n\ntext4 :\n\"Factual, evidence-based relationships are not widely underst...\"\n\ntext5 :\n\"Whatever it takes to get nutritious sustainable food into th...\"\n\ntext6 :\n\"\"\n\n[ reached max_ndoc ... 4 more documents ]\n```\n:::\n:::\n\n\nInteresting. Based on the categorizations of the above text, I don't ultimately think that analyzing sentiment of the responses is really appropriate. Many of the above documents are neither positive nor negative but are being categorized as one or the other. I also think that given the question that produced these responses, analyzing sentiment isn't especially interesting. I am more interested in a method that will allow me to understand the actual changes respondents would like to see.\n\nI will continue to look for an appropriate dictionary to use for my corpus. I also need to practice these methods a bit more, as I feel that there are parts I don't really understand yet.\n\n\n\n\n\n\n",
    "supporting": [
      "ClaireBattaglia_blogpost4_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}