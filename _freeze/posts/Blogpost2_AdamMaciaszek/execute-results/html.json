{
  "hash": "daabaacc4debb26ed490bf51323929f8",
  "result": {
    "markdown": "---\ntitle: \"Blog Post 2 Adam Maciaszek\"\nauthor: \"Adam Maciaszek\"\ndesription: \"Web Scraping Ancient babylonian texts\"\ndate: \"10/10/2022\"\nformat:\n  html:\n    toc: true\n    code-fold: true\n    code-copy: true\n    code-tools: true\n---\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nimport pandas as pd\nimport re\nimport numpy as np\nimport collections\nimport matplotlib.pyplot as plt\n```\n:::\n\n\n## Blog Post 2\nFurther investigation into Zipf's law and ancient texts\n\n## Web Scraping Ancient babylonian texts\nTo analyze ancient texts in relation to the Zipf law and the general complexity compared to modern-day language A large source of documents needed to be gathered. For this, I used a collection created by the Department of History, School of History, Religions & Philosophies of SOAS University of London. This collection's purpose was to hear how the ancient language of Akkadian sounded like and have recordings of each text as well as a phonetic spelling of each word. Each text is separate line by line with its direct translation of the line rather than a reworded contextual translation. The collection of these texts was made more difficult since the website I found currently is being reorganized and I needed to use the WayBackMAchine archived webpages which does not include the sound recording but all of the texts were saved\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\ndef cleaner(the_input):\n    the_input = re.sub(\"\\(\\(.*\\)\\)\",'', the_input)\n    the_input=the_input.lower()\n    the_input = the_input.replace('(ii',\"\").replace(\"iii.\",\"\").replace(\"ii.\",\"\").replace(\"i ii \",\"\").replace(\"i i \",\"\").replace(\"i iii \",\"\")\n    the_input = the_input.replace('#',\"\").replace('˺',\"\").replace('˹',\"\").replace(':',\"\").replace('<',\"\").replace('>',\"\").replace('*',\"\").replace('\\xa0',\"\").replace('|',\"\").replace('/',\"\").replace('–',\"\").replace('“',\"\").replace('”',\"\").replace(\"[\",\"\").replace(\"]\",\"\").replace(\"(\",\"\").replace(\")\",\"\").replace(\"’\",\"\").replace(\".\",\"\").replace(\"…\",\"\").replace(\":\",\"\").replace(\"!\",\"\").replace(\"?\",\"\")\n    the_input = the_input.replace(\"   \",\" \").replace(\"  \",\" \").replace(\",\",\"\").replace(\";\",\"\").replace('\"',\"\")\n    return the_input\n\ndef grab_html2(url,text_output):\n    df = pd.read_html(url)\n    df=df[1]\n    for x in range(0,len(df)):\n        akk=df.iloc[x][0]\n        akk = re.sub(r'[0-9]+', '', akk)\n        akk = cleaner(akk)\n        akk = akk.replace('- ',\" \")\n        akk = akk.replace(' -',\" \")\n        eng=df.iloc[x][1]\n        eng = re.sub(r'[0-9]+', '', eng)\n        eng = cleaner(eng)\n        eng = eng.replace('- ',\" \")\n        eng = eng.replace(' -',\" \")\n        akk=akk[1:] if akk.startswith(\" \") else akk\n        eng=eng[1:] if eng.startswith(\" \") else eng\n        if akk=='' or \"lines\" in akk and \"lost\" in akk or \"fragmentary\" in akk:\n            continue\n        else:\n            text_output.append([akk,eng])\n    return text_output\n\ndef grab_html(url,text_output):\n    error_flag=0\n    df = pd.read_html(url)\n    df=df[1]\n    temp_text = []\n    for x in range(0,len(df)):\n        tester=df.iloc[x][0]\n        tester = cleaner(tester)\n        if \"lines\" in tester and \"lost\" in tester or \"fragmentary\" in tester:\n            tester=\"\"\n        akk = re.split('([0123456789]+)', tester)\n        index=-1\n        while '' in akk:\n            akk.remove('')\n        while '-' in akk:\n            index = akk.index('-')\n            del akk[index]\n            del akk[index]\n            \n        tester=df.iloc[x][1]\n        tester = cleaner(tester)\n        if \"lines\" in tester and \"lost\" in tester or \"fragmentary\" in tester:\n            tester=\"\"\n        eng = re.split('([0123456789]+)', tester)\n        index=-1\n        while '' in eng:\n            eng.remove('')\n        while '-' in eng:\n            index = eng.index('-')\n            del eng[index]\n            del eng[index]\n        if len(akk)!=len(eng):\n            error_flag=1\n            break\n        for y in range(0,len(akk)):\n            if akk[y].isnumeric() or akk[y]=='':\n                continue\n            else:\n                akk[y]=akk[y][1:] if akk[y].startswith(\" \") else akk[y]\n                eng[y]=eng[y][1:] if eng[y].startswith(\" \") else eng[y]\n                akk[y]=akk[y][2:] if akk[y].startswith(\"’ \") else akk[y]\n                eng[y]=eng[y][2:] if eng[y].startswith(\"’ \") else eng[y]\n                temp_text.append([akk[y],eng[y]])\n    if error_flag==1:\n        return grab_html2(url,text_output)\n    else:\n        text_output.extend(temp_text)\n        return text_output\n```\n:::\n\n\nBelow is a loop scraping and collecting all the data from a list of URLs, originally the function would be able to grab each element from the home webpage but being archived by the way back machine each URL for a text needs to be specified.\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\ntext = []\nurls=[\"https://web.archive.org/web/20220920202225/https://www.soas.ac.uk/baplar/recordings/ammi-ditnas-hymn-to-itar-read-by-k-hecker.html\",\"https://web.archive.org/web/20220920202226/https://www.soas.ac.uk/baplar/recordings/the-codex-hammurabi-prologue-i1-49-read-by-albert-naccache.html\",\"https://web.archive.org/web/20220920202223/https://www.soas.ac.uk/baplar/recordings/the-codex-hammurapi-epilogue-xlix-18-28-and-53-80-read-by-aage-westenholz.html\",\"https://web.archive.org/web/20220920202227/https://www.soas.ac.uk/baplar/recordings/the-epic-of-gilgame-old-babylonian-version-tablet-ii-lines-85-111-read-by-michael-streck.html\",\"https://web.archive.org/web/20220920202232/https://www.soas.ac.uk/baplar/recordings/the-epic-of-gilgame-old-babylonian-version-tablet-ii-lines-1-61-read-by-jacob-klein.html\",\"https://web.archive.org/web/20220920202229/https://www.soas.ac.uk/baplar/recordings/gilgamesh-x-huehnergard.html\",\"https://web.archive.org/web/20220920202226/https://www.soas.ac.uk/baplar/recordings/the-epic-of-gilgamesh-old-babylonian-version-bmvat-lines-ii0-iii14-read-by-martin-west.html\",\"https://web.archive.org/web/20220920202232/https://www.soas.ac.uk/baplar/recordings/the-epic-of-anz-old-babylonian-version-from-susa-tablet-ii-lines-1-83-read-by-claus-wilcke.html\",\"https://web.archive.org/web/20220920202229/https://www.soas.ac.uk/baplar/recordings/atramass-ob-version-from-sippir-tablet-i-lines-i1-iii16-read-by-claus-wilcke.html\",\"https://web.archive.org/web/20220920202231/https://www.soas.ac.uk/baplar/recordings/diviners-prayer-to-the-gods-of-the-night-read-by-michael-streck.html\",\"https://web.archive.org/web/20220920202228/https://www.soas.ac.uk/baplar/recordings/incantation-for-dog-bite-read-by-michael-streck.html\",\"https://web.archive.org/web/20220920202223/https://www.soas.ac.uk/baplar/recordings/letter-of-marduk-nir-to-ruttum-abb-iii-15-read-by-wilfred-van-soldt.html\",\"https://web.archive.org/web/20220920202225/https://www.soas.ac.uk/baplar/recordings/letter-of-kurkurtum-to-erb-sn-abb-xii-89-read-by-wilfred-van-soldt.html\",\"https://web.archive.org/web/20220920202230/https://www.soas.ac.uk/baplar/recordings/ob-letter-iddin-sin.html\",\"https://web.archive.org/web/20220920202225/https://www.soas.ac.uk/baplar/recordings/the-epic-of-gilgame-standard-version-tablet-xi-lines-1-163-read-by-karl-hecker.html\",\"https://web.archive.org/web/20220920202224/https://www.soas.ac.uk/baplar/recordings/the-poem-of-the-righteous-sufferer-ludlul-bl-nmeqi-tablet-ii-lines-1-26-and-56-82-read-by-brigitte-groneberg.html\",\"https://web.archive.org/web/20220920202229/https://www.soas.ac.uk/baplar/recordings/the-poem-of-the-righteous-sufferer-ludlul-bl-nmeqi-tablet-ii-lines-1-55-read-by-margaret-jaques-cavigneaux.html\",\"https://web.archive.org/web/20220920202231/https://www.soas.ac.uk/baplar/recordings/itars-descent-to-the-netherworld-lines-1-125-read-by-martin-west.html\",\"https://web.archive.org/web/20220920202231/https://www.soas.ac.uk/baplar/recordings/the-ama-hymn-lines-15-52-read-by-martin-west.html\"]\nfor source in urls:\n    text = grab_html(source,text)\n        \nfor x in range(0,10) : print(text[x])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n['iltam zumrā rašubti ilātim', 'sing ye of the goddess the most fearsome of the gods']\n[\"litta''id bēlet iššī rabīt igigī\", 'praise be upon the lady ruler of men the greatest of the igigi']\n['ištar zumrā rašubti ilātim', 'sing ye of ishtar the most fearsome of the gods']\n[\"litta''id bēlet ilī nišī rabīt igigī\", 'praise be upon the lady ruler of the people the greatest of the igigi']\n['šāt mēleṣim ruāmam labšat', 'she who gets excited clothed in sex appeal']\n[\"za'nat inbī mīkiam u kuzbam\", 'adorned with fruits charm and allure']\n['šāt mēleṣim ruāmam labšat', 'she who gets excited clothed in sex appeal']\n[\"za'nat inbī mīkiam u kuzbam\", 'adorned with fruits charm and allure']\n['šaptīn duššupat balāṭum pīša', 'she is sweet at the lips her mouth is life']\n['simtišša ihannīma ṣīhātum', 'delights are lush on her cheeks']\n```\n:::\n:::\n\n\nHere each is separating the Akkadian only text from the array. Each line or chunk is broken down into an array of words and then appended to a list of all the Akkadian words. Using the counter class it fills a dictionary with each word being a key and the value is that word's frequency. The graph displays on the x axis in order of theier frequency of usage of the first 12 words and the y-axis is how many times that word was used.\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\nall_words = []\nakkadian=[i[0] for i in text]\nfor z in range(0,len(akkadian)):\n    stuff = re.split(' ', akkadian[z])\n    all_words = all_words + stuff\nall_words=np.sort(all_words)\nall_words=all_words[all_words!='']\nelements_count = collections.Counter(all_words)\nprint(\"In Akkadian there are \",len(all_words),\" and\",len(elements_count),\"of which are unique\")\n\nelements = sorted(elements_count.items(), key=lambda item: (-item[1], item[0]))\nelements_count=collections.OrderedDict(elements)\nindex=0\nfor key, value in elements_count.items():\n    index+=1\n    print(f\"{key}: {value}\")\n    if index > 11: break\n        \nspecific_word = list(elements_count.keys())\nword_freq = list(elements_count.values())\n\nplt.bar(specific_word[:12], word_freq[:12])\nplt.show()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nIn Akkadian there are  4160  and 2253 of which are unique\nana: 158\nina: 119\nša: 93\nu: 77\nul: 57\nlā: 47\nkīma: 30\nilī: 27\ništar: 23\nenlil: 21\nilū: 18\nlū: 18\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](Blogpost2_AdamMaciaszek_files/figure-html/cell-5-output-2.png){}\n:::\n:::\n\n\nBelow the same process was repeated for all of the English translations of the same lines. This is done as a control since the content should be nearly the same the word distribution should be similar if it follows Zipf law the same way English does.\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\nall_words = []\nenglish=[i[1] for i in text]\nfor z in range(0,len(english)):\n    stuff = re.split(' ', english[z])\n    all_words = all_words + stuff\n\nall_words=np.sort(all_words)\nall_words=all_words[all_words!='']\nelements_count = collections.Counter(all_words)\nprint(\"In English there are \",len(all_words),\" and\",len(elements_count),\"of which are unique\")\n\nelements = sorted(elements_count.items(), key=lambda item: (-item[1], item[0]))\nelements_count=collections.OrderedDict(elements)\nindex=0\nfor key, value in elements_count.items():\n    index+=1\n    print(f\"{key}: {value}\")\n    if index > 11: break\n        \nspecific_word = list(elements_count.keys())\nword_freq = list(elements_count.values())\n\nplt.bar(specific_word[:12], word_freq[:12])\nplt.show()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nIn English there are  7706  and 1709 of which are unique\nthe: 660\nof: 239\nand: 195\nto: 175\ni: 148\nmy: 136\nher: 123\nhis: 109\na: 108\nin: 104\nyou: 94\nhe: 86\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](Blogpost2_AdamMaciaszek_files/figure-html/cell-6-output-2.png){}\n:::\n:::\n\n\nThe next area of calculation is finding the syllable count for the words and there will need to be separate functions for each language. Normally this would be very difficult if had the raw cuniform of Akkadian but since it is phonetic spelling there are no silent letters or special rules unique to that language\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\ndef syllable_eng(word):\n    word = word.lower()\n    count = 0\n    vowels = \"aeiouy\"\n    if word[0] in vowels:\n        count += 1\n    for index in range(1, len(word)):\n        if word[index] in vowels and word[index - 1] not in vowels:\n            count += 1\n    if word.endswith(\"e\"):\n        count -= 1\n    if count == 0:\n        count += 1\n    return count\ndef syllable_akk(word):\n    word = word.lower()\n    count = 0\n    vowels = \"īāîáâêeēíûaoūui\"\n    if word[0] in vowels:\n        count += 1\n    for index in range(1, len(word)):\n        if word[index] in vowels and word[index - 1] not in vowels:\n            count += 1\n    if count == 0:\n        count += 1\n    return count\n```\n:::\n\n\nHere the average number of syllabls per word is calulated over all for each language showing that akkadian despite having many fewer words to describe the same concept they are longer and have more syllabuls. In the graph each dot represents a line or chunk of text the red in Akkadian and the blue in English\n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\nakkadian=[i[0] for i in text]\nenglish=[i[1] for i in text]\nwords_akk,syl_akk,words_eng,syl_eng=[],[],[],[]\nfor line in  range(0,len(akkadian)):\n    words_akk.append(len(akkadian[line].split()))\n    syl_akk.append(syllable_akk(akkadian[line]))\n    words_eng.append(len(english[line].split()))\n    syl_eng.append(syllable_eng(english[line]))\nprint(\"Average number of syllables per word Akkadian: \",(sum(syl_akk)/sum(words_akk)))\nprint(\"Average number of syllables per word English: \", (sum(syl_eng)/sum(words_eng)))\nplt.plot(words_akk,syl_akk, 'o', color='red');\nplt.plot(words_eng,syl_eng, 'o', color='blue');\nplt.xlabel('Words per Line/Chunk')\nplt.ylabel('Syllables per Line/Chunk')\nplt.show()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAverage number of syllables per word Akkadian:  2.4793269230769233\nAverage number of syllables per word English:  1.4600311445626784\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](Blogpost2_AdamMaciaszek_files/figure-html/cell-8-output-2.png){}\n:::\n:::\n\n\n",
    "supporting": [
      "Blogpost2_AdamMaciaszek_files"
    ],
    "filters": [],
    "includes": {}
  }
}